From 3aca5309ed2be29155d100491a04fef52ed3909a Mon Sep 17 00:00:00 2001
From: hemanthk <hemanthkumar.sm@intel.com>
Date: Fri, 11 Sep 2020 17:00:50 +0530
Subject: [PATCH 218/223] xlink-secure: TBH - Add Support for SecureXLink
 Driver

    Secure Xlink driver secures data over Xlink.

    Secure Xlink driver will use HW acceleration for
    encryption/decryption.

Signed-off-by: hemanthk <hemanthkumar.sm@intel.com>
---
 drivers/misc/Kconfig                          |    1 +
 drivers/misc/Makefile                         |    1 +
 drivers/misc/xlink-secure/Kconfig             |   35 +
 drivers/misc/xlink-secure/Makefile            |    5 +
 drivers/misc/xlink-secure/xlink-secure-defs.h |   38 +
 drivers/misc/xlink-secure/xlink-secure.c      | 1585 +++++++++++++++++
 drivers/misc/xlink-secure/xlink_aead_api.c    |  162 ++
 drivers/misc/xlink-secure/xlink_aead_api.h    |   29 +
 include/linux/xlink_secure.h                  |   44 +
 include/uapi/misc/xlink_secure_data_struct.h  |  163 ++
 include/uapi/misc/xlink_secure_uapi.h         |   94 +
 11 files changed, 2157 insertions(+)
 create mode 100644 drivers/misc/xlink-secure/Kconfig
 create mode 100644 drivers/misc/xlink-secure/Makefile
 create mode 100644 drivers/misc/xlink-secure/xlink-secure-defs.h
 create mode 100644 drivers/misc/xlink-secure/xlink-secure.c
 create mode 100644 drivers/misc/xlink-secure/xlink_aead_api.c
 create mode 100644 drivers/misc/xlink-secure/xlink_aead_api.h
 create mode 100644 include/linux/xlink_secure.h
 create mode 100644 include/uapi/misc/xlink_secure_data_struct.h
 create mode 100644 include/uapi/misc/xlink_secure_uapi.h

diff --git a/drivers/misc/Kconfig b/drivers/misc/Kconfig
index 10cb04daf7e9..359636934596 100644
--- a/drivers/misc/Kconfig
+++ b/drivers/misc/Kconfig
@@ -483,4 +483,5 @@ source "drivers/misc/vpumgr/Kconfig"
 source "drivers/misc/xlink-pcie/Kconfig"
 source "drivers/misc/xlink-core/Kconfig"
 source "drivers/misc/xlink-ipc/Kconfig"
+source "drivers/misc/xlink-secure/Kconfig"
 endmenu
diff --git a/drivers/misc/Makefile b/drivers/misc/Makefile
index 61b52d0e29ef..3fe577324920 100644
--- a/drivers/misc/Makefile
+++ b/drivers/misc/Makefile
@@ -68,3 +68,4 @@ obj-$(CONFIG_VPUMGR)		+= vpumgr/
 obj-y				+= xlink-pcie/
 obj-$(CONFIG_XLINK_CORE)        += xlink-core/
 obj-$(CONFIG_XLINK_IPC)		+= xlink-ipc/
+obj-$(CONFIG_XLINK_SECURE)      += xlink-secure/
diff --git a/drivers/misc/xlink-secure/Kconfig b/drivers/misc/xlink-secure/Kconfig
new file mode 100644
index 000000000000..a28c1abb72ff
--- /dev/null
+++ b/drivers/misc/xlink-secure/Kconfig
@@ -0,0 +1,35 @@
+config XLINK_SECURE
+	tristate "Support for XLINK SECURE"
+	depends on XLINK_CORE
+	depends on CRYPTO_DEV_THUNDERBAY_OCS_AES_SECUREXLINK
+	help
+	  XLINK SECURE Secures Data Over XLINK
+          communication/control Sub-System.
+
+	  If unsure, say N.
+
+	  To compile this driver as a module, choose M here: the
+	  module will be called xlink-secure.ko.
+
+config XLINK_SECURE_MULTITENANT
+	tristate "Support for XLINK SECURE MULTIPLETENANCY"
+	depends on XLINK_SECURE
+	help
+	  XLINK SECURE MULTITENANT enables the xlink secure driver with
+	  support for multiple tenants.
+
+	  Say Y for Thunder Bay Soc Multitenancy Build.
+
+	  If unsure, say N.
+
+config XLINK_SECURE_LOCAL_HOST
+	tristate "Support for XLINK SECURE LOCAL HOST"
+	depends on XLINK_SECURE
+	help
+	  XLINK SECURE LOCAL HOST enables local host functionality for
+	  the communication/control Sub-System.
+
+	  Enable this config when building the kernel for the Intel Vision
+	  Processing Unit (VPU) Local Host core.
+
+	  If unsure, say N.
diff --git a/drivers/misc/xlink-secure/Makefile b/drivers/misc/xlink-secure/Makefile
new file mode 100644
index 000000000000..20df3dc2cbc5
--- /dev/null
+++ b/drivers/misc/xlink-secure/Makefile
@@ -0,0 +1,5 @@
+#
+# Makefile for xlink secure Linux driver
+#
+obj-$(CONFIG_XLINK_SECURE) += xlink_secure.o
+xlink_secure-objs += xlink-secure.o xlink_aead_api.o
diff --git a/drivers/misc/xlink-secure/xlink-secure-defs.h b/drivers/misc/xlink-secure/xlink-secure-defs.h
new file mode 100644
index 000000000000..e453379b23de
--- /dev/null
+++ b/drivers/misc/xlink-secure/xlink-secure-defs.h
@@ -0,0 +1,38 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+/*
+ * Xlink Secure Driver.
+ *
+ * Copyright (C) 2020-2021 Intel Corporation
+ *
+ */
+
+#ifndef __XLINK_SECURE_DEFS_H
+#define __XLINK_SECURE_DEFS_H
+
+#include <linux/xlink.h>
+#include <linux/xlink_secure.h>
+
+#define XLINK_MAX_BUF_SIZE 128U
+#define XLINK_MAX_DATA_SIZE (1024U * 1024U * 1024U)
+
+#define XLINK_SECURE_DEBUG
+
+#ifdef XLINK_SECURE_DEBUG
+
+#define XLINK_SECURE_DBG(x, args...) do { \
+		if (xlink_secure_dbg) { \
+			pr_info("SECURE_XLINK_KDBG %s() : " x, __func__, ##args); \
+		} \
+	} while (0)
+
+#else
+
+#define XLINK_SECURE_DBG(x, ...)
+
+#endif
+
+#define XLINK_SECURE_ERR(x, args...) pr_info("SECURE_XLINK_KERR %s(): " x, __func__, ##args)
+
+extern unsigned int xlink_secure_dbg;
+
+#endif /* __XLINK_SECURE_DEFS_H */
diff --git a/drivers/misc/xlink-secure/xlink-secure.c b/drivers/misc/xlink-secure/xlink-secure.c
new file mode 100644
index 000000000000..8452627aec9c
--- /dev/null
+++ b/drivers/misc/xlink-secure/xlink-secure.c
@@ -0,0 +1,1585 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Xlink Secure Driver.
+ *
+ * Copyright (C) 2020-2021 Intel Corporation
+ *
+ */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/cdev.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/mod_devicetable.h>
+#include <linux/uaccess.h>
+#include <linux/dma-mapping.h>
+#include <linux/kobject.h>
+#include <linux/sysfs.h>
+#include <linux/string.h>
+#include "xlink-secure-defs.h"
+#include "xlink_aead_api.h"
+#include <linux/sched.h>
+#include <linux/sched/mm.h>
+#include <linux/sched/task.h>
+#include <linux/dma-buf.h>
+#include <linux/dma-direct.h>
+#include <linux/err.h>
+
+// xlink secure version number
+#define XLINK_VERSION_MAJOR	0
+#define XLINK_VERSION_MINOR	1
+
+// device, class, and driver names
+#define DEVICE_NAME "xlnksecure"
+#define CLASS_NAME  "xlksecure"
+#define DRV_NAME    "xlink-secure-driver"
+
+#define AES_GCM_IVLEN   12
+#define AES_GCM_TAGLEN  16
+#define AES_GCM_AADLEN  15
+
+#define PCIE_PID_TBH 0X4FC0
+#define XLINK_MAX_DEVICE_LIST_SIZE 12
+
+// used to extract the interface type from a sw device id
+#define SW_DEVICE_ID_INTERFACE_SHIFT 24U
+#define SW_DEVICE_ID_INTERFACE_MASK  0x7
+#define GET_INTERFACE_FROM_SW_DEVICE_ID(id) \
+	       (((id) >> SW_DEVICE_ID_INTERFACE_SHIFT) & SW_DEVICE_ID_INTERFACE_MASK)
+#define SW_DEVICE_ID_IPC_INTERFACE  0x0
+#define SW_DEVICE_ID_PCIE_INTERFACE 0x1
+#define SW_DEVICE_ID_USB_INTERFACE  0x2
+#define SW_DEVICE_ID_ETH_INTERFACE  0x3
+
+#define XLNK_SEC_CNTRL_CHAN_PCIE 0x9FC
+
+#define METADATA_SIZE (sizeof(struct header) + sizeof(uint64_t))
+
+//#define CONFIG_XLINK_SECURE_MULTITENANT
+
+static dev_t xdev;
+static struct class *dev_class;
+static struct cdev xlink_cdev;
+static struct xlnk_sec_handle g_sec_handler[NUM_OF_CONNECTIONS];
+static u32 sks_mask;
+static struct mutex initialize_lock;
+static int initialize_done;
+static bool disable;
+module_param(disable, bool, 0644);
+MODULE_PARM_DESC(disable, "Control to Disable Xlink Security");
+
+static long xlink_secure_ioctl(struct file *file, unsigned int cmd,
+			       unsigned long arg);
+
+static const struct file_operations fops = {
+		.owner			= THIS_MODULE,
+		.unlocked_ioctl = xlink_secure_ioctl,
+};
+
+struct xlink_secure_dev {
+	struct platform_device *pdev;
+};
+
+/*
+ * Global variable pointing to our Xlink Secure Device.
+ *
+ * This is meant to be used only when platform_get_drvdata() cannot be used
+ * because we lack a reference to our platform_device.
+ */
+static struct xlink_secure_dev *xlink;
+struct xlnk_sec_multidev *sec_multidev;
+u32 sec_num_devices;
+struct seqno_chan {
+	u64 tx_ctr; //tx ctr per channel
+	u64 rx_ctr; //rx ctr per channel
+	u32 chan_no;
+	struct   list_head      chan_list;
+	struct   aead_request  *r_aead_req;
+	struct   aead_request  *w_aead_req;
+	struct   iv_format     *r_gcm_iv;
+	struct   iv_format     *w_gcm_iv;
+	u8 *cipher_data;
+	u32 cipher_data_size;
+	u32 xlink_read;
+};
+
+struct list_head *chan_node;
+
+static int xlink_secure_find_sec_device(struct xlink_handle *handle)
+{
+	int id, limit;
+
+#ifdef CONFIG_XLINK_SECURE_MULTITENANT
+	if (handle->dev_type == HOST_DEVICE) {
+		id = 0;
+		limit = sec_num_devices / 2;
+	} else {
+		id = sec_num_devices / 2;
+		limit = sec_num_devices;
+	}
+#else
+	id = 0;
+	limit = sec_num_devices;
+#endif
+	while (id < limit) {
+		if (sec_multidev[id].sw_device_id == handle->sw_device_id)
+			return id;
+		id++;
+	}
+
+	return -1;
+}
+
+static struct seqno_chan *find_seqno_chan_list_context(u16 chan, int id)
+{
+	struct seqno_chan *node;
+
+	list_for_each_entry(node, &chan_node[id], chan_list) {
+		if (node->chan_no != chan)
+			continue;
+		else
+			return node;
+	}
+	XLINK_SECURE_DBG("ERROR: Could not find channel context\n");
+	return NULL;
+}
+
+static struct xlnk_sec_handle *find_secure_handler(struct xlink_handle *handle)
+{
+#ifdef CONFIG_XLINK_SECURE_MULTITENANT
+	int i = 0;
+
+	if (handle->dev_type == HOST_DEVICE) {
+		for (i = 0; i < 4; i++) {
+			if (handle->sw_device_id == g_sec_handler[i].sw_device_id)
+				return &g_sec_handler[i];
+		}
+	} else {
+		for (i = 4; i < 8; i++) {
+			if (handle->sw_device_id == g_sec_handler[i].sw_device_id)
+				return &g_sec_handler[i];
+		}
+	}
+
+	return NULL;
+#else
+	return &g_sec_handler[0];
+#endif
+}
+
+static struct seqno_chan *seqno_list_create_add_node(u32 chan_no,
+						     struct xlink_handle *handle,
+						     uint32_t data_size)
+{
+	struct seqno_chan  *node;
+	int dev_id = 0;
+	struct xlnk_sec_handle *sec_handler;
+	int reqsize;
+
+	sec_handler = find_secure_handler(handle);
+	if (!sec_handler) {
+		XLINK_SECURE_ERR("sec_handler not found\n");
+		return NULL;
+	}
+
+	dev_id = xlink_secure_find_sec_device(handle);
+	if (dev_id < 0)	{
+		XLINK_SECURE_ERR("Invalid Device ID\n");
+		return NULL;
+	}
+
+	node = kzalloc(sizeof(*node), GFP_KERNEL);
+	if (!node) {
+		XLINK_SECURE_ERR("node kzalloc fail\n");
+		return NULL;
+	}
+
+	reqsize = sizeof(*node->r_aead_req) + crypto_aead_reqsize(sec_multidev[dev_id].tfm);
+
+	INIT_LIST_HEAD(&node->chan_list);
+
+	node->tx_ctr = 0;
+	node->rx_ctr = 0;
+	node->chan_no = chan_no;
+	node->cipher_data = NULL;
+	node->cipher_data_size = 0;
+	node->xlink_read = 0;
+	node->r_aead_req = kzalloc(reqsize, GFP_KERNEL);
+	if (!node->r_aead_req) {
+		XLINK_SECURE_ERR("read aead_req kzalloc fail\n");
+		return NULL;
+	}
+
+	node->w_aead_req = kzalloc(reqsize, GFP_KERNEL);
+	if (!node->w_aead_req) {
+		XLINK_SECURE_ERR("write aead_req kzalloc fail\n");
+		return NULL;
+	}
+
+	node->r_gcm_iv = kmalloc(AES_GCM_IVLEN, GFP_KERNEL);
+	if (!node->r_gcm_iv) {
+		XLINK_SECURE_ERR("read gcmiv kzalloc fail\n");
+		return NULL;
+	}
+
+	memcpy(node->r_gcm_iv->fixed_iv, sec_handler->fixed_iv,
+	       (TLS_FIXED_IV_SIZE * sizeof(uint8_t)));
+
+	node->w_gcm_iv = kmalloc(AES_GCM_IVLEN, GFP_KERNEL);
+	if (!node->w_gcm_iv) {
+		XLINK_SECURE_ERR("write gcm iv kzalloc fail\n");
+		return NULL;
+	}
+
+	memcpy(node->w_gcm_iv->fixed_iv, sec_handler->fixed_iv,
+	       (TLS_FIXED_IV_SIZE * sizeof(uint8_t)));
+
+	mutex_lock(&sec_handler->lock);
+	list_add(&node->chan_list, &chan_node[dev_id]);
+	mutex_unlock(&sec_handler->lock);
+
+	XLINK_SECURE_DBG("seqno_list_create_add__node on chan = %u\n", chan_no);
+
+	return node;
+}
+
+static void  seqno_list_delete_node(struct xlnk_sec_handle *sec_handler, struct seqno_chan *node)
+{
+	XLINK_SECURE_DBG("chan = %u\n", node->chan_no);
+
+	mutex_lock(&sec_handler->lock);
+	list_del(&node->chan_list);
+	mutex_unlock(&sec_handler->lock);
+
+	node->cipher_data = NULL;
+	node->cipher_data_size = 0;
+	node->xlink_read = 0;
+	kfree_sensitive(node->r_aead_req);
+	kfree_sensitive(node->w_aead_req);
+	kfree(node->r_gcm_iv);
+	kfree(node->w_gcm_iv);
+	kfree(node);
+}
+
+static enum xlink_error xlink_secure_dmabuf_to_paddr(struct dma_buf *dmabuf,
+						     enum dma_data_direction direction,
+						     phys_addr_t *physical_addr)
+{
+	enum xlink_error rc = X_LINK_SUCCESS;
+	struct dma_buf_attachment *attach;
+	struct sg_table *sgt;
+	struct scatterlist *sg;
+	dma_addr_t addr;
+
+	attach = dma_buf_attach(dmabuf, &xlink->pdev->dev);
+	if (IS_ERR(attach))
+		return X_LINK_ERROR;
+
+	sgt = dma_buf_map_attachment(attach, direction);
+	if (IS_ERR(sgt)) {
+		dma_buf_detach(dmabuf, attach);
+		return X_LINK_ERROR;
+	}
+
+	sg = sgt->sgl;
+	addr = sg_dma_address(sg);
+	(*physical_addr) = (addr + sg->offset);
+
+	XLINK_SECURE_DBG("\nsg->offset = %d\n", sg->offset);
+	XLINK_SECURE_DBG("\nsg_dma_addr = %llx\n", addr);
+
+	dma_buf_unmap_attachment(attach, sgt, direction);
+	dma_buf_detach(dmabuf, attach);
+
+	return rc;
+}
+
+static enum xlink_error xlink_secure_uvirt_to_dmabuf(u8 *user_virt_addr, struct dma_buf **dmabuf)
+{
+	struct task_struct *task = current;
+	struct mm_struct *mm;
+	struct vm_area_struct *vma;
+
+	mm = get_task_mm(task);
+	if (!mm)
+		goto failed;
+
+	mmap_read_lock(mm);
+	vma = find_vma(mm, (unsigned long)user_virt_addr);
+	if (!vma) {
+		XLINK_SECURE_ERR("\ncannot find vaddr\n");
+		goto failed;
+	}
+
+	if ((unsigned long)user_virt_addr < vma->vm_start) {
+		XLINK_SECURE_ERR("\nfailed at line %d, user_virt_addr=%llx, vma->vm_start=%lx\n",
+				 __LINE__, (u64)user_virt_addr, vma->vm_start);
+		goto failed;
+	}
+
+	/* make sure the vma is backed by a dmabuf */
+	if (!vma->vm_file) {
+		XLINK_SECURE_ERR("\nfailed at line %d\n", __LINE__);
+		goto failed;
+	}
+
+	*dmabuf = vma->vm_file->private_data;
+	if (!(*dmabuf)) {
+		XLINK_SECURE_ERR("\nfailed at line %d\n", __LINE__);
+		goto failed;
+	}
+
+	if ((*dmabuf)->file != vma->vm_file) {
+		XLINK_SECURE_ERR("\nfailed at line %d\n", __LINE__);
+		goto failed;
+	}
+
+	mmap_read_unlock(mm);
+	mmput(mm);
+
+	return X_LINK_SUCCESS;
+
+failed:
+	XLINK_SECURE_ERR("\nxlink_secure_get_dmabuf failed\n");
+	if (mm) {
+		mmap_read_unlock(mm);
+		mmput(mm);
+	}
+	return X_LINK_ERROR;
+}
+
+static int xlink_secure_tfm_init(void)
+{
+	u32 ocs_slice_id;
+	char crypto_driver_name[128];
+	int id;
+
+#ifdef CONFIG_XLINK_SECURE_MULTITENANT
+	for (id = 0; id < (sec_num_devices / 2); id++) {
+		sprintf(crypto_driver_name, "xlink-gcm-aes-thunderbay-ocs_cpu");
+		sec_multidev[id].tfm =	xlink_aead_setup_encrypt(crypto_driver_name,
+								 AES_GCM_TAGLEN);
+	}
+#else
+	id = 0;
+#endif
+	for (ocs_slice_id = 1; ocs_slice_id < NOF_OCS_SLICE; ocs_slice_id++) {
+		if (sks_mask & (1 << ocs_slice_id)) {
+			sprintf(crypto_driver_name,
+				"xlink-gcm-aes-thunderbay-ocs_%d",
+					(ocs_slice_id - 1));
+			sec_multidev[id].tfm =	xlink_aead_setup_encrypt(crypto_driver_name,
+									 AES_GCM_TAGLEN);
+			id++;
+		}
+	}
+
+	if (id != sec_num_devices) {
+		XLINK_SECURE_ERR("aead setup based on sks mask failed\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+static void xlink_secure_sks_init(void)
+{
+#ifdef CONFIG_XLINK_SECURE_MULTITENANT
+	//TODO prime case handle
+	g_sec_handler[0].ocs_sks.slice[0].status = SLICE_ENABLED;
+	g_sec_handler[0].ocs_sks.slice[0].slot = OCS_SKS_SLOT_15;
+	g_sec_handler[0].ocs_sks.slice[0].prepareAes = SKS_SKIP_PREPARE_AES;
+
+	g_sec_handler[1].ocs_sks.slice[0].status = SLICE_ENABLED;
+	g_sec_handler[1].ocs_sks.slice[0].slot = OCS_SKS_SLOT_16;
+	g_sec_handler[1].ocs_sks.slice[0].prepareAes = SKS_SKIP_PREPARE_AES;
+
+	g_sec_handler[2].ocs_sks.slice[0].status = SLICE_ENABLED;
+	g_sec_handler[2].ocs_sks.slice[0].slot = OCS_SKS_SLOT_17;
+	g_sec_handler[2].ocs_sks.slice[0].prepareAes = SKS_SKIP_PREPARE_AES;
+
+	g_sec_handler[3].ocs_sks.slice[0].status = SLICE_ENABLED;
+	g_sec_handler[3].ocs_sks.slice[0].slot = OCS_SKS_SLOT_18;
+	g_sec_handler[3].ocs_sks.slice[0].prepareAes = SKS_SKIP_PREPARE_AES;
+
+	g_sec_handler[4].ocs_sks.slice[1].status = SLICE_ENABLED;
+	g_sec_handler[4].ocs_sks.slice[1].slot = OCS_SKS_SLOT_15;
+	g_sec_handler[4].ocs_sks.slice[1].prepareAes = SKS_DO_PREPARE_AES;
+
+	g_sec_handler[5].ocs_sks.slice[2].status = SLICE_ENABLED;
+	g_sec_handler[5].ocs_sks.slice[2].slot = OCS_SKS_SLOT_15;
+	g_sec_handler[5].ocs_sks.slice[2].prepareAes = SKS_DO_PREPARE_AES;
+
+	g_sec_handler[6].ocs_sks.slice[3].status = SLICE_ENABLED;
+	g_sec_handler[6].ocs_sks.slice[3].slot = OCS_SKS_SLOT_15;
+	g_sec_handler[6].ocs_sks.slice[3].prepareAes = SKS_DO_PREPARE_AES;
+
+	g_sec_handler[7].ocs_sks.slice[4].status = SLICE_ENABLED;
+	g_sec_handler[7].ocs_sks.slice[4].slot = OCS_SKS_SLOT_15;
+	g_sec_handler[7].ocs_sks.slice[4].prepareAes = SKS_DO_PREPARE_AES;
+#else
+	u32 ocs_slice_id;
+	struct sks_info *p_slice;
+
+	for (ocs_slice_id = 1; ocs_slice_id < NOF_OCS_SLICE; ocs_slice_id++) {
+		if (sks_mask & (1 << ocs_slice_id)) {
+			p_slice = &g_sec_handler[0].ocs_sks.slice[ocs_slice_id];
+			p_slice->status = SLICE_ENABLED;
+			p_slice->slot = OCS_SKS_SLOT_15;
+			p_slice->prepareAes = SKS_DO_PREPARE_AES;
+		}
+	}
+#endif
+}
+
+static struct kobject *xlink_secure_kobject;
+unsigned int xlink_secure_dbg;
+
+static ssize_t xlink_secure_dbg_show(struct kobject *kobj, struct kobj_attribute *attr,
+				     char *buf)
+{
+	return sprintf(buf, "%u\n", xlink_secure_dbg);
+}
+
+static ssize_t xlink_secure_dbg_store(struct kobject *kobj, struct kobj_attribute *attr,
+				      const char *buf, size_t count)
+{
+	unsigned int value;
+
+	if (kstrtou32(buf, 10, &value) == 0)
+		xlink_secure_dbg = value;
+	return count;
+}
+
+static struct kobj_attribute xlink_secure_dbg_attribute = __ATTR(debug, 0664,
+		xlink_secure_dbg_show, xlink_secure_dbg_store);
+
+/* Driver probing. */
+static int xlink_secure_probe(struct platform_device *pdev)
+{
+	struct xlink_secure_dev *xlink_dev;
+	struct device *dev_ret;
+	int rc, i;
+	u32 count = 0, mask = 0;
+
+	dev_info(&pdev->dev, "xlink-secure v%d.%d\n", XLINK_VERSION_MAJOR,
+		 XLINK_VERSION_MINOR);
+	xlink_dev = devm_kzalloc(&pdev->dev, sizeof(*xlink), GFP_KERNEL);
+	if (!xlink_dev)
+		return -ENOMEM;
+
+	xlink_dev->pdev = pdev;
+	platform_set_drvdata(pdev, xlink_dev);
+
+	/* Set the global reference to our device. */
+	xlink = xlink_dev;
+
+	if (device_property_read_u32(&pdev->dev, "sks-mask", &sks_mask)) {
+		dev_err(&pdev->dev, "Failed to set sks-mask\n");
+		return -1;
+	}
+
+	mask = sks_mask;
+	while (mask) {
+		mask &= (mask - 1);
+		count++;
+	}
+
+#ifdef CONFIG_XLINK_SECURE_MULTITENANT
+	dev_info(&pdev->dev, "multitenant build\n");
+	sec_num_devices = (count * 2);
+#else
+	dev_info(&pdev->dev, "singletenant build\n");
+	sec_num_devices = count;
+#endif
+
+	dev_info(&pdev->dev, "xlink-secure sec_num_devices=%d",	sec_num_devices);
+
+	sec_multidev = devm_kzalloc(&pdev->dev,
+				    sizeof(struct xlnk_sec_multidev) * sec_num_devices, GFP_KERNEL);
+	if (!sec_multidev)
+		return -ENOMEM;
+
+	if (dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64))) {
+		dev_err(&pdev->dev, "Failed to set 64 bit dma mask\n");
+		return -ENODEV;
+	}
+
+	/*Allocating Major number*/
+	if ((alloc_chrdev_region(&xdev, 0, 1, "xlinksecuredev")) < 0) {
+		dev_err(&pdev->dev, "Cannot allocate major number\n");
+		return -1;
+	}
+	dev_info(&pdev->dev, "Major = %d Minor = %d\n", MAJOR(xdev), MINOR(xdev));
+
+	mutex_init(&initialize_lock);
+	for (i = 0; i < NUM_OF_CONNECTIONS; i++)
+		mutex_init(&g_sec_handler[i].lock);
+
+	xlink_secure_sks_init();
+
+	xlink_secure_kobject = kobject_create_and_add("xlink_secure",
+						      kernel_kobj);
+	if (!xlink_secure_kobject)
+		return -ENOMEM;
+
+	rc = sysfs_create_file(xlink_secure_kobject, &xlink_secure_dbg_attribute.attr);
+	if (rc) {
+		dev_info(&pdev->dev, "failed to create the debug file\n");
+		return -1;
+	}
+
+	/*Creating struct class*/
+	dev_class = class_create(THIS_MODULE, CLASS_NAME);
+	if (IS_ERR(dev_class)) {
+		dev_info(&pdev->dev, "Cannot create the struct class - Err %ld\n",
+			 PTR_ERR(dev_class));
+		goto r_class;
+	}
+
+	/*Creating device*/
+	dev_ret = device_create(dev_class, NULL, xdev, NULL, DEVICE_NAME);
+	if (IS_ERR(dev_ret)) {
+		dev_err(&pdev->dev, "Cannot create the Device 1 - Err %ld\n",
+			PTR_ERR(dev_ret));
+		goto r_device;
+	}
+	dev_info(&pdev->dev, "Xlink-Secure Device Driver Insert...Done!!!\n");
+
+	/*Creating cdev structure*/
+	cdev_init(&xlink_cdev, &fops);
+
+	/*Adding character device to the system*/
+	if ((cdev_add(&xlink_cdev, xdev, 1)) < 0) {
+		dev_err(&pdev->dev, "Cannot add the device to the system\n");
+		goto r_class;
+	}
+
+	chan_node = kzalloc((sec_num_devices * sizeof(*chan_node)), GFP_KERNEL);
+	if (!chan_node) {
+		XLINK_SECURE_ERR("ERROR: chan_node kzalloc fail\n");
+		return -ENOMEM;
+	}
+	for (i = 0; i < sec_num_devices; i++)
+		INIT_LIST_HEAD(&chan_node[i]);
+
+	return 0;
+
+r_device:
+	class_destroy(dev_class);
+r_class:
+	unregister_chrdev_region(xdev, 1);
+	return -1;
+}
+
+/* Driver removal. */
+static int xlink_secure_remove(struct platform_device *pdev)
+{
+	int id;
+	// unregister and destroy device
+	kobject_put(xlink_secure_kobject);
+	unregister_chrdev_region(xdev, 1);
+	device_destroy(dev_class, xdev);
+	cdev_del(&xlink_cdev);
+	class_destroy(dev_class);
+	for (id = 0; id < sec_num_devices; id++)
+		xlink_aead_free(sec_multidev[id].tfm);
+	kfree(chan_node);
+	pr_info("XLink Secure Driver removed\n");
+	return 0;
+}
+
+static enum xlink_error xlink_secure_key_exchange(unsigned long arg)
+{
+	struct xlinksecurekeyexchange ex = {0};
+	struct xlinksecurekeyexchange *p_ex;
+	struct xlnk_sec_handle *sec_handler;
+	struct xlink_handle handle;
+	int id;
+#ifdef CONFIG_XLINK_SECURE_MULTITENANT
+	u8 slot_id;
+#endif
+
+	if (copy_from_user(&ex, (int32_t *)arg, sizeof(struct xlinksecurekeyexchange)))
+		return X_LINK_ERROR;
+	p_ex = (struct xlinksecurekeyexchange *)arg;
+
+	if (copy_from_user(&handle, (struct xlink_handle *)ex.handle,
+			   sizeof(struct xlink_handle)))
+		return -EFAULT;
+
+	sec_handler = find_secure_handler(&handle);
+	if (!sec_handler) {
+		XLINK_SECURE_ERR("sec_handler not found\n");
+		return X_LINK_ERROR;
+	}
+
+	id = xlink_secure_find_sec_device(&handle);
+	if (id < 0) {
+		XLINK_SECURE_ERR("Error Could not find sec device\n");
+		return X_LINK_ERROR;
+	}
+
+	switch (ex.op) {
+	case KEY_EXCHANGE_MUTEX_LOCK:
+		XLINK_SECURE_DBG("KEY_EXCHANGE_MUTEX_LOCK\n");
+		XLINK_SECURE_DBG("get mutex\n");
+		mutex_lock(&sec_handler->lock);
+		XLINK_SECURE_DBG("got mutex\n");
+		break;
+	case KEY_EXCHANGE_MUTEX_UNLOCK:
+		XLINK_SECURE_DBG("KEY_EXCHANGE_MUTEX_UNLOCK\n");
+		mutex_unlock(&sec_handler->lock);
+		XLINK_SECURE_DBG("unlocked mutex\n");
+		break;
+	case KEY_EXCHANGE_GET_INFO:
+		XLINK_SECURE_DBG("KEY_EXCHANGE_GET_INFO\n");
+		if (copy_to_user(&p_ex->conn_flag,
+				 (void *)&sec_handler->conn_flag,
+			sizeof(sec_handler->conn_flag)))
+			return X_LINK_ERROR;
+
+		if (copy_to_user(&p_ex->ocs_sks,
+				 (void *)&sec_handler->ocs_sks,
+			sizeof(struct ocs_sks_info)))
+			return X_LINK_ERROR;
+
+		if (copy_to_user(&p_ex->handshake,
+				 (void *)&sec_handler->handshake,
+			sizeof(struct handshake_info)))
+			return X_LINK_ERROR;
+		break;
+	case KEY_EXCHANGE_SET_INFO:
+		XLINK_SECURE_DBG("KEY_EXCHANGE_SET_INFO\n");
+		memcpy(&sec_handler->conn_flag, &ex.conn_flag,
+		       sizeof(ex.conn_flag));
+		memcpy(sec_handler->fixed_iv, ex.fixed_iv,
+		       TLS_FIXED_IV_SIZE);
+		memcpy(&sec_handler->ocs_sks, &ex.ocs_sks,
+		       sizeof(struct ocs_sks_info));
+		print_hex_dump(KERN_INFO, "fixed_iv: ",
+			       DUMP_PREFIX_ADDRESS, 16, 1,
+				sec_handler->fixed_iv,
+				TLS_FIXED_IV_SIZE, true);
+#ifdef CONFIG_XLINK_SECURE_MULTITENANT
+		if (sec_handler->ocs_sks.slice[0].status == SLICE_ENABLED) {
+			slot_id = (u8)sec_handler->ocs_sks.slice[0].slot;
+			crypto_aead_setkey(sec_multidev[id].tfm, &slot_id, 1);
+		}
+#endif
+		break;
+	}
+
+	return X_LINK_SUCCESS;
+}
+
+/*
+ * IOCTL function for User Space access to xlink secure kernel functions
+ *
+ */
+
+static long xlink_secure_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
+{
+	int rc = 0;
+	struct xlink_handle device_handle = {0};
+	struct xlink_handle local_handle = {0};
+	struct xlinksecureopenchannel op = {0};
+	struct xlinksecurewritedata wr = {0};
+	struct xlinksecurereaddata rd = {0};
+	struct xlinksecureconnect con = {0};
+	struct xlinksecurerelease rel = {0};
+	struct xlinksecuredisable dis = {0};
+	u8 *plain_data = NULL;
+	u8 *rdaddr = NULL;
+	u8 *disable_flag = NULL;
+	u32 size = 0;
+	u8 reladdr;
+
+	switch (cmd) {
+	case XL_SECURE_CONNECT:
+		if (copy_from_user(&con, (int32_t *)arg, sizeof(struct xlinksecureconnect)))
+			return -EFAULT;
+		if (copy_from_user(&device_handle, (struct xlink_handle *)con.handle,
+				   sizeof(struct xlink_handle)))
+			return -EFAULT;
+		rc = xlink_secure_connect(&device_handle);
+		if (!rc) {
+			if (copy_to_user((struct xlink_handle *)con.handle, &device_handle,
+					 sizeof(struct xlink_handle)))
+				return -EFAULT;
+		}
+		if (copy_to_user(con.return_code, (void *)&rc, sizeof(rc)))
+			return -EFAULT;
+		break;
+	case XL_SECURE_OPEN_CHANNEL:
+		if (copy_from_user(&op, (int32_t *)arg,
+				   sizeof(struct xlinksecureopenchannel)))
+			return -EFAULT;
+		if (copy_from_user(&device_handle, (struct xlink_handle *)op.handle,
+				   sizeof(struct xlink_handle)))
+			return -EFAULT;
+		rc = xlink_secure_open_channel(&device_handle, op.chan, op.mode, op.data_size,
+					       op.timeout);
+		if (copy_to_user(op.return_code, (void *)&rc, sizeof(rc)))
+			return -EFAULT;
+		break;
+	case XL_SECURE_READ_DATA:
+		if (copy_from_user(&rd, (int32_t *)arg, sizeof(struct xlinksecurereaddata)))
+			return -EFAULT;
+		if (copy_from_user(&device_handle, (struct xlink_handle *)rd.handle,
+				   sizeof(struct xlink_handle)))
+			return -EFAULT;
+		if (device_handle.dev_type == VPUIP_DEVICE) {/*Slice Secure*/
+			rc = xlink_secure_read_data(&device_handle, rd.chan,
+						    (uint8_t **)&rd.pmessage, &size);
+			if (!rc) {
+				local_handle.sw_device_id = device_handle.sw_device_id;
+				local_handle.dev_type = HOST_DEVICE;
+				if (rd.pmessage) {
+					XLINK_SECURE_DBG("MT Slice Secure xlink_release data\n");
+					rc = xlink_release_data(&local_handle, rd.chan, NULL);
+					if (rc != X_LINK_SUCCESS)
+						XLINK_SECURE_ERR("Release failed for chan = %d\n",
+								 rd.chan);
+				}
+				if (copy_to_user(rd.size, (void *)&size, sizeof(size)))
+					return -EFAULT;
+			}
+			if (copy_to_user(rd.return_code, (void *)&rc, sizeof(rc)))
+				return -EFAULT;
+		} else {/*ARM Secure*/
+			rc = xlink_secure_read_data(&device_handle, rd.chan, &rdaddr, &size);
+			if (!rc) {
+				if (copy_to_user(rd.pmessage, ((void *)rdaddr +
+					sizeof(struct header) + sizeof(uint64_t)),
+						size))
+					return -EFAULT;
+				local_handle.sw_device_id = device_handle.sw_device_id;
+				local_handle.dev_type = HOST_DEVICE;
+				rc = xlink_release_data(&local_handle, rd.chan, NULL);
+				if (rc != X_LINK_SUCCESS)
+					XLINK_SECURE_ERR("release fail chan = %d\n", rd.chan);
+				if (copy_to_user(rd.size, (void *)&size, sizeof(size)))
+					return -EFAULT;
+			}
+			if (copy_to_user(rd.return_code, (void *)&rc, sizeof(rc)))
+				return -EFAULT;
+		}
+		break;
+	case XL_SECURE_WRITE_DATA:
+		if (copy_from_user(&wr, (int32_t *)arg, sizeof(struct xlinksecurewritedata)))
+			return -EFAULT;
+		if (copy_from_user(&device_handle, (struct xlink_handle *)wr.handle,
+				   sizeof(struct xlink_handle)))
+			return -EFAULT;
+
+		if (device_handle.dev_type == VPUIP_DEVICE) {/*Slice Secure*/
+			rc = xlink_secure_write_data(&device_handle, wr.chan,
+						     (uint8_t const *)wr.pmessage, wr.size);
+			if (copy_to_user(wr.return_code, (void *)&rc, sizeof(rc)))
+				return -EFAULT;
+		} else {/*ARM Secure*/
+			plain_data = kmalloc(wr.size + METADATA_SIZE + AES_GCM_TAGLEN, GFP_KERNEL);
+			if (!plain_data)
+				return -ENOMEM;
+
+			if (copy_from_user(plain_data + METADATA_SIZE, wr.pmessage, wr.size)) {
+				kfree(plain_data);
+				return -EFAULT;
+			}
+			rc = xlink_secure_write_data(&device_handle, wr.chan,
+						     (uint8_t const *)plain_data, wr.size);
+			if (copy_to_user(wr.return_code, (void *)&rc, sizeof(rc))) {
+				kfree(plain_data);
+				return -EFAULT;
+			}
+			kfree(plain_data);
+		}
+		break;
+	case XL_SECURE_RELEASE_DATA:
+		if (copy_from_user(&rel, (int32_t *)arg, sizeof(struct xlinksecurerelease)))
+			return -EFAULT;
+		if (copy_from_user(&device_handle, (struct xlink_handle *)rel.handle,
+				   sizeof(struct xlink_handle)))
+			return -EFAULT;
+		if (rel.addr) {
+			if (get_user(reladdr, (uint32_t *const)rel.addr))
+				return -EFAULT;
+			rc = xlink_secure_release_data(&device_handle,
+						       rel.chan, (uint8_t *)&reladdr);
+		} else {
+			rc = xlink_secure_release_data(&device_handle, rel.chan, NULL);
+		}
+		if (copy_to_user(rel.return_code, (void *)&rc, sizeof(rc)))
+			return -EFAULT;
+		break;
+	case XL_SECURE_DISABLE:
+		if (copy_from_user(&dis, (int32_t *)arg, sizeof(struct xlinksecuredisable)))
+			return -EFAULT;
+
+		disable_flag = kmalloc((sizeof(uint8_t)), GFP_KERNEL);
+		if (!disable_flag)
+			return -ENOMEM;
+		*disable_flag = (uint8_t)disable;
+		if (copy_to_user(dis.flag, (void *)disable_flag, sizeof(uint8_t))) {
+			kfree(disable_flag);
+			return -EFAULT;
+		}
+		kfree(disable_flag);
+		break;
+	case XL_SECURE_CLOSE_CHANNEL:
+		if (copy_from_user(&op, (int32_t *)arg,
+				   sizeof(struct xlinksecureopenchannel)))
+			return -EFAULT;
+		if (copy_from_user(&device_handle, (struct xlink_handle *)op.handle,
+				   sizeof(struct xlink_handle)))
+			return -EFAULT;
+		rc = xlink_secure_close_channel(&device_handle, op.chan);
+		if (copy_to_user(op.return_code, (void *)&rc, sizeof(rc)))
+			return -EFAULT;
+		break;
+	case XL_SECURE_DISCONNECT:
+		if (copy_from_user(&con, (int32_t *)arg, sizeof(struct xlinksecureconnect)))
+			return -EFAULT;
+		if (copy_from_user(&device_handle, (struct xlink_handle *)con.handle,
+				   sizeof(struct xlink_handle)))
+			return -EFAULT;
+		rc = xlink_secure_disconnect(&device_handle);
+		if (copy_to_user(con.return_code, (void *)&rc, sizeof(rc)))
+			return -EFAULT;
+		break;
+	case XL_SECURE_INITIALIZE:
+		rc = xlink_secure_initialize();
+		if (copy_to_user(con.return_code, (void *)&rc, sizeof(rc)))
+			return -EFAULT;
+		break;
+	case XL_SECURE_KEY_EXCHANGE:
+		rc = xlink_secure_key_exchange(arg);
+		if (copy_to_user(con.return_code, (void *)&rc, sizeof(rc)))
+			return -EFAULT;
+		break;
+	}
+	if (rc)
+		return -EIO;
+	else
+		return 0;
+}
+
+/*
+ * Xlink Secure Kernel API.
+ */
+
+enum xlink_error xlink_secure_initialize(void)
+{
+	u32 sw_device_id_list[XLINK_MAX_DEVICE_LIST_SIZE];
+	u32 xlink_num_devices, interface;
+	int id = 0, i = 0, j = 0, interface_found = 0;
+	enum xlink_error rc = X_LINK_SUCCESS;
+	struct xlnk_sec_handle *handle;
+#ifdef CONFIG_XLINK_SECURE_MULTITENANT
+	int k = 4;
+#endif
+
+	XLINK_SECURE_DBG("Entry\n");
+	mutex_lock(&initialize_lock);
+	if (!initialize_done) {
+		if (xlink_get_device_list(sw_device_id_list,
+					  &xlink_num_devices) > 0) {
+			XLINK_SECURE_ERR("Error could not get xlink device list\n");
+			rc = X_LINK_ERROR;
+			goto err;
+		}
+
+		for (i = 0; ((i < xlink_num_devices) && (j < 4)); i++) {
+			if (GET_INTERFACE_FROM_SW_DEVICE_ID(sw_device_id_list[i])
+					== SW_DEVICE_ID_PCIE_INTERFACE) {
+				interface_found = 1;
+#ifdef CONFIG_XLINK_SECURE_MULTITENANT
+				handle = &g_sec_handler[j];
+				handle->handshake.handle.dev_type = HOST_DEVICE;
+				handle->sw_device_id = sw_device_id_list[i];
+				handle->handshake.handle.sw_device_id = sw_device_id_list[i];
+				handle->handshake.channel = XLNK_SEC_CNTRL_CHAN_PCIE - j;
+				j++;
+				handle = &g_sec_handler[k];
+				handle->handshake.handle.dev_type = HOST_DEVICE;
+				handle->sw_device_id = sw_device_id_list[i];
+				handle->handshake.handle.sw_device_id = sw_device_id_list[i];
+				handle->handshake.channel = XLNK_SEC_CNTRL_CHAN_PCIE - k;
+				k++;
+#else
+				handle = &g_sec_handler[0];
+				handle->handshake.handle.dev_type = HOST_DEVICE;
+				handle->handshake.handle.sw_device_id = sw_device_id_list[i];
+				handle->handshake.channel = XLNK_SEC_CNTRL_CHAN_PCIE;
+				break;
+#endif
+			}
+		}
+
+		i = 0;
+#ifdef CONFIG_XLINK_SECURE_MULTITENANT
+		while ((id < (sec_num_devices / 2)) && (i < xlink_num_devices)) {
+			interface = GET_INTERFACE_FROM_SW_DEVICE_ID(sw_device_id_list[i]);
+			if (interface == SW_DEVICE_ID_PCIE_INTERFACE) {
+				sec_multidev[id].sw_device_id = sw_device_id_list[i];
+				sec_multidev[id + (sec_num_devices / 2)].sw_device_id =
+					sw_device_id_list[i];
+				id++;
+			}
+			i++;
+		}
+#else
+		while ((id < sec_num_devices) && (i < xlink_num_devices)) {
+			interface = GET_INTERFACE_FROM_SW_DEVICE_ID(sw_device_id_list[i]);
+			if (interface == SW_DEVICE_ID_PCIE_INTERFACE) {
+				sec_multidev[id].sw_device_id = sw_device_id_list[i];
+				id++;
+			}
+			i++;
+		}
+#endif
+
+		if (interface_found) {
+			if (xlink_secure_tfm_init() < 0) {
+				XLINK_SECURE_ERR("xlink secure tfm init failed\n");
+				rc = X_LINK_ERROR;
+				goto err;
+			}
+			initialize_done = 1;
+			rc = X_LINK_SUCCESS;
+		} else {
+			rc = X_LINK_ERROR;
+		}
+	}
+
+err:
+	mutex_unlock(&initialize_lock);
+	return rc;
+}
+EXPORT_SYMBOL(xlink_secure_initialize);
+
+enum xlink_error xlink_secure_connect(struct xlink_handle *handle)
+{
+	struct xlink_handle local_handle;
+
+	XLINK_SECURE_DBG("Entry\n");
+	local_handle.sw_device_id = handle->sw_device_id;
+	local_handle.dev_type = HOST_DEVICE;
+	return xlink_connect(&local_handle);
+}
+EXPORT_SYMBOL(xlink_secure_connect);
+
+enum xlink_error xlink_secure_open_channel(struct xlink_handle *handle,
+					   u16 chan, enum xlink_opmode mode, uint32_t data_size,
+		uint32_t timeout)
+{
+	struct seqno_chan *node;
+	enum xlink_error rc = X_LINK_SUCCESS;
+	u32 secure_data_size;
+	struct xlink_handle local_handle;
+
+	XLINK_SECURE_DBG("Entry chan=%d\n", chan);
+	local_handle.sw_device_id = handle->sw_device_id;
+	local_handle.dev_type = HOST_DEVICE;
+
+	//resizing data_size to accommodate xlink secure overhead
+	secure_data_size = METADATA_SIZE + data_size + AES_GCM_TAGLEN;
+
+	rc = xlink_open_channel(&local_handle, chan, mode, secure_data_size, timeout);
+	if (rc != X_LINK_SUCCESS) {
+		XLINK_SECURE_ERR("xlink open channel fail rc=%d on chan=%d\n", rc, chan);
+		return rc;
+	}
+
+	node = seqno_list_create_add_node(chan, handle, data_size);
+	if (!node) {
+		XLINK_SECURE_ERR("ERROR: seqno_list_create_add_node fail in open channel\n");
+		return X_LINK_ERROR;
+	}
+
+	return rc;
+}
+EXPORT_SYMBOL(xlink_secure_open_channel);
+
+enum xlink_error xlink_secure_close_channel(struct xlink_handle *handle,
+					    uint16_t chan)
+{
+	int dev_id = 0;
+	struct seqno_chan *node;
+	enum xlink_error rc = X_LINK_SUCCESS;
+	struct xlink_handle local_handle;
+	struct xlnk_sec_handle *sec_handler;
+
+	XLINK_SECURE_DBG("Entry chan=%d\n", chan);
+	local_handle.sw_device_id = handle->sw_device_id;
+	local_handle.dev_type = HOST_DEVICE;
+
+	rc =  xlink_close_channel(&local_handle, chan);
+	//Note: Do not print close channel error log.
+	if (rc != X_LINK_SUCCESS) {
+		XLINK_SECURE_DBG("xlink close channel fail rc=%d chan = %d\n", rc, chan);
+		return rc;
+	}
+
+	sec_handler = find_secure_handler(handle);
+	if (!sec_handler) {
+		XLINK_SECURE_ERR("sec_handler not found\n");
+		return X_LINK_ERROR;
+	}
+
+	dev_id = xlink_secure_find_sec_device(handle);
+	if (dev_id < 0) {
+		XLINK_SECURE_ERR("ERROR: Invalid device ID\n");
+		return X_LINK_ERROR;
+	}
+
+	mutex_lock(&sec_handler->lock);
+	node = find_seqno_chan_list_context(chan, dev_id);
+	mutex_unlock(&sec_handler->lock);
+	if (!node)
+		XLINK_SECURE_DBG("ERROR: failed to find_seqno_chan_list_context\n");
+	else
+		seqno_list_delete_node(sec_handler, node);
+
+	return rc;
+}
+EXPORT_SYMBOL(xlink_secure_close_channel);
+
+enum xlink_error xlink_secure_write_data(struct xlink_handle *handle,
+					 u16 chan, uint8_t const *data_in, uint32_t size)
+{
+	u8 *data_frame = NULL;
+	u8 *data_out_frame = NULL;
+	struct frame_format frame;
+	struct header data_header;
+	struct aad_format *gcm_aad = NULL;
+	enum xlink_error rc = X_LINK_SUCCESS;
+	u32 frame_len = 0;
+	u32 min_data_len = 0;
+	u64 len_ovfl = 0;
+	u64 local_seq = 0;
+	dma_addr_t aad_paddr = 0, data_paddr = 0, data_out_paddr = 0;
+	int id = 0;
+	struct seqno_chan *node;
+	struct xlink_handle local_handle;
+	struct xlnk_sec_handle *sec_handler;
+	u8 *gcm_tag;
+	struct dma_buf *dmabuf = NULL;
+	phys_addr_t phys_addr;
+
+	if (!data_in) {
+		XLINK_SECURE_DBG("\nxlink_secure_write_data_user_buffer_NULL\n");
+		rc = X_LINK_ERROR;
+		goto sec_cleanup;
+	}
+
+	frame_len = sizeof(struct header) + sizeof(frame.sequence) + size + AES_GCM_TAGLEN;
+	min_data_len = sizeof(struct header) + sizeof(frame.sequence) + AES_GCM_TAGLEN;
+
+	len_ovfl = size + min_data_len;
+
+	XLINK_SECURE_DBG("Entry chan=%d\n", chan);
+	local_handle.sw_device_id = handle->sw_device_id;
+	local_handle.dev_type = HOST_DEVICE;
+
+	sec_handler = find_secure_handler(handle);
+	if (!sec_handler) {
+		XLINK_SECURE_ERR("sec_handler not found\n");
+		rc = X_LINK_ERROR;
+		goto sec_cleanup;
+	}
+
+	id = xlink_secure_find_sec_device(handle);
+	if (id < 0) {
+		XLINK_SECURE_ERR("Error Could not find sec device\n");
+		rc = X_LINK_ERROR;
+		goto sec_cleanup;
+	}
+
+	if (size == 0) {
+		XLINK_SECURE_ERR("invalid input data len\n");
+		rc = X_LINK_ERROR;
+		goto sec_cleanup;
+	}
+	if (len_ovfl > UINT_MAX) {
+		XLINK_SECURE_ERR("data len overflow err\n");
+		rc = X_LINK_ERROR;
+		goto sec_cleanup;
+	}
+
+	XLINK_SECURE_DBG("Entry %s chan = %u\n", __func__, chan);
+
+	mutex_lock(&sec_handler->lock);
+	node = find_seqno_chan_list_context(chan, id);
+	mutex_unlock(&sec_handler->lock);
+	if (!node) {
+		XLINK_SECURE_ERR("ERROR: failed to find_seqno_chan_list_context\n");
+		rc = X_LINK_ERROR;
+		goto sec_cleanup;
+	}
+
+	local_seq = node->tx_ctr;
+	local_seq++;
+
+	XLINK_SECURE_DBG(" wr on chan = %u local_seq = %llu\n", chan, local_seq);
+
+	if (handle->dev_type == VPUIP_DEVICE) {
+		rc = xlink_secure_uvirt_to_dmabuf((u8 *)data_in, &dmabuf);
+		if (rc != X_LINK_SUCCESS) {
+			XLINK_SECURE_ERR("\nxlink_secure_get_dmabuf error\n");
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+		if (dmabuf) {
+			rc = xlink_secure_dmabuf_to_paddr(dmabuf, DMA_FROM_DEVICE, &phys_addr);
+			if (rc != X_LINK_SUCCESS) {
+				XLINK_SECURE_ERR("\nxlink_secure_get_phys_addr_from_sg failed\n");
+				goto sec_cleanup;
+			}
+			XLINK_SECURE_DBG("\nSecure_write_phy_addr_from_sg = %llx\n", phys_addr);
+		} else {
+			XLINK_SECURE_ERR("\ndmabuf is NULL\n");
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+		data_out_frame  = kmalloc(size + METADATA_SIZE + AES_GCM_TAGLEN, GFP_KERNEL);
+		if (!data_out_frame) {
+			XLINK_SECURE_ERR("write kmalloc failed\n");
+			return -ENOMEM;
+		}
+	} else {
+		data_frame = (u8 *)data_in;
+	}
+
+	//Initialize AAD pointer
+	if (handle->dev_type == VPUIP_DEVICE)
+		gcm_aad = (struct aad_format *)data_out_frame;
+	else
+		gcm_aad = (struct aad_format *)data_frame;
+
+	//Initialize TAG pointer
+	gcm_tag = data_frame + sizeof(struct header) + sizeof(frame.sequence) + size;
+
+	//construct secure xlink header
+	data_header.msg_type = ARM_SECURE;
+	data_header.ver_maj = 1;
+	data_header.ver_min = 0;
+	data_header.len = size;
+
+	//construct AAD
+	gcm_aad->seq = local_seq;
+	memcpy(&gcm_aad->head, &data_header, sizeof(struct header));
+
+	//construct IV
+	node->w_gcm_iv->counter = local_seq;
+
+	if (handle->dev_type == VPUIP_DEVICE) {
+		data_out_paddr = dma_map_single(&xlink->pdev->dev, data_out_frame,
+						frame_len, DMA_BIDIRECTIONAL);
+		if (dma_mapping_error(&xlink->pdev->dev, data_out_paddr)) {
+			XLINK_SECURE_ERR("dma_map_single failed\n");
+			data_out_paddr = 0;
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+		aad_paddr = data_out_paddr;
+
+		if (0 != (xlink_aead_encrypt(sec_multidev[id].tfm, node->w_aead_req,
+					     (u8 *)node->w_gcm_iv,
+						(u8 *)gcm_aad, aad_paddr, AES_GCM_AADLEN,
+						(NULL),
+						(phys_addr),
+						(data_out_frame + METADATA_SIZE),
+						(data_out_paddr + METADATA_SIZE),
+						size, gcm_tag))) {
+			XLINK_SECURE_ERR("xlink_aead_encrypt error on chan = %d\n", chan);
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+		dma_unmap_single(&xlink->pdev->dev, data_out_paddr, frame_len, DMA_BIDIRECTIONAL);
+		data_out_paddr = 0;
+
+		//Copy header and seqno to data_frame.
+		memcpy(data_out_frame, &data_header, sizeof(struct header));
+		memcpy(data_out_frame + sizeof(struct header), &local_seq, sizeof(frame.sequence));
+		if (frame_len > (512 - 28))
+			rc = xlink_write_data(&local_handle, chan, data_out_frame, frame_len);
+		else
+			rc = xlink_write_control_data(&local_handle, chan,
+						      data_out_frame, frame_len);
+		if (rc != X_LINK_SUCCESS) {
+			XLINK_SECURE_ERR("write error rc=%d on chan = %d\n", rc, chan);
+			goto sec_cleanup;
+		}
+	} else {
+		data_paddr = dma_map_single(&xlink->pdev->dev, data_frame,
+					    frame_len, DMA_BIDIRECTIONAL);
+		if (dma_mapping_error(&xlink->pdev->dev, data_paddr)) {
+			XLINK_SECURE_ERR("dma_map_single failed\n");
+			data_paddr = 0;
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+		aad_paddr = data_paddr;
+		if (0 != (xlink_aead_encrypt(sec_multidev[id].tfm, node->w_aead_req,
+					     (u8 *)node->w_gcm_iv,
+						(u8 *)gcm_aad, aad_paddr, AES_GCM_AADLEN,
+						(data_frame + METADATA_SIZE),
+						(data_paddr + METADATA_SIZE),
+						(data_frame + METADATA_SIZE),
+						(data_paddr + METADATA_SIZE),
+						size, gcm_tag))) {
+			XLINK_SECURE_ERR("xlink_aead_encrypt error on chan = %d\n", chan);
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+		dma_unmap_single(&xlink->pdev->dev, data_paddr, frame_len, DMA_BIDIRECTIONAL);
+		data_paddr = 0;
+
+		//Copy header and seqno to data_frame.
+		memcpy(data_frame, &data_header, sizeof(struct header));
+		memcpy(data_frame + sizeof(struct header), &local_seq, sizeof(frame.sequence));
+		if (frame_len > (512 - 28))
+			rc = xlink_write_data(&local_handle, chan, data_frame, frame_len);
+		else
+			rc = xlink_write_control_data(&local_handle, chan, data_frame, frame_len);
+		if (rc != X_LINK_SUCCESS) {
+			XLINK_SECURE_ERR("write error rc=%d on chan = %d\n", rc, chan);
+			goto sec_cleanup;
+		}
+	}
+
+	node->tx_ctr++;
+
+sec_cleanup:
+	XLINK_SECURE_DBG(" wrtie_sec_cleanup\n");
+	if (data_paddr)
+		dma_unmap_single(&xlink->pdev->dev, data_paddr, frame_len, DMA_BIDIRECTIONAL);
+	if (data_out_paddr)
+		dma_unmap_single(&xlink->pdev->dev, data_out_paddr, frame_len, DMA_BIDIRECTIONAL);
+	XLINK_SECURE_DBG("write Exit chan=%d rc=%d\n", chan, rc);
+	return rc;
+}
+EXPORT_SYMBOL(xlink_secure_write_data);
+
+enum xlink_error xlink_secure_read_data(struct xlink_handle *handle,
+					u16 chan, uint8_t **data_in, uint32_t *size)
+{
+	u8 *read_data = NULL;
+	struct frame_format frame;
+	struct header data_header;
+	struct aad_format *gcm_aad = NULL;
+	enum xlink_error rc = X_LINK_SUCCESS;
+	size_t data_len;
+	u32 min_data_len = 0;
+	u64 local_seq = 0;
+	dma_addr_t aad_paddr = 0, data_paddr = 0, data_in_paddr = 0;
+	int id = 0;
+	struct seqno_chan *node;
+	struct xlink_handle local_handle;
+	struct xlnk_sec_handle *sec_handler;
+	struct dma_buf *dmabuf = NULL;
+	phys_addr_t phys_addr;
+
+	min_data_len = sizeof(struct header) + sizeof(frame.sequence)
+				+ AES_GCM_TAGLEN;
+
+	XLINK_SECURE_DBG("Entry chan=%d\n", chan);
+
+	local_handle.sw_device_id = handle->sw_device_id;
+	local_handle.dev_type = HOST_DEVICE;
+	sec_handler = find_secure_handler(handle);
+	if (!sec_handler) {
+		XLINK_SECURE_ERR("sec_handler not found\n");
+		rc = X_LINK_ERROR;
+		goto sec_cleanup;
+	}
+
+	id = xlink_secure_find_sec_device(handle);
+	if (id < 0) {
+		XLINK_SECURE_ERR("Error Could not find sec device\n");
+		rc = X_LINK_ERROR;
+		goto sec_cleanup;
+	}
+
+	mutex_lock(&sec_handler->lock);
+	node = find_seqno_chan_list_context(chan, id);
+	mutex_unlock(&sec_handler->lock);
+	if (!node) {
+		XLINK_SECURE_ERR("ERROR: failed to find_seqno_chan_list_context\n");
+		rc = X_LINK_ERROR;
+		goto sec_cleanup;
+	}
+	XLINK_SECURE_DBG("\nread_data_in_user_usrvaddr_offset = %llu\n", (u64)(*data_in) % 4096);
+
+	if (handle->dev_type == VPUIP_DEVICE) {
+		if (node->xlink_read == 1 && (!data_in || (!(*data_in)))) {
+			XLINK_SECURE_ERR("\nread_user_buffer_NULL\n");
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+	}
+
+	if (handle->dev_type == VPUIP_DEVICE) {/*Slice Secure*/
+		if (!data_in && (!(*data_in))) {
+			XLINK_SECURE_DBG("\n\n\nnode->cipher_data NULL\n\n\n");
+			rc = xlink_read_data(&local_handle, chan, &read_data, size);
+			if (rc != X_LINK_SUCCESS || (*size <= min_data_len) || !read_data) {
+				if (rc == X_LINK_TIMEOUT) {
+					XLINK_SECURE_DBG("read error %d on chan=%d\n", rc, chan);
+					XLINK_SECURE_DBG("len %d\n", *size);
+					XLINK_SECURE_DBG("read_data_addr=0x%X\n", *read_data);
+				} else {
+					XLINK_SECURE_ERR("read error %d on chan=%d\n", rc, chan);
+					XLINK_SECURE_ERR("len %d\n", *size);
+					XLINK_SECURE_ERR("read_data_addr=0x%X\n", *read_data);
+				}
+				rc = X_LINK_ERROR;
+				goto sec_cleanup;
+			}
+			node->cipher_data = read_data;
+			node->cipher_data_size = *size;
+			node->xlink_read = 1;
+		} else {
+			XLINK_SECURE_DBG("\n\n\nnode->cipher_data_not_NULL\n\n\n");
+			read_data = node->cipher_data;
+			*size = node->cipher_data_size;
+		}
+	} else {/*ARM Secure*/
+		rc = xlink_read_data(&local_handle, chan, &read_data, size);
+		if (rc != X_LINK_SUCCESS || (*size <= min_data_len) || !read_data) {
+			if (rc == X_LINK_TIMEOUT) {
+				XLINK_SECURE_DBG("read error %d on chan=%d\n", rc, chan);
+				XLINK_SECURE_DBG("len %d\n", *size);
+				XLINK_SECURE_DBG("read_data_addr=0x%X\n", *read_data);
+			} else {
+				XLINK_SECURE_ERR("read error %d on chan=%d\n", rc, chan);
+				XLINK_SECURE_ERR("len %d\n", *size);
+				XLINK_SECURE_ERR("read_data_addr=0x%X\n", *read_data);
+			}
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+	}
+	XLINK_SECURE_DBG("size=%d\n", *size);
+
+	//read data_header and sequence/counter
+	memcpy(&data_header, read_data, sizeof(struct header));
+	memcpy(&local_seq, (read_data + sizeof(struct header)), sizeof(frame.sequence));
+
+	data_len = data_header.len;
+	if ((data_len + min_data_len) != *size) {
+		XLINK_SECURE_ERR("outlen %lu != inlen %u & error on chan=%u\n",
+				 data_len, (*size - min_data_len), chan);
+		rc = X_LINK_ERROR;
+		goto sec_cleanup;
+	}
+
+	if (handle->dev_type == VPUIP_DEVICE) {
+		if (!data_in && !(*data_in)) {
+			*size = data_len;
+			XLINK_SECURE_DBG("MT Slice secure size=%d return\n", *size);
+			rc = X_LINK_SUCCESS;
+			goto sec_cleanup;
+		}
+		XLINK_SECURE_DBG("\n\n*data_in_not_NULL\n\n");
+	}
+
+#ifdef ENABLE_SEQNO_ERROR_CHECK
+	if ((node->rx_ctr + 1) != local_seq) {
+		XLINK_SECURE_ERR("ERROR: received packet not in order\n");
+		XLINK_SECURE_ERR("ERROR: received seq_no = %llu expected seq_no = %llu\n"
+				, local_seq, node->rx_ctr);
+		rc = xlink_release_data(&local_handle, chan, NULL);
+		if (rc != X_LINK_SUCCESS)
+			XLINK_SECURE_ERR("ERROR: xlink secure release fail chan = %d\n", chan);
+		rc = X_LINK_ERROR;
+		goto sec_cleanup;
+	}
+#endif
+
+	XLINK_SECURE_DBG(" rd on chan = %u local_seq = %llu\n", chan, local_seq);
+	node->rx_ctr++;
+
+	if (handle->dev_type == VPUIP_DEVICE) {
+		rc = xlink_secure_uvirt_to_dmabuf(*data_in, &dmabuf);
+		if (rc != X_LINK_SUCCESS) {
+			XLINK_SECURE_ERR("\nxlink_secure_get_dmabuf error\n");
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+		if (dmabuf) {
+			rc = xlink_secure_dmabuf_to_paddr(dmabuf, DMA_FROM_DEVICE, &phys_addr);
+			if (rc != X_LINK_SUCCESS) {
+				XLINK_SECURE_ERR("\nxlink_secure_get_phys_addr_from_sg failed\n");
+				goto sec_cleanup;
+			}
+			XLINK_SECURE_DBG("\nSecure_read_phy_addr_from_sg = %llx\n", phys_addr);
+		} else {
+			XLINK_SECURE_ERR("\ndmabuf is NULL\n");
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+	}
+
+	//Initialise AAD pointer
+	gcm_aad = (struct aad_format *)read_data;
+
+	//construct AAD
+	gcm_aad->seq = local_seq;
+	memcpy(&gcm_aad->head, &data_header, sizeof(struct header));
+	//construct IV
+	node->r_gcm_iv->counter = local_seq;
+
+	if (handle->dev_type == VPUIP_DEVICE) {
+		XLINK_SECURE_DBG("\n\n*Slice_secure_decrypt\n\n");
+		data_in_paddr = dma_map_single(&xlink->pdev->dev, read_data,
+					       *size, DMA_TO_DEVICE);
+		if (dma_mapping_error(&xlink->pdev->dev, data_in_paddr)) {
+			XLINK_SECURE_ERR("dma_map_single failed\n");
+			data_in_paddr = 0;
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+		aad_paddr = data_in_paddr;
+
+		if (0 != (xlink_aead_decrypt(sec_multidev[id].tfm, node->r_aead_req,
+					     (u8 *)node->r_gcm_iv,
+						(u8 *)gcm_aad, aad_paddr, AES_GCM_AADLEN,
+						(read_data + METADATA_SIZE),
+						(data_in_paddr + METADATA_SIZE),
+						(NULL),
+						(phys_addr),
+						data_len, read_data + METADATA_SIZE + data_len))) {
+			XLINK_SECURE_ERR("xlink_aead_decrypt error chan =%d\n", chan);
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+		dma_unmap_single(&xlink->pdev->dev, data_in_paddr, *size, DMA_TO_DEVICE);
+		data_in_paddr = 0;
+	} else {
+		XLINK_SECURE_DBG("\n\n*ST/ARM_decrypt\n\n");
+		data_paddr = dma_map_single(&xlink->pdev->dev, read_data,
+					    *size, DMA_BIDIRECTIONAL);
+		if (dma_mapping_error(&xlink->pdev->dev, data_paddr)) {
+			XLINK_SECURE_ERR("dma_map_single failed\n");
+			data_paddr = 0;
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+		aad_paddr = data_paddr;
+		if (0 != (xlink_aead_decrypt(sec_multidev[id].tfm, node->r_aead_req,
+					     (u8 *)node->r_gcm_iv,
+						(u8 *)gcm_aad, aad_paddr, AES_GCM_AADLEN,
+						(read_data + METADATA_SIZE),
+						(data_paddr + METADATA_SIZE),
+						(read_data + METADATA_SIZE),
+						(data_paddr + METADATA_SIZE),
+						data_len, read_data + METADATA_SIZE + data_len))) {
+			XLINK_SECURE_ERR("xlink_aead_decrypt error chan =%d\n", chan);
+			rc = X_LINK_ERROR;
+			goto sec_cleanup;
+		}
+		dma_unmap_single(&xlink->pdev->dev, data_paddr, *size, DMA_BIDIRECTIONAL);
+		data_paddr = 0;
+	}
+
+	node->cipher_data = NULL;
+	node->xlink_read = 0;
+
+	*size = data_len;
+	if (handle->dev_type != VPUIP_DEVICE)
+		*data_in = read_data;
+
+	XLINK_SECURE_DBG("\n\n*decrypt_done\n\n");
+
+sec_cleanup:
+	XLINK_SECURE_DBG("\n\n*read_cleanup_start\n\n");
+	if (data_paddr)
+		dma_unmap_single(&xlink->pdev->dev, data_paddr, *size, DMA_BIDIRECTIONAL);
+	if (data_in_paddr)
+		dma_unmap_single(&xlink->pdev->dev, data_in_paddr, *size, DMA_TO_DEVICE);
+	XLINK_SECURE_DBG("Exit chan=%d rc=%d\n", chan, rc);
+	return rc;
+}
+EXPORT_SYMBOL(xlink_secure_read_data);
+
+enum xlink_error xlink_secure_release_data(struct xlink_handle *handle,
+					   u16 chan, uint8_t * const data_addr)
+{
+	XLINK_SECURE_DBG("Entry chan=%d\n", chan);
+	return X_LINK_SUCCESS;
+}
+EXPORT_SYMBOL(xlink_secure_release_data);
+
+enum xlink_error xlink_secure_disconnect(struct xlink_handle *handle)
+{
+	struct xlink_handle local_handle;
+
+	XLINK_SECURE_DBG("Entry\n");
+	local_handle.sw_device_id = handle->sw_device_id;
+	local_handle.dev_type = HOST_DEVICE;
+	return xlink_disconnect(&local_handle);
+}
+EXPORT_SYMBOL(xlink_secure_disconnect);
+
+/* Device tree driver match. */
+static const struct of_device_id xlink_secure_of_match[] = {
+	{
+		.compatible = "intel,xlink-secure",
+	},
+	{}
+};
+
+/* The xlink secure driver is a platform device. */
+static struct platform_driver xlink_secure_driver = {
+	.probe = xlink_secure_probe,
+	.remove = xlink_secure_remove,
+	.driver = {
+			.name = DRV_NAME,
+			.of_match_table = xlink_secure_of_match,
+		},
+};
+
+/*
+ * The remote host system will need to create an xlink secure platform
+ * device for the platform driver to match with
+ */
+#ifndef CONFIG_XLINK_SECURE_LOCAL_HOST
+static struct platform_device pdev;
+void xlink_secure_release(struct device *dev) { return; }
+#endif
+
+static int xlink_secure_init(void)
+{
+	int rc = 0;
+
+	rc = platform_driver_register(&xlink_secure_driver);
+#ifndef CONFIG_XLINK_SECURE_LOCAL_HOST
+	pdev.dev.release = xlink_secure_release;
+	pdev.name = DRV_NAME;
+	pdev.id = -1;
+	if (!rc) {
+		rc = platform_device_register(&pdev);
+		if (rc)
+			platform_driver_unregister(&xlink_secure_driver);
+	}
+#endif
+	return rc;
+}
+module_init(xlink_secure_init);
+
+static void xlink_secure_exit(void)
+{
+#ifndef CONFIG_XLINK_SECURE_LOCAL_HOST
+	platform_device_unregister(&pdev);
+#endif
+	platform_driver_unregister(&xlink_secure_driver);
+}
+module_exit(xlink_secure_exit);
+
+MODULE_DESCRIPTION("Xlink-Secure Kernel Driver");
+MODULE_AUTHOR("Sagar Patil <sagarp.patil@intel.com>");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/misc/xlink-secure/xlink_aead_api.c b/drivers/misc/xlink-secure/xlink_aead_api.c
new file mode 100644
index 000000000000..74c1fe5f4422
--- /dev/null
+++ b/drivers/misc/xlink-secure/xlink_aead_api.c
@@ -0,0 +1,162 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Xlink Secure Driver.
+ *
+ * Copyright (C) 2020-2021 Intel Corporation
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/err.h>
+#include <linux/scatterlist.h>
+#include <crypto/aead.h>
+
+#include "xlink_aead_api.h"
+#include "xlink-secure-defs.h"
+
+int xlink_aead_encrypt(struct crypto_aead *tfm, struct aead_request *aead_req,
+		       u8 *iv, u8 *aad, dma_addr_t aad_paddr, size_t aad_len,
+		u8 const *data_in, dma_addr_t data_in_paddr,
+		u8 const *data_out, dma_addr_t data_out_paddr, size_t data_len, u8 *tag)
+{
+	struct scatterlist sg_in[2], sg_out[3];
+	int err = 0;
+	size_t tag_len = crypto_aead_authsize(tfm);
+	DECLARE_CRYPTO_WAIT(wait);
+
+	XLINK_SECURE_DBG("Entry tag_len=%lu data_len=%lu aad_len=%lu\n",
+			 tag_len, data_len, aad_len);
+
+	if (data_len == 0) {
+		XLINK_SECURE_ERR("invalid data_len\n");
+		err = -EINVAL;
+		goto err_out;
+	}
+
+	sg_init_table(sg_in, 2);
+	sg_set_buf(&sg_in[0], aad, aad_len); //set sg_in buf for aad in 1st sgl (sg_in[0])
+	sg_in[0].dma_address = aad_paddr;
+	sg_in[0].dma_length = aad_len;
+	sg_set_buf(&sg_in[1], data_in, data_len);
+	sg_in[1].dma_address = data_in_paddr;
+	sg_in[1].dma_length = data_len;
+
+	sg_init_table(sg_out, 3);
+	sg_set_buf(&sg_out[0], aad, aad_len); //set sg_in buf for aad in 1st sgl (sg_in[0])
+	sg_out[0].dma_address = aad_paddr;
+	sg_out[0].dma_length = aad_len;
+	sg_set_buf(&sg_out[1], data_out, data_len);
+	sg_out[1].dma_address = data_out_paddr;
+	sg_out[1].dma_length = data_len;
+	sg_set_buf(&sg_out[2], tag, tag_len);
+
+	aead_request_set_tfm(aead_req, tfm);
+	aead_request_set_crypt(aead_req, sg_in, sg_out, data_len, iv);
+	aead_request_set_ad(aead_req, sg_in[0].length);
+
+	aead_request_set_callback(aead_req,
+				  CRYPTO_TFM_REQ_MAY_BACKLOG,
+				  crypto_req_done, &wait);
+
+	err = crypto_aead_encrypt(aead_req);
+	XLINK_SECURE_DBG("crypto wait start\n");
+	err = crypto_wait_req(err, &wait);
+	XLINK_SECURE_DBG("crypto wait end\n");
+	if (err != 0) {
+		XLINK_SECURE_ERR("crypto_aead_encrypt failed\n");
+		goto err_out;
+	}
+
+err_out:
+	XLINK_SECURE_DBG("xlink_aead_encrypt_err_out = %d\n", err);
+
+	return err;
+}
+
+int xlink_aead_decrypt(struct crypto_aead *tfm, struct aead_request *aead_req,
+		       u8 *iv, u8 *aad, dma_addr_t aad_paddr, size_t aad_len,
+		u8 *data_in, dma_addr_t data_in_paddr,
+		u8 *data_out, dma_addr_t data_out_paddr, size_t data_len, u8 *tag)
+{
+	size_t tag_len = crypto_aead_authsize(tfm);
+	struct scatterlist sg_in[3], sg_out[2];
+	int err = 0;
+	DECLARE_CRYPTO_WAIT(wait);
+
+	XLINK_SECURE_DBG("Entry tag_len=%lu data_len=%lu aad_len=%lu\n",
+			 tag_len, data_len, aad_len);
+
+	if (data_len == 0) {
+		XLINK_SECURE_ERR("invalid data_len\n");
+		err = -EINVAL;
+		goto err_out;
+	}
+
+	sg_init_table(sg_in, 3);
+	sg_set_buf(&sg_in[0], aad, aad_len);
+	sg_in[0].dma_address = aad_paddr;
+	sg_in[0].dma_length = aad_len;
+	sg_set_buf(&sg_in[1], data_in, data_len);
+	sg_in[1].dma_address = data_in_paddr;
+	sg_in[1].dma_length = data_len;
+	sg_set_buf(&sg_in[2], tag, tag_len);
+
+	sg_init_table(sg_out, 2);
+	sg_set_buf(&sg_out[0], aad, aad_len);
+	sg_out[0].dma_address = aad_paddr;
+	sg_out[0].dma_length = aad_len;
+	sg_set_buf(&sg_out[1], data_out, data_len);
+	sg_out[1].dma_address = data_out_paddr;
+	sg_out[1].dma_length = data_len;
+
+	aead_request_set_tfm(aead_req, tfm);
+	aead_request_set_crypt(aead_req, sg_in, sg_out, data_len + tag_len, iv);
+	aead_request_set_ad(aead_req, sg_in[0].length);
+
+	aead_request_set_callback(aead_req,
+				  CRYPTO_TFM_REQ_MAY_BACKLOG,
+				  crypto_req_done, &wait);
+
+	err = crypto_aead_decrypt(aead_req);
+	XLINK_SECURE_DBG("crypto wait start\n");
+	err = crypto_wait_req(err, &wait);
+	XLINK_SECURE_DBG("crypto wait end\n");
+	if (err != 0) {
+		XLINK_SECURE_ERR("crypto_aead_decrypt failed\n");
+		goto err_out;
+	}
+
+err_out:
+	XLINK_SECURE_DBG("err_out = %d\n", err);
+
+	return err;
+}
+
+struct crypto_aead *
+xlink_aead_setup_encrypt(const char *alg, size_t tag_len)
+{
+	struct crypto_aead *tfm;
+	int err;
+
+	tfm = crypto_alloc_aead(alg, 0, 0);
+	if (IS_ERR(tfm))
+		return tfm;
+
+	crypto_aead_clear_flags(tfm, CRYPTO_TFM_NEED_KEY);
+
+	err = crypto_aead_setauthsize(tfm, tag_len);
+	if (err)
+		goto free_aead;
+
+	return tfm;
+
+free_aead:
+	crypto_free_aead(tfm);
+	return ERR_PTR(err);
+}
+
+void xlink_aead_free(struct crypto_aead *tfm)
+{
+	crypto_free_aead(tfm);
+}
diff --git a/drivers/misc/xlink-secure/xlink_aead_api.h b/drivers/misc/xlink-secure/xlink_aead_api.h
new file mode 100644
index 000000000000..453686cffe90
--- /dev/null
+++ b/drivers/misc/xlink-secure/xlink_aead_api.h
@@ -0,0 +1,29 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+/*
+ * Xlink Secure Driver.
+ *
+ * Copyright (C) 2020-2021 Intel Corporation
+ *
+ */
+
+#ifndef XLINK_AEAD_API_H
+#define XLINK_AEAD_API_H
+
+#include <crypto/aead.h>
+#include <linux/crypto.h>
+
+struct crypto_aead *xlink_aead_setup_encrypt(const char *alg, size_t tag_len);
+
+int xlink_aead_encrypt(struct crypto_aead *tfm, struct aead_request *aead_req,
+		       u8 *iv, u8 *aad, dma_addr_t aad_paddr, size_t aad_len,
+		u8 const *data_in, dma_addr_t data__in_paddr,
+		u8 const *data_out, dma_addr_t data__out_paddr, size_t data_len, u8 *tag);
+
+int xlink_aead_decrypt(struct crypto_aead *tfm, struct aead_request *aead_req,
+		       u8 *iv, u8 *aad, dma_addr_t aad_paddr, size_t aad_len,
+		u8 *data_in, dma_addr_t data__in_paddr,
+		u8 *data_out, dma_addr_t data__out_paddr, size_t data_len, u8 *tag);
+
+void xlink_aead_free(struct crypto_aead *tfm);
+
+#endif /* XLINK_AEAD_API_H */
diff --git a/include/linux/xlink_secure.h b/include/linux/xlink_secure.h
new file mode 100644
index 000000000000..7266727921cc
--- /dev/null
+++ b/include/linux/xlink_secure.h
@@ -0,0 +1,44 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+/*
+ * Xlink Secure Linux Kernel API
+ *
+ * Copyright (C) 2020-2021 Intel Corporation
+ *
+ */
+#ifndef __XLINK_SECURE_H
+#define __XLINK_SECURE_H
+
+#ifdef __cplusplus
+extern "C"{
+#endif
+
+#include <uapi/misc/xlink_secure_uapi.h>
+
+/*XLINK SECURE API'S*/
+enum xlink_error xlink_secure_initialize(void);
+
+enum xlink_error xlink_secure_connect(struct xlink_handle *handle);
+
+enum xlink_error xlink_secure_open_channel(struct xlink_handle *handle,
+					   u16 chan, enum xlink_opmode mode, uint32_t data_size,
+	uint32_t timeout);
+
+enum xlink_error xlink_secure_close_channel(struct xlink_handle *handle,
+					    uint16_t chan);
+
+enum xlink_error xlink_secure_write_data(struct xlink_handle *handle,
+					 u16 chan, uint8_t const *message, uint32_t size);
+
+enum xlink_error xlink_secure_read_data(struct xlink_handle *handle,
+					u16 chan, uint8_t **message, uint32_t *size);
+
+enum xlink_error xlink_secure_release_data(struct xlink_handle *handle,
+					   u16 chan, uint8_t * const data_addr);
+
+enum xlink_error xlink_secure_disconnect(struct xlink_handle *handle);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* __XLINK_SECURE_H */
diff --git a/include/uapi/misc/xlink_secure_data_struct.h b/include/uapi/misc/xlink_secure_data_struct.h
new file mode 100644
index 000000000000..e52079795490
--- /dev/null
+++ b/include/uapi/misc/xlink_secure_data_struct.h
@@ -0,0 +1,163 @@
+/* SPDX-License-Identifier: GPL-2.0+ WITH Linux-syscall-note */
+/*
+ * xlink Linux Kernel API
+ *
+ * Copyright (C) 2020-2021 Intel Corporation
+ *
+ */
+#ifndef __XLINK_SECURE_DATA_STRUCT_H
+#define __XLINK_SECURE_DATA_STRUCT_H
+
+#include <linux/types.h>
+
+#ifdef __KERNEL__
+
+#include <linux/xlink.h>
+#include <linux/mutex.h>
+
+#else
+enum xlink_dev_type {
+	HOST_DEVICE = 0,        /* used when communicating host to host*/
+	VPUIP_DEVICE            /* used when communicating host to vpu ip */
+};
+
+struct xlink_handle {
+	__u32 sw_device_id;               /* identifies a device in the system */
+	enum xlink_dev_type dev_type;   /* determines direction of comms */
+};
+#endif
+
+#define AES_256_KEY_SIZE 32
+#define TLS_FIXED_IV_SIZE 4
+#define NOF_OCS_SLICE 5
+#define NUM_OF_CONNECTIONS 8
+#define NUM_OF_CHANNELS 4096
+
+enum xlnk_sec_conn_status {
+	SECURE_CONNECT_DOWN = 0,
+	SECURE_CONNECT_UP
+};
+
+enum xlnk_sec_chan_status {
+	SECURE_CHANNEL_NOTUSED = 0,
+	SECURE_CHANNEL_USED
+};
+
+enum xlnk_mutex_status {
+	MUTEX_NOT_INITIALISED = 0,
+	MUTEX_INITIALISED
+};
+
+enum ocs_slice_status {
+	SLICE_DISABLED = 0,
+	SLICE_ENABLED
+};
+
+enum sks_prepare_aes {
+	SKS_SKIP_PREPARE_AES = 0,
+	SKS_DO_PREPARE_AES
+};
+
+enum ocs_sks_slot {
+	OCS_SKS_SLOT_0 = 0,
+	OCS_SKS_SLOT_1,
+	OCS_SKS_SLOT_2,
+	OCS_SKS_SLOT_3,
+	OCS_SKS_SLOT_4,
+	OCS_SKS_SLOT_5,
+	OCS_SKS_SLOT_6,
+	OCS_SKS_SLOT_7,
+	OCS_SKS_SLOT_8,
+	OCS_SKS_SLOT_9,
+	OCS_SKS_SLOT_10,
+	OCS_SKS_SLOT_11,
+	OCS_SKS_SLOT_12, /* Reserved for DUK */
+	OCS_SKS_SLOT_13,
+	OCS_SKS_SLOT_14,
+	OCS_SKS_SLOT_15,
+	OCS_SKS_SLOT_16,
+	OCS_SKS_SLOT_17,
+	OCS_SKS_SLOT_18,
+	OCS_SKS_SLOT_19,
+	OCS_SKS_SLOT_20,
+	OCS_SKS_SLOT_21,
+	OCS_SKS_MAX_SLOT = OCS_SKS_SLOT_21
+};
+
+struct sks_info {
+	enum ocs_sks_slot slot;
+	enum ocs_slice_status status;
+	enum sks_prepare_aes prepareAes;
+};
+
+struct ocs_sks_info {
+	struct sks_info slice[NOF_OCS_SLICE];
+};
+
+struct handshake_info {
+	struct xlink_handle handle;
+	__u16 channel;
+};
+
+#ifdef __KERNEL__
+
+struct xlnk_sec_handle {
+	enum xlnk_sec_conn_status conn_flag; // connection flag
+	struct ocs_sks_info ocs_sks;
+	struct handshake_info handshake;
+	uint8_t fixed_iv[TLS_FIXED_IV_SIZE]; // TLS IV
+	struct mutex lock;
+	uint32_t sw_device_id;		/* the sw device id */
+};
+
+//TODO: move members of xlnk_sec_multidev to xlnk_sec_handle
+struct xlnk_sec_multidev {
+	struct device *mem_dev;		/* child device managing the memory region */
+	u32 sw_device_id;		/* the sw device id */
+	struct crypto_aead *tfm;
+};
+
+struct xlnk_sec_chan_hand {
+	struct xlnk_sec_handle *handler; // secure handler
+	uint64_t counter; // counter per channel
+	uint32_t chan_no; // channel number
+	enum xlnk_sec_chan_status used; // handler used
+};
+
+struct sequence {
+	uint8_t explicit_iv[8];
+};
+
+enum msg_type {
+	ARM_SECURE = 0,
+	SLICE_SECURE,
+	PT_SECURE
+};
+
+struct header {
+	uint8_t msg_type;
+	uint8_t ver_maj;
+	uint8_t ver_min;
+	uint32_t len;
+} __attribute__((packed));
+
+struct aad_format {
+	uint64_t seq;				//8 byte sequence
+	struct header head;			//7 byte header
+} __attribute__((packed));
+
+struct iv_format {
+	uint8_t fixed_iv[TLS_FIXED_IV_SIZE];	//4 byte fixed-iv
+//	uint32_t channel_num;			//4 byte implicit-iv
+	uint64_t counter;			//4 byte explicit-iv
+} __attribute__((packed));
+
+struct frame_format {
+	struct header head;			//7 byte header
+	uint64_t sequence;			//8 byte sequence
+	uint8_t const *data;
+	uint8_t *tag;
+} __attribute__((packed));
+
+#endif /* __KERNEL__ */
+#endif /* __XLINK_SECURE_DATA_STRUCT_H */
diff --git a/include/uapi/misc/xlink_secure_uapi.h b/include/uapi/misc/xlink_secure_uapi.h
new file mode 100644
index 000000000000..303580b49247
--- /dev/null
+++ b/include/uapi/misc/xlink_secure_uapi.h
@@ -0,0 +1,94 @@
+/* SPDX-License-Identifier: GPL-2.0+ WITH Linux-syscall-note */
+/*
+ * Xlink Secure Linux Kernel API
+ *
+ * Copyright (C) 2020-2021 Intel Corporation
+ *
+ */
+#ifndef __XLINK_SECURE_UAPI_H
+#define __XLINK_SECURE_UAPI_H
+
+#include <linux/types.h>
+#include "xlink_secure_data_struct.h"
+
+#define XLINK_MAGIC 'x'
+#define XL_SECURE_OPEN_CHANNEL				_IOW(XLINK_MAGIC, 1, void*)
+#define XL_SECURE_READ_DATA				_IOW(XLINK_MAGIC, 2, void*)
+#define XL_SECURE_WRITE_DATA				_IOW(XLINK_MAGIC, 3, void*)
+#define XL_SECURE_CLOSE_CHANNEL			_IOW(XLINK_MAGIC, 4, void*)
+#define XL_SECURE_WRITE_VOLATILE			_IOW(XLINK_MAGIC, 5, void*)
+#define XL_SECURE_READ_TO_BUFFER			_IOW(XLINK_MAGIC, 6, void*)
+#define XL_SECURE_CONNECT					_IOW(XLINK_MAGIC, 7, void*)
+#define XL_SECURE_RELEASE_DATA				_IOW(XLINK_MAGIC, 8, void*)
+#define XL_SECURE_DISCONNECT				_IOW(XLINK_MAGIC, 9, void*)
+#define XL_SECURE_INITIALIZE				_IOW(XLINK_MAGIC, 10, void*)
+#define XL_SECURE_KEY_EXCHANGE				_IOW(XLINK_MAGIC, 11, void*)
+#define XL_SECURE_DISABLE                              _IOW(XLINK_MAGIC, 12, void*)
+
+struct xlinksecureconnect {
+	void *handle;
+	__u32 *return_code;
+};
+
+struct xlinksecureopenchannel {
+	void *handle;
+	__u16 chan;
+	int mode;
+	__u32 data_size;
+	__u32 timeout;
+	__u32 *return_code;
+};
+
+struct xlinksecurewritedata {
+	void *handle;
+	__u16 chan;
+	void const *pmessage;
+	__u32 size;
+	__u32 *return_code;
+};
+
+struct xlinksecurereaddata {
+	void *handle;
+	__u16 chan;
+	void *pmessage;
+	__u32 *size;
+	__u32 *return_code;
+};
+
+struct xlinksecurereadtobuffer {
+	void *handle;
+	__u16 chan;
+	void *pmessage;
+	__u32 *size;
+	__u32 *return_code;
+};
+
+enum xlinksecurekeyexchange_op {
+	KEY_EXCHANGE_MUTEX_LOCK = 0,
+	KEY_EXCHANGE_MUTEX_UNLOCK,
+	KEY_EXCHANGE_GET_INFO,
+	KEY_EXCHANGE_SET_INFO,
+};
+
+struct xlinksecurekeyexchange {
+	void *handle;
+	enum xlinksecurekeyexchange_op op;
+	enum xlnk_sec_conn_status conn_flag; /* connection flag */
+	struct ocs_sks_info ocs_sks;
+	struct handshake_info handshake;
+	__u8 fixed_iv[TLS_FIXED_IV_SIZE]; /* TLS IV */
+	__u32 *return_code;
+};
+
+struct xlinksecurerelease {
+	void *handle;
+	__u16 chan;
+	void *addr;
+	__u32 *return_code;
+};
+
+struct xlinksecuredisable {
+	void *flag;
+};
+
+#endif /* __XLINK_SECURE_UAPI_H */
-- 
2.27.0

