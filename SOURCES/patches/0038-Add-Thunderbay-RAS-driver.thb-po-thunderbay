From cfbffa41c153e78e80fd23e54cd85c5c4a79c571 Mon Sep 17 00:00:00 2001
From: Srikanth Thokala <srikanth.thokala@intel.com>
Date: Mon, 27 Jul 2020 19:20:04 +0530
Subject: [PATCH 038/223] Add Thunderbay RAS driver

This patch adds driver to support Thunderbay RAS functionality

Signed-off-by: Srikanth Thokala <srikanth.thokala@intel.com>
---
 drivers/misc/Kconfig                     |  10 +
 drivers/misc/Makefile                    |   1 +
 drivers/misc/xbay_ras/Makefile           |   6 +
 drivers/misc/xbay_ras/cortex_a53_edac.c  | 410 ++++++++++++++++++++
 drivers/misc/xbay_ras/csram_edac.c       | 301 +++++++++++++++
 drivers/misc/xbay_ras/ras_core.c         | 298 +++++++++++++++
 drivers/misc/xbay_ras/ras_core.h         |  73 ++++
 drivers/misc/xbay_ras/snps_lpddr_edac.c  | 426 +++++++++++++++++++++
 drivers/misc/xbay_ras/snps_pcie_rasdes.c | 460 +++++++++++++++++++++++
 include/linux/xbay_ras.h                 | 106 ++++++
 10 files changed, 2091 insertions(+)
 create mode 100644 drivers/misc/xbay_ras/Makefile
 create mode 100644 drivers/misc/xbay_ras/cortex_a53_edac.c
 create mode 100644 drivers/misc/xbay_ras/csram_edac.c
 create mode 100644 drivers/misc/xbay_ras/ras_core.c
 create mode 100644 drivers/misc/xbay_ras/ras_core.h
 create mode 100644 drivers/misc/xbay_ras/snps_lpddr_edac.c
 create mode 100644 drivers/misc/xbay_ras/snps_pcie_rasdes.c
 create mode 100644 include/linux/xbay_ras.h

diff --git a/drivers/misc/Kconfig b/drivers/misc/Kconfig
index 421c421e1e2a..68876a96a054 100644
--- a/drivers/misc/Kconfig
+++ b/drivers/misc/Kconfig
@@ -445,6 +445,16 @@ config HISI_HIKEY_USB
 	  switching between the dual-role USB-C port and the USB-A host ports
 	  using only one USB controller.
 
+config XBAY_RAS
+	tristate "xBAY RAS Collector Driver"
+	depends on HAS_IOMEM
+	help
+	  This option enables support for XBay RAS Collector driver. This
+	  enables a sysfs interface to read the RAS EDAC information from
+	  various RAS components that are available in the XBAY platforms.
+
+	  If unsure, say N.
+
 source "drivers/misc/c2port/Kconfig"
 source "drivers/misc/eeprom/Kconfig"
 source "drivers/misc/cb710/Kconfig"
diff --git a/drivers/misc/Makefile b/drivers/misc/Makefile
index 69d09a95f9d7..83e7b07d39ca 100644
--- a/drivers/misc/Makefile
+++ b/drivers/misc/Makefile
@@ -57,3 +57,4 @@ obj-$(CONFIG_UACCE)		+= uacce/
 obj-$(CONFIG_XILINX_SDFEC)	+= xilinx_sdfec.o
 obj-$(CONFIG_HISI_HIKEY_USB)	+= hisi_hikey_usb.o
 obj-$(CONFIG_HOST_KMB_TJ)       += Gpio-asm28xx/
+obj-$(CONFIG_XBAY_RAS)          += xbay_ras/
diff --git a/drivers/misc/xbay_ras/Makefile b/drivers/misc/xbay_ras/Makefile
new file mode 100644
index 000000000000..e2c99ddec881
--- /dev/null
+++ b/drivers/misc/xbay_ras/Makefile
@@ -0,0 +1,6 @@
+obj-$(CONFIG_XBAY_RAS) += xbay_ras.o
+xbay_ras-objs += ras_core.o
+xbay_ras-objs += cortex_a53_edac.o
+xbay_ras-objs += csram_edac.o
+xbay_ras-objs += snps_lpddr_edac.o
+xbay_ras-objs += snps_pcie_rasdes.o
diff --git a/drivers/misc/xbay_ras/cortex_a53_edac.c b/drivers/misc/xbay_ras/cortex_a53_edac.c
new file mode 100644
index 000000000000..6b3118439463
--- /dev/null
+++ b/drivers/misc/xbay_ras/cortex_a53_edac.c
@@ -0,0 +1,410 @@
+// SPDX-License-Identifier: GPL-2.0 only
+/*
+ * Intel xBay RAS: CPU EDAC SW
+ *
+ * Copyright (C) 2020 Intel Corporation
+ *
+ * Code used from:
+ *  https://lwn.net/Articles/662208/
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2, as published
+ * by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/cpu.h>
+
+#include "ras_core.h"
+
+#define CPUMERRSR_EL1_INDEX(x, y)	((x) & (y))
+#define CPUMERRSR_EL1_BANK_WAY(x, y)	(((x) >> 18) & (y))
+#define CPUMERRSR_EL1_RAMID(x)		(((x) >> 24) & 0x7f)
+#define CPUMERRSR_EL1_VALID(x)		((x) & (1 << 31))
+#define CPUMERRSR_EL1_REPEAT(x)		(((x) >> 32) & 0x7f)
+#define CPUMERRSR_EL1_OTHER(x)		(((x) >> 40) & 0xff)
+#define CPUMERRSR_EL1_FATAL(x)		((x) & (1UL << 63))
+#define L1_I_TAG_RAM			0x00
+#define L1_I_DATA_RAM			0x01
+#define L1_D_TAG_RAM			0x08
+#define L1_D_DATA_RAM			0x09
+#define L1_D_DIRTY_RAM			0x14
+#define TLB_RAM				0x18
+
+#define L2MERRSR_EL1_CPUID_WAY(x)	(((x) >> 18) & 0xf)
+#define L2MERRSR_EL1_RAMID(x)		(((x) >> 24) & 0x7f)
+#define L2MERRSR_EL1_VALID(x)		((x) & (1 << 31))
+#define L2MERRSR_EL1_REPEAT(x)		(((x) >> 32) & 0xff)
+#define L2MERRSR_EL1_OTHER(x)		(((x) >> 40) & 0xff)
+#define L2MERRSR_EL1_FATAL(x)		((x) & (1UL << 63))
+#define L2_TAG_RAM			0x10
+#define L2_DATA_RAM			0x11
+#define L2_SNOOP_RAM			0x12
+#define L2_DIRTY_RAM			0x14
+#define L2_INCLUSION_PF_RAM		0x18
+
+#define L1_CACHE			0
+#define L2_CACHE			1
+
+#define EDAC_MOD_STR			DRV_NAME
+
+/* Error injectin macros*/
+#define L1_DCACHE_ERRINJ_ENABLE		(1 << 6)
+#define L1_DCACHE_ERRINJ_DISABLE	(~(1 << 6))
+#define L2_DCACHE_ERRINJ_ENABLE		(1 << 29)
+#define L2_DCACHE_ERRINJ_DISABLE	(~(1 << 29))
+#define L2_ECC_PROTECTION		(1 << 22)
+
+static struct cpu_edac_info_t
+	cpu_edac_info[NUM_CACHES];
+
+static inline u64 read_cpumerrsr_el1(void)
+{
+	u64 val;
+
+	asm volatile("mrs %0, s3_1_c15_c2_2" : "=r" (val));
+	return val;
+}
+
+static inline void write_cpumerrsr_el1(u64 val)
+{
+	asm volatile("msr s3_1_c15_c2_2, %0" :: "r" (val));
+}
+
+static inline u64 read_l2merrsr_el1(void)
+{
+	u64 val;
+
+	asm volatile("mrs %0, s3_1_c15_c2_3" : "=r" (val));
+	return val;
+}
+
+static inline void write_l2merrsr_el1(u64 val)
+{
+	asm volatile("msr s3_1_c15_c2_3, %0" :: "r" (val));
+}
+
+static inline void cortex_a53_edac_busy_on_inst(void)
+{
+	asm volatile("isb sy");
+}
+
+static inline void cortex_a53_edac_busy_on_data(void)
+{
+	asm volatile("dsb sy");
+}
+
+static inline void write_l2actrl_el1(u64 val)
+{
+	asm volatile("msr s3_1_c15_c0_0, %0" :: "r" (val));
+	cortex_a53_edac_busy_on_inst();
+}
+
+static inline u64 read_l2actrl_el1(void)
+{
+	u64 val;
+
+	asm volatile("mrs %0, s3_1_c15_c0_0" : "=r" (val));
+	return val;
+}
+
+static inline u64 read_l2ctlr_el1(void)
+{
+	u64 rval;
+
+	asm volatile("mrs %0,  S3_1_C11_C0_2" : "=r" (rval));
+	return rval;
+
+}
+
+static inline u64 read_l1actrl_el1(void)
+{
+	u64 rval;
+
+	asm volatile("mrs %0,  S3_1_C15_C2_0" : "=r" (rval));
+	return rval;
+}
+
+static inline void write_l1actrl_el1(u64 val)
+{
+	asm volatile("msr S3_1_C15_C2_0, %0" :: "r" (val));
+}
+
+static void parse_cpumerrsr(void *arg)
+{
+	struct cpu_edac_info_t *e_sts = &cpu_edac_info[0];
+	u64 val = read_cpumerrsr_el1();
+
+	/* we do not support fatal error handling so far */
+	if (CPUMERRSR_EL1_FATAL(val))
+		return;
+
+	/* check if we have valid error before continuing */
+	if (!CPUMERRSR_EL1_VALID(val))
+		return;
+
+	e_sts->cpu = smp_processor_id();
+	e_sts->repeat_err = CPUMERRSR_EL1_REPEAT(val);
+	e_sts->other_err = CPUMERRSR_EL1_OTHER(val);
+	e_sts->index = CPUMERRSR_EL1_INDEX(val, 0xfff);
+	e_sts->way = CPUMERRSR_EL1_BANK_WAY(val, 0x7);
+	e_sts->ram_id = CPUMERRSR_EL1_RAMID(val);
+
+#ifdef DEBUG_RAS_CPU
+	switch (e_sts->ram_id) {
+	case L1_I_TAG_RAM:
+		pr_debug("'L1-I Tag RAM' (way %d)", e_sts->way);
+		break;
+	case L1_I_DATA_RAM:
+		pr_debug("'L1-I Data RAM' (bank %d)", e_sts->way);
+		break;
+	case L1_D_TAG_RAM:
+		pr_debug("'L1-D Tag RAM' (way %d)", e_sts->way);
+		break;
+	case L1_D_DATA_RAM:
+		pr_debug("'L1-D Data RAM' (bank %d)", e_sts->way);
+		break;
+	case L1_D_DIRTY_RAM:
+		pr_debug("'L1 Dirty RAM'");
+		break;
+	case TLB_RAM:
+		pr_debug("'TLB RAM'");
+		break;
+	default:
+		pr_debug("'unknown'");
+		break;
+	}
+#endif
+
+	write_cpumerrsr_el1(0);
+}
+
+#ifdef DEBUG_RAS_CPU
+static void cortex_a53_parse_l2merrsr_way(u8 ramid, u8 val)
+{
+	switch (ramid) {
+	case L2_TAG_RAM:
+		pr_debug("(way %d)", val);
+		break;
+	case L2_DATA_RAM:
+		pr_debug("(bank %d)", val);
+		break;
+	case L2_SNOOP_RAM:
+		pr_debug("(cpu%d tag, way %d)", val / 2, val % 4);
+		break;
+	}
+}
+#endif
+
+static void parse_l2merrsr(void *arg)
+{
+	struct cpu_edac_info_t *e_sts = &cpu_edac_info[1];
+	u64 val = read_l2merrsr_el1();
+
+	/* we do not support fatal error handling so far */
+	if (L2MERRSR_EL1_FATAL(val))
+		return;
+
+	/* check if we have valid error before continuing */
+	if (!L2MERRSR_EL1_VALID(val))
+		return;
+
+	e_sts->cpu = smp_processor_id();
+	e_sts->repeat_err = L2MERRSR_EL1_REPEAT(val);
+	e_sts->other_err = L2MERRSR_EL1_OTHER(val);
+	e_sts->index = (val >> 3) & 0x3fff;
+	e_sts->ram_id = L2MERRSR_EL1_RAMID(val);
+	e_sts->way = L2MERRSR_EL1_CPUID_WAY(val);
+
+#ifdef DEBUG_RAS_CPU
+	switch (e_sts->ram_id) {
+	case L2_TAG_RAM:
+		pr_debug("'L2 Tag RAM'");
+		break;
+	case L2_DATA_RAM:
+		pr_debug("'L2 Data RAM'");
+		break;
+	case L2_SNOOP_RAM:
+		pr_debug("'L2 Snoop tag RAM'");
+		break;
+	case L2_DIRTY_RAM:
+		pr_debug("'L2 Dirty RAM'");
+		break;
+	case L2_INCLUSION_PF_RAM:
+		pr_debug("'L2 inclusion PF RAM'");
+		break;
+	default:
+		pr_debug("unknown");
+		break;
+	}
+
+	/* cpuid/way bit description is different between A57 and A53 */
+	cortex_a53_parse_l2merrsr_way(e_sts->ram_id, e_sts->way);
+#endif
+
+	write_l2merrsr_el1(0);
+}
+
+static void cortex_a53_edac_check(void)
+{
+	int cpu;
+	struct cpumask cluster_mask, old_mask;
+
+	cpumask_clear(&cluster_mask);
+	cpumask_clear(&old_mask);
+
+	get_online_cpus();
+	for_each_online_cpu(cpu) {
+		/* Check CPU L1 error */
+		smp_call_function_single(cpu, parse_cpumerrsr, NULL, 0);
+		cpumask_copy(&cluster_mask, topology_core_cpumask(cpu));
+		if (cpumask_equal(&cluster_mask, &old_mask))
+			continue;
+		cpumask_copy(&old_mask, &cluster_mask);
+
+		/* Check CPU L2 error */
+		smp_call_function_any(&cluster_mask, parse_l2merrsr, NULL, 0);
+	}
+	put_online_cpus();
+}
+
+#if defined(DEBUG_RAS_CPU) && defined(DEBUG_CPU_HW_INJ)
+static void cortex_a53_edac_inject_L2(void)
+{
+	u64 l2actrl, l2ecc;
+
+	l2ecc = read_l2ctlr_el1();
+	if ((l2ecc & L2_ECC_PROTECTION)) {
+		l2actrl = read_l2actrl_el1();
+		l2actrl = l2actrl | L2_DCACHE_ERRINJ_ENABLE;
+		write_l2actrl_el1(l2actrl);
+		cortex_a53_edac_busy_on_inst();
+	}
+}
+
+static void cortex_a53_edac_inject_L1(void)
+{
+	u64 l1actrl;
+
+	l1actrl = read_l1actrl_el1();
+	l1actrl |= L1_DCACHE_ERRINJ_ENABLE;
+	write_l1actrl_el1(l1actrl);
+	cortex_a53_edac_busy_on_inst();
+}
+
+static ssize_t cortex_a53_inj_L2_err_store(struct device *dev,
+					   struct device_attribute *mattr,
+					   const char *data, size_t count)
+{
+	struct platform_device *pdev = to_pdev(dev);
+
+	dev_info(&pdev->dev, "Injecting L2 Cache Error ..\n");
+	cortex_a53_edac_inject_L2();
+
+	return count;
+}
+
+static ssize_t cortex_a53_inj_L1_err_store(struct device *dev,
+					   struct device_attribute *mattr,
+					   const char *data, size_t count)
+{
+	struct platform_device *pdev = to_pdev(dev);
+
+	dev_info(&pdev->dev, "Injecting L1 Cache Error ..\n");
+	cortex_a53_edac_inject_L1();
+
+	return count;
+}
+
+static DEVICE_ATTR_WO(cortex_a53_inj_L1_err);
+static DEVICE_ATTR_WO(cortex_a53_inj_L2_err);
+#endif
+
+#if defined(DEBUG_RAS_CPU) && defined(DEBUG_CPU_SW_INJ)
+static ssize_t tst_cpu_edac_sw_inj_store(struct device *dev,
+					 struct device_attribute *mattr,
+					 const char *data, size_t count)
+{
+	struct platform_device *pdev = to_pdev(dev);
+	struct cpu_edac_info_t *e_sts = NULL;
+	int cache_id;
+
+	if (strncmp(data, "L1", 2) == 0)
+		cache_id = 0;
+	else if (strncmp(data, "L2", 2) == 0)
+		cache_id = 1;
+	else {
+		dev_err(&pdev->dev, "Invalid options chosen\n");
+		dev_err(&pdev->dev, "L1, L2 are available\n");
+		return -EINVAL;
+	}
+
+	dev_info(&pdev->dev, "Injecting SW Error on CPU Cache L1/L2\n");
+	e_sts = &cpu_edac_info[cache_id];
+
+	e_sts->cpu = 0x01 + cache_id;
+	e_sts->repeat_err = 0x02 + cache_id;
+	e_sts->other_err = 0x03 + cache_id;
+	e_sts->index = 0x02 + cache_id;
+	e_sts->way = 0x03 + cache_id;
+	e_sts->ram_id = 0x08 + (cache_id << 3);
+
+	return count;
+}
+static DEVICE_ATTR_WO(tst_cpu_edac_sw_inj);
+#endif
+static const struct attribute *cortex_a53_edac_attrs[] = {
+#ifdef DEBUG_CPU_HW_INJ
+	&dev_attr_cortex_a53_inj_L1_err.attr,
+	&dev_attr_cortex_a53_inj_L2_err.attr,
+#endif
+#ifdef DEBUG_CPU_SW_INJ
+	&dev_attr_tst_cpu_edac_sw_inj.attr,
+#endif
+	NULL,
+};
+
+#ifdef DEBUG_RAS_CPU
+static const struct attribute_group cortex_a53_edac_attributes = {
+	.attrs = (struct attribute **)cortex_a53_edac_attrs,
+};
+#endif
+
+void xbay_cpu_edac_get_all_info(struct platform_device *pdev,
+				char *buf, int count)
+{
+	cortex_a53_edac_check();
+	memcpy(buf, (char *)cpu_edac_info, count);
+}
+
+void xbay_cpu_edac_clear_all_info(struct platform_device *pdev, int count)
+{
+	memset((char *)cpu_edac_info, 0, count);
+}
+
+int xbay_cortex_a53_edac_probe(struct platform_device *pdev,
+			       struct device_node *np)
+{
+	int err;
+
+	err = sysfs_create_group(&pdev->dev.kobj,
+				 &cortex_a53_edac_attributes);
+	if (err < 0) {
+		dev_err(&pdev->dev,
+			"Failed to create Cortex a53 EDAC sysfs entries\n");
+		return err;
+	}
+
+	dev_info(&pdev->dev,
+		 "ARM Cortex a53 EDAC module probed Successfully\n");
+
+	return 0;
+
+}
diff --git a/drivers/misc/xbay_ras/csram_edac.c b/drivers/misc/xbay_ras/csram_edac.c
new file mode 100644
index 000000000000..25e1b224c39e
--- /dev/null
+++ b/drivers/misc/xbay_ras/csram_edac.c
@@ -0,0 +1,301 @@
+// SPDX-License-Identifier: GPL-2.0 only
+/*
+ * Intel xBay RAS: Synopsys CSRAM ECC SW
+ *
+ * Copyright (C) 2020 Intel Corporation
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2, as published
+ * by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include "ras_core.h"
+
+#define THB_CSRAM_IRQ_NUM	2
+
+/* Register Offsets */
+#define ERR_STATUS	0x00
+#define ERR_MASK	0x08
+#define ERR_SVRTY	0x10
+#define ERR_ACSRAMS_LOG	0x18
+#define ECC_INFO	0x20
+#define ERR_INJ		0x28
+
+#define ERR_STATUS_ERR_MASK	GENMASK(12, 0)
+
+#define ECC_INFO_SBIT_MASK	GENMASK(15, 0)
+#define ECC_INFO_DBIT_MASK	GENMASK(31, 16)
+#define ECC_INFO_DBIT_SHIFT	16
+
+#define ERR_INJ_PARITY	BIT(11)
+#define ERR_INJ_DEC_BG	BIT(7)
+#define ERR_INJ_DEC_FG	BIT(6)
+#define ERR_INJ_BG	BIT(5)
+#define ERR_INJ_FG	BIT(4)
+
+enum {
+	NON_FATAL,
+	FATAL,
+};
+
+static struct csram_edac_status_t
+	csram_edac_status[THB_CSRAM_BANK_NUM];
+static void __iomem
+	*csram_edac_base[THB_CSRAM_BANK_NUM];
+static int csram_edac_irq[THB_CSRAM_IRQ_NUM];
+static u32 num_banks;
+
+#if defined(DEBUG_RAS_CSRAM) && defined(DEBUG_CSRAM_HW_INJ)
+static void csram_edac_print_info(struct platform_device *pdev)
+{
+	struct csram_edac_status_t *e_sts;
+	int bank_num;
+
+	for (bank_num = 0; bank_num < num_banks; bank_num++) {
+		e_sts = &csram_edac_status[bank_num];
+
+		dev_dbg(&pdev->dev, "CSRAM Bank %d Statistics :\n", bank_num);
+		dev_dbg(&pdev->dev, "SBIT: %d DBIT: %d\n",
+				     e_sts->sbit_cnt, e_sts->dbit_cnt);
+		dev_dbg(&pdev->dev, "Error @Acsramess: %llx\n",
+				     e_sts->err_acsramess);
+		dev_dbg(&pdev->dev, "Error status: %08x\n",
+				     e_sts->err_status);
+	}
+}
+#endif
+
+static int csram_edac_get_err_info(struct platform_device *pdev, int irq)
+{
+	void __iomem *base = NULL;
+	struct csram_edac_status_t *e_sts;
+	u64 val;
+	int bank_num;
+	enum error_type err = NO_ERR;
+
+	if (csram_edac_irq[FATAL] == irq)
+		err = UNCORR_ERR;
+	else
+		err = CORR_ERR;
+
+	for (bank_num = 0; bank_num < num_banks; bank_num++) {
+		base = csram_edac_base[bank_num];
+		e_sts = &csram_edac_status[bank_num];
+
+		/* Read ECC Info */
+		val = readl(base + ECC_INFO);
+		e_sts->sbit_cnt = val & ECC_INFO_SBIT_MASK;
+		e_sts->dbit_cnt = val &
+				  (ECC_INFO_DBIT_MASK >> ECC_INFO_DBIT_SHIFT);
+
+		/* Read ACSRAM log */
+		e_sts->err_acsramess = readl(base + ERR_ACSRAMS_LOG);
+
+		/* Read error status */
+		val = readl(base + ERR_STATUS);
+		e_sts->err_status = val & ERR_STATUS_ERR_MASK;
+
+		/* Clear Error */
+		if (val)
+			writel(val, base + ERR_STATUS);
+	}
+
+	return err;
+}
+
+static irqreturn_t csram_edac_handle_irq(int irq, void *data)
+{
+	int err = 0;
+	struct platform_device *pdev = (struct platform_device *)data;
+
+	dev_dbg(&pdev->dev, "CSRAM Interrupt %d raised\n", irq);
+
+	err = csram_edac_get_err_info(pdev, irq);
+	dev_dbg(&pdev->dev, "CSRAM Error type %d", err);
+	xbay_ras_clear_interrupt(irq);
+	xbay_pcie_report_internal_error(err);
+
+	return IRQ_HANDLED;
+}
+
+#if defined(DEBUG_RAS_CSRAM) && defined(DEBUG_CSRAM_HW_INJ)
+static ssize_t tst_csram_edac_inj_error_store(struct device *dev,
+					      struct device_attribute *mattr,
+					      const char *data, size_t count)
+{
+	struct platform_device *pdev = to_pdev(dev);
+	u32 inj_error_val = 0;
+
+	if (strncmp(data, "Parity", 6) == 0)
+		inj_error_val = ERR_INJ_PARITY;
+	else if (strncmp(data, "DecBG", 5) == 0)
+		inj_error_val = ERR_INJ_DEC_BG;
+	else if (strncmp(data, "DecFG", 5) == 0)
+		inj_error_val = ERR_INJ_DEC_FG;
+	else if (strncmp(data, "BG", 2) == 0)
+		inj_error_val = ERR_INJ_BG;
+	else if (strncmp(data, "FG", 2) == 0)
+		inj_error_val = ERR_INJ_FG;
+	else {
+		dev_err(&pdev->dev, "Invalid option chosen\n");
+		return 0;
+	}
+
+	dev_dbg(&pdev->dev, "Injecting %08x error on CSRAM ...\n",
+			     inj_error_val);
+	writel(inj_error_val, csram_edac_base[0] + ERR_INJ);
+
+	return count;
+}
+static DEVICE_ATTR_WO(tst_csram_edac_inj_error);
+#endif
+
+#if defined(DEBUG_RAS_CSRAM) && defined(DEBUG_CSRAM_SW_INJ)
+static ssize_t tst_csram_edac_sw_inj_store(struct device *dev,
+					   struct device_attribute *mattr,
+					   const char *data, size_t count)
+{
+	struct platform_device *pdev = to_pdev(dev);
+	struct csram_edac_status_t *e_sts = NULL;
+	int bank_num;
+	bool se = false;
+
+	if (strncmp(data, "SE_0", 4) == 0) {
+		bank_num = 0; se = true;
+	} else if (strncmp(data, "DE_0", 4) == 0) {
+		bank_num = 0; se = false;
+	} else if (strncmp(data, "SE_3", 4) == 0) {
+		bank_num = 3; se = true;
+	} else if (strncmp(data, "DE_3", 4) == 0) {
+		bank_num = 3; se = false;
+	} else {
+		dev_err(&pdev->dev, "Invalid options chosen\n");
+		dev_err(&pdev->dev, "SE_0, DE_0, SE_3, DE_3 are available\n");
+		return -EINVAL;
+	}
+
+	dev_info(&pdev->dev, "Injecting SW Error on CSRAM Bank%d\n",
+		 bank_num);
+
+	e_sts = &csram_edac_status[bank_num];
+	if (se)
+		e_sts->sbit_cnt = 0x02 + bank_num;
+	else
+		e_sts->dbit_cnt = 0x03 + bank_num;
+	e_sts->err_acsramess = 0x5a5a5a + bank_num;
+	e_sts->err_status = 0xa5a5 + bank_num;
+
+	return count;
+}
+static DEVICE_ATTR_WO(tst_csram_edac_sw_inj);
+#endif
+
+#ifdef DEBUG_RAS_CSRAM
+static const struct attribute *csram_edac_inject_attrs[] = {
+#ifdef DEBUG_CSRAM_HW_INJ
+	&dev_attr_tst_csram_edac_inj_error.attr,
+#endif
+#ifdef DEBUG_CSRAM_SW_INJ
+	&dev_attr_tst_csram_edac_sw_inj.attr,
+#endif
+	NULL,
+};
+#endif
+
+#ifdef DEBUG_RAS_CSRAM
+static const struct attribute_group csram_edac_attributes = {
+	.attrs = (struct attribute **)csram_edac_inject_attrs,
+};
+#endif
+
+void xbay_csram_edac_get_all_info(struct platform_device *pdev,
+				  char *buf, int count)
+{
+	memcpy(buf, (char *)csram_edac_status, count);
+}
+
+void xbay_csram_edac_clear_all_info(struct platform_device *pdev, int count)
+{
+	memset((char *)csram_edac_status, 0, count);
+}
+
+int xbay_csram_edac_probe(struct platform_device *pdev, struct device_node *np)
+{
+	int i, err;
+	char of_name[20];
+
+	err = of_property_read_u32(np, "num-banks", &num_banks);
+	if (err) {
+		dev_err(&pdev->dev, "missing num-banks property\n");
+		return err;
+	}
+
+	if (num_banks > THB_CSRAM_BANK_NUM) {
+		dev_err(&pdev->dev, "Expected CSRAM Banks %d, but got %d\n",
+					THB_CSRAM_BANK_NUM,
+					num_banks);
+		return -EINVAL;
+	}
+
+	for (i = 0; i < num_banks; i++) {
+		sprintf(of_name, "csram-bank%d-edac", i);
+
+		/* Map CSRAM ECC Registers */
+		csram_edac_base[i] =
+			devm_platform_ioremap_resource_byname(pdev,
+							      of_name);
+		if (IS_ERR(csram_edac_base[i])) {
+			dev_err(&pdev->dev,
+				"Failed to I/O Map CSRAM ECC bank%d\n", i);
+			return PTR_ERR(csram_edac_base[i]);
+		}
+	}
+
+	for (i = 0; i < THB_CSRAM_IRQ_NUM; i++) {
+		/* Get IRQ */
+		sprintf(of_name, "csram-edac-irq%d", i);
+
+		csram_edac_irq[i] = of_irq_get_byname(np, of_name);
+		if (csram_edac_irq[i] < 0) {
+			dev_err(&pdev->dev,
+				"Failed to get IRQ csram-edac-irq%d\n", i);
+			return csram_edac_irq[i];
+		}
+
+		/* Request IRQ */
+		err = devm_request_threaded_irq(&pdev->dev,
+						csram_edac_irq[i],
+						csram_edac_handle_irq,
+						NULL,
+						IRQF_SHARED,
+						of_name,
+						pdev);
+
+		if (err) {
+			dev_err(&pdev->dev,
+				"Failed to request IRQ %d\n",
+				csram_edac_irq[i]);
+			return err;
+		}
+
+	}
+
+	err = sysfs_create_group(&pdev->dev.kobj, &csram_edac_attributes);
+	if (err < 0) {
+		dev_err(&pdev->dev,
+			"Failed to create CSRAM EDAC sysfs entries\n");
+		return err;
+	}
+
+	dev_info(&pdev->dev, "CSRAM EDAC module probed Successfully\n");
+
+	return 0;
+}
diff --git a/drivers/misc/xbay_ras/ras_core.c b/drivers/misc/xbay_ras/ras_core.c
new file mode 100644
index 000000000000..f57984db1fb0
--- /dev/null
+++ b/drivers/misc/xbay_ras/ras_core.c
@@ -0,0 +1,298 @@
+// SPDX-License-Identifier: GPL-2.0 only
+/*
+ * Intel xBay RAS Collector Driver
+ *
+ * Copyright (C) 2020 Intel Corporation
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2, as published
+ * by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/wait.h>
+
+#include "ras_core.h"
+
+/* Interrupt Status Register */
+#define RAS_EDAC_INTR_STAT_0	0x0
+#define RAS_EDAC_INTR_STAT_1	0x4
+#define RAS_EDAC_INTR_BITS	64
+
+#define RAS_DDR_EDAC_BMAP	BIT(0)
+#define RAS_CSRAM_EDAC_BMAP	BIT(1)
+#define RAS_CPU_EDAC_BMAP	BIT(2)
+#define RAS_WDOG_EDAC_BMAP	BIT(3)
+#define RAS_ALL_EDAC_BMAP	(RAS_DDR_EDAC_BMAP |  \
+				RAS_CSRAM_EDAC_BMAP | \
+				RAS_CPU_EDAC_BMAP | \
+				RAS_WDOG_EDAC_BMAP)
+
+static void __iomem *ras_base;
+static u32 ras_intr_bit_map[RAS_EDAC_INTR_BITS], ras_num_intr;
+static u32 record_last_edac_err, ns_wdog_sts;
+static spinlock_t intr_stat_lock;
+static DECLARE_WAIT_QUEUE_HEAD(err_sts_waitq);
+
+static void xbay_wdog_get_all_info(struct platform_device *pdev,
+				   char *buf, int count)
+{
+	unsigned long flags;
+
+	memcpy(buf, &ns_wdog_sts, count);
+	spin_lock_irqsave(&intr_stat_lock, flags);
+	ns_wdog_sts = 0;
+	spin_unlock_irqrestore(&intr_stat_lock, flags);
+}
+
+static ssize_t ras_get_edac_info(struct file *filp, struct kobject *kobj,
+				 struct bin_attribute *bin_attr,
+				 char *buf, loff_t off, size_t count)
+{
+	struct platform_device *pdev =
+			to_pdev(container_of(kobj, struct device, kobj));
+	unsigned long flags;
+	int read_map = 0x0;
+
+	if (count == EDAC_STS_SZ) {
+		wait_event_interruptible(err_sts_waitq,
+					 (record_last_edac_err != 0));
+		memcpy(buf + EDAC_STS_OFF, &record_last_edac_err, EDAC_STS_SZ);
+		return count;
+	} else if (count == DDR_EDAC_INFO_SZ)
+		read_map |= RAS_DDR_EDAC_BMAP;
+	else if (count == CSRAM_EDAC_INFO_SZ)
+		read_map |= RAS_CSRAM_EDAC_BMAP;
+	else if (count == CPU_EDAC_INFO_SZ)
+		read_map |= RAS_CPU_EDAC_BMAP;
+	else if (count == WDOG_INFO_SZ)
+		read_map |= RAS_WDOG_EDAC_BMAP;
+	else if (count == TOTAL_INFO_SZ)
+		read_map |= RAS_ALL_EDAC_BMAP;
+	else {
+		dev_warn(&pdev->dev, "Invalid length to read\n");
+		return -EINVAL;
+	}
+
+	memcpy(buf + EDAC_STS_OFF, &record_last_edac_err, EDAC_STS_SZ);
+	if (read_map & RAS_DDR_EDAC_BMAP)
+		xbay_ddr_edac_get_all_info(pdev, buf + DDR_EDAC_OFF,
+					   DDR_EDAC_INFO_SZ);
+	if (read_map & RAS_CSRAM_EDAC_BMAP)
+		xbay_csram_edac_get_all_info(pdev, buf + CSRAM_EDAC_OFF,
+					     CSRAM_EDAC_INFO_SZ);
+	if (read_map & RAS_CPU_EDAC_BMAP)
+		xbay_cpu_edac_get_all_info(pdev, buf + CPU_EDAC_OFF,
+					   CPU_EDAC_INFO_SZ);
+	if (read_map & RAS_WDOG_EDAC_BMAP)
+		xbay_wdog_get_all_info(pdev, buf + WDOG_OFF,
+				       WDOG_INFO_SZ);
+
+	spin_lock_irqsave(&intr_stat_lock, flags);
+	if (read_map & RAS_DDR_EDAC_BMAP)
+		record_last_edac_err &= ~RAS_EDAC_INTR_STAT_0_DDR_MASK;
+	if (read_map & RAS_CSRAM_EDAC_BMAP)
+		record_last_edac_err &= ~RAS_EDAC_INTR_STAT_0_CSRAM_MASK;
+	if (read_map & RAS_CPU_EDAC_BMAP)
+		record_last_edac_err &= ~RAS_TST_CPU_INTR;
+	if (read_map & RAS_WDOG_EDAC_BMAP)
+		record_last_edac_err &= ~RAS_RESV_WDOG_INTR;
+	spin_unlock_irqrestore(&intr_stat_lock, flags);
+
+	return count;
+}
+
+static struct bin_attribute ras_info_attr = {
+	.attr =	{
+		.name = "get_edac_info",
+		.mode = 0644,
+	},
+	.size = 4096,
+	.read = ras_get_edac_info,
+};
+
+static struct bin_attribute *ras_edac_info_bin_attrs[] = {
+	&ras_info_attr,
+	NULL,
+};
+
+#ifdef DEBUG_RAS_SW_INJ
+static ssize_t tst_set_ras_interrupt_store(struct device *dev,
+					   struct device_attribute *mattr,
+					   const char *data, size_t count)
+{
+	struct platform_device *pdev = to_pdev(dev);
+	u32 val = 0;
+	unsigned long flags;
+
+	if (strncmp(data, "DDR", 3) == 0)
+		val = RAS_TST_DDR_INTR;
+	else if (strncmp(data, "CSRAM", 5) == 0)
+		val = RAS_TST_CSRAM_INTR;
+	else if (strncmp(data, "CPU", 3) == 0)
+		val = RAS_TST_CPU_INTR;
+	else if (strncmp(data, "WDOG", 4) == 0)
+		val = RAS_RESV_WDOG_INTR;
+	else {
+		dev_err(&pdev->dev, "Invalid options chosen\n");
+		dev_err(&pdev->dev,
+			"DDR, CSRAM, CPU, WDOG available\n");
+		return -EINVAL;
+	}
+
+	spin_lock_irqsave(&intr_stat_lock, flags);
+	record_last_edac_err |= val;
+	if (val == RAS_RESV_WDOG_INTR)
+		ns_wdog_sts = XBAY_RAS_NS_WDOG_TO;
+	spin_unlock_irqrestore(&intr_stat_lock, flags);
+	wake_up_interruptible(&err_sts_waitq);
+
+	return count;
+}
+static DEVICE_ATTR_WO(tst_set_ras_interrupt);
+
+static ssize_t tst_clear_edac_info_store(struct device *dev,
+					 struct device_attribute *mattr,
+					 const char *data, size_t count)
+{
+	struct platform_device *pdev = to_pdev(dev);
+
+	record_last_edac_err = ns_wdog_sts = 0;
+	xbay_ddr_edac_clear_all_info(pdev, DDR_EDAC_INFO_SZ);
+	xbay_csram_edac_clear_all_info(pdev, CSRAM_EDAC_INFO_SZ);
+	xbay_cpu_edac_clear_all_info(pdev, CPU_EDAC_INFO_SZ);
+
+	return count;
+}
+static DEVICE_ATTR_WO(tst_clear_edac_info);
+
+static const struct attribute *tst_ras_sw_inject_attrs[] = {
+	&dev_attr_tst_set_ras_interrupt.attr,
+	&dev_attr_tst_clear_edac_info.attr,
+	NULL,
+};
+#endif
+
+static const struct attribute_group ras_edac_info_attrs = {
+	.bin_attrs = ras_edac_info_bin_attrs,
+#ifdef DEBUG_RAS_SW_INJ
+	.attrs = (struct attribute **)tst_ras_sw_inject_attrs,
+#endif
+};
+
+void xbay_ras_clear_interrupt(int irq)
+{
+	struct irq_data *irqd = irq_get_irq_data(irq);
+	irq_hw_number_t hwirq = irqd_to_hwirq(irqd);
+	int bit;
+
+	for (bit = 0; bit < ras_num_intr; bit++) {
+		if (hwirq == ras_intr_bit_map[bit]) {
+			record_last_edac_err |=
+				   readl(ras_base + RAS_EDAC_INTR_STAT_0);
+			writel(1 << bit, ras_base + RAS_EDAC_INTR_STAT_0);
+			wake_up_interruptible(&err_sts_waitq);
+			break;
+		}
+	}
+}
+
+void xbay_ras_notify_wdog_event(enum xbay_ras_wdog_event evnt)
+{
+	/* Called from IRQ context */
+	ns_wdog_sts |= evnt;
+	record_last_edac_err |= RAS_RESV_WDOG_INTR;
+	xbay_pcie_report_internal_error(UNCORR_ERR);
+	wake_up_interruptible(&err_sts_waitq);
+}
+EXPORT_SYMBOL(xbay_ras_notify_wdog_event);
+
+static int xbay_ras_probe(struct platform_device *pdev)
+{
+	struct device_node *node = pdev->dev.of_node, *child;
+	int err;
+
+	ras_base = devm_platform_ioremap_resource_byname(pdev,
+							 "ras-regs");
+	if (IS_ERR(ras_base)) {
+		dev_err(&pdev->dev, "Failed to I/O map of RAS regs\n");
+		return PTR_ERR(ras_base);
+	}
+
+	/* Clear any errors, if already set */
+	writel(RAS_EDAC_INTR_STAT_0_MASK, ras_base + RAS_EDAC_INTR_STAT_0);
+
+	err = of_property_read_u32(node, "ras-num-intr",
+				   &ras_num_intr);
+	if (err) {
+		dev_err(&pdev->dev, "missing ras-num-intr property\n");
+		return err;
+	}
+
+	err = of_property_read_u32_array(node, "ras-intr-bit-map",
+					 ras_intr_bit_map,
+					 ras_num_intr);
+	if (err) {
+		dev_err(&pdev->dev, "missing ras-intr-bit-map property\n");
+		return err;
+	}
+
+	err = sysfs_create_group(&pdev->dev.kobj, &ras_edac_info_attrs);
+	if (err < 0) {
+		dev_err(&pdev->dev,
+			"Failed to create RAS EDAC sysfs entries\n");
+		return err;
+	}
+
+	for_each_child_of_node(node, child) {
+		if (of_device_is_compatible(child, "snps,ddr-edac"))
+			xbay_ddr_edac_probe(pdev, child);
+
+		if (of_device_is_compatible(child, "netspeed,noc-csram-edac"))
+			xbay_csram_edac_probe(pdev, child);
+
+		if (of_device_is_compatible(child, "arm,cortex-a53-edac"))
+			xbay_cortex_a53_edac_probe(pdev, child);
+
+		if (of_device_is_compatible(child, "thb,pcie-ep-edac"))
+			xbay_pcie_rasdes_probe(pdev, child);
+	}
+
+	spin_lock_init(&intr_stat_lock);
+	dev_info(&pdev->dev, "RAS Driver probed Successfully\n");
+
+	return 0;
+}
+
+static int xbay_ras_remove(struct platform_device *pdev)
+{
+	return 0;
+}
+
+static const struct of_device_id xbay_ras_of_match[] = {
+	{ .compatible = "intel,xbay-ras", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, xbay_ras_of_match);
+
+static struct platform_driver xbay_ras_driver = {
+	.probe = xbay_ras_probe,
+	.remove = xbay_ras_remove,
+	.driver = {
+		.name = "xbay_ras",
+		.of_match_table = xbay_ras_of_match,
+	},
+};
+
+module_platform_driver(xbay_ras_driver);
+
+MODULE_AUTHOR("Intel");
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("xBay RAS Driver");
diff --git a/drivers/misc/xbay_ras/ras_core.h b/drivers/misc/xbay_ras/ras_core.h
new file mode 100644
index 000000000000..ffabec91afe8
--- /dev/null
+++ b/drivers/misc/xbay_ras/ras_core.h
@@ -0,0 +1,73 @@
+/* SPDX-License-Identifier: GPL-2.0 only */
+/*
+ * Intel xBay RAS: Core Header file
+ *
+ * Copyright (C) 2020 Intel Corporation
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2, as published
+ * by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/io.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of_irq.h>
+#include <linux/of_platform.h>
+#include <linux/xbay_ras.h>
+
+#define DEBUG_RAS_SW_INJ
+
+#define DEBUG_RAS_DDR
+#define DEBUG_DDR_SW_INJ
+#undef DEBUG_DDR_HW_INJ
+
+#define DEBUG_RAS_CSRAM
+#define DEBUG_CSRAM_SW_INJ
+#undef DEBUG_CSRAM_HW_INJ
+
+#define DEBUG_RAS_CPU
+#define DEBUG_CPU_SW_INJ
+#undef DEBUG_CPU_HW_INJ
+
+#define to_pdev(devp) container_of(devp, struct platform_device, dev)
+
+enum error_type {
+	NO_ERR = -1,
+	CORR_ERR,
+	UNCORR_ERR,
+};
+
+/* Function declarations */
+int xbay_pcie_rasdes_probe(struct platform_device *pdev,
+			   struct device_node *np);
+int xbay_ddr_edac_probe(struct platform_device *pdev,
+			struct device_node *np);
+int xbay_cortex_a53_edac_probe(struct platform_device *pdev,
+			       struct device_node *np);
+int xbay_csram_edac_probe(struct platform_device *pdev,
+			  struct device_node *np);
+void xbay_ddr_edac_get_all_info(struct platform_device *pdev,
+				char *buf, int count);
+void xbay_csram_edac_get_all_info(struct platform_device *pdev,
+				  char *buf, int count);
+void xbay_cpu_edac_get_all_info(struct platform_device *pdev,
+				char *buf, int count);
+void xbay_ddr_edac_clear_all_info(struct platform_device *pdev,
+				  int count);
+void xbay_csram_edac_clear_all_info(struct platform_device *pdev,
+				    int count);
+void xbay_cpu_edac_clear_all_info(struct platform_device *pdev,
+				  int count);
+void xbay_pcie_report_internal_error(bool ce);
+void xbay_ras_clear_interrupt(int value);
+void xbay_ras_notify_wdog_event(enum xbay_ras_wdog_event evnt);
diff --git a/drivers/misc/xbay_ras/snps_lpddr_edac.c b/drivers/misc/xbay_ras/snps_lpddr_edac.c
new file mode 100644
index 000000000000..66be9dec5431
--- /dev/null
+++ b/drivers/misc/xbay_ras/snps_lpddr_edac.c
@@ -0,0 +1,426 @@
+// SPDX-License-Identifier: GPL-2.0 only
+/*
+ * Intel xBay RAS: Synopsys DDR ECC SW
+ *
+ * Copyright (C) 2020 Intel Corporation
+ *
+ * Code referred from:
+ * drivers/edac/synopsys_edac.c
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2, as published
+ * by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include "ras_core.h"
+
+/* Register Offsets */
+#define ECC_CFG0_OFF		0x00
+#define ECC_CFG1_OFF		0x04
+#define ECC_STAT_OFF		0x08
+#define ECC_CTRL_OFF		0x0C
+#define ECC_ERRCNT_OFF		0x10
+#define ECC_CE_ADDR0_OFF	0x14
+#define ECC_CE_ADDR1_OFF	0x18
+#define ECC_BITMASK0_OFF	0x28
+#define ECC_BITMASK1_OFF	0x2C
+#define ECC_BITMASK2_OFF	0x30
+#define ECC_POISON0_OFF		0x48
+#define ECC_POISON1_OFF		0x4C
+
+/* Status Register Bit definitions */
+#define ECC_STAT_UE_CNT_MASK	GENMASK(19, 16)
+#define ECC_STAT_CE_CNT_MASK	GENMASK(11, 8)
+#define ECC_STAT_BIT_NUM_MASK	GENMASK(6, 0)
+#define ECC_STAT_UE_CNT_SHIFT	16
+#define ECC_STAT_CE_CNT_SHIFT	8
+
+/* Control Register Bit definitions */
+#define ECC_CTRL_CLR_CE		BIT(0)
+#define ECC_CTRL_CLR_UE		BIT(1)
+#define ECC_CTRL_CLR_CE_CNT	BIT(2)
+#define ECC_CTRL_CLR_UE_CNT	BIT(3)
+#define ECC_CTRL_CLR_INTR	BIT(4)
+#define ECC_CTRL_CLR_MASK	GENMASK(4, 0)
+
+/* CE/UE Info register definitions */
+#define ECC_CE_INFO_OFF		ECC_CE_ADDR0_OFF
+#define ECC_UE_INFO_OFF		(ECC_CE_INFO_OFF + 0x20)
+
+#define ADDR0_OFF		0x00
+#define ADDR1_OFF		0x04
+#define SYN0_OFF		0x08
+#define SYN1_OFF		0x0C
+#define SYN2_OFF		0x10
+
+#define ADDR0_ROW_MASK		GENMASK(17, 0)
+#define ADDR0_RANK_MASK		BIT(24)
+#define ADDR1_BANK_GRP_MASK	GENMASK(25, 24)
+#define ADDR1_BANK_NUM_MASK	GENMASK(18, 16)
+#define ADDR1_BLK_NUM_MASK	GENMASK(11, 0)
+#define ADDR1_BANK_GRP_SHIFT	24
+#define ADDR1_BANK_NUM_SHIFT	16
+
+static struct ddr_edac_status_t
+	ddr_edac_status[THB_DDR_SLICE_NUM][THB_DDR_MCS_PER_SLICE];
+static void __iomem
+	*ddr_edac_base[THB_DDR_SLICE_NUM][THB_DDR_MCS_PER_SLICE];
+static int ddr_edac_irq[THB_DDR_SLICE_NUM][THB_DDR_MCS_PER_SLICE];
+static u32 num_slices, num_mcs_per_slice;
+
+static int ddr_edac_clear_err(struct platform_device *pdev,
+				   int slice_id, int mc_id)
+{
+	void __iomem *base;
+
+	if (slice_id >= num_slices || mc_id >= num_mcs_per_slice) {
+		dev_err(&pdev->dev, "Invalid DDR ECC Slice %d MC %d\n",
+			slice_id, mc_id);
+		return -EINVAL;
+	}
+
+	base = ddr_edac_base[slice_id][mc_id];
+	writel(ECC_CTRL_CLR_MASK, base + ECC_CTRL_OFF);
+
+	return 0;
+}
+
+#if defined(DEBUG_RAS_DDR) && defined(DEBUG_DDR_HW_INJ)
+static void ddr_edac_print_info(struct platform_device *pdev,
+				    int slice_id, int mc_id)
+{
+	struct ddr_edac_status_t *e_sts;
+	struct ddr_edac_err_info_t *e_info = NULL;
+
+	if (slice_id >= num_slices || mc_id >= num_mcs_per_slice) {
+		dev_err(&pdev->dev, "Invalid DDR ECC Slice %d MC %d\n",
+				    slice_id, mc_id);
+		return;
+	}
+
+	e_sts = &ddr_edac_status[slice_id][mc_id];
+
+	dev_info(&pdev->dev, "DDR ECC Slice %d MC %d Statistics :\n",
+			     slice_id, mc_id);
+	dev_info(&pdev->dev, "CE: %d UE: %d\n", e_sts->ce_cnt, e_sts->ue_cnt);
+	dev_info(&pdev->dev, "CE Statistics :\n");
+	e_info = &e_sts->ce_info;
+	dev_info(&pdev->dev, "BitPos %d\n", e_info->bit_pos);
+	dev_info(&pdev->dev, "Row %d Bank %d Bank Group %d Block %d\n",
+			     e_info->row, e_info->bank,
+			     e_info->bank_grp_num, e_info->blk_num);
+	dev_info(&pdev->dev, "Data Pattern: %08x\n", e_info->data_pattern);
+	dev_info(&pdev->dev, "UE Statistics :\n");
+	e_info = &e_sts->ue_info;
+	dev_info(&pdev->dev, "Row %d Bank %d Bank Group %d Block %d\n",
+			     e_info->row, e_info->bank,
+			     e_info->bank_grp_num, e_info->blk_num);
+	dev_info(&pdev->dev, "Data Pattern: %08x\n", e_info->data_pattern);
+}
+#endif
+
+static int ddr_edac_get_err_info(struct platform_device *pdev,
+				     int slice_id, int mc_id)
+{
+	void __iomem *base, *e_base = NULL;
+	struct ddr_edac_status_t *e_sts;
+	struct ddr_edac_err_info_t *e_info = NULL;
+	u32 val;
+	enum error_type err;
+
+	if (slice_id >= num_slices || mc_id >= num_mcs_per_slice) {
+		dev_err(&pdev->dev, "Invalid DDR ECC Slice %d MC %d\n",
+				    slice_id, mc_id);
+		return -EINVAL;
+	}
+
+	base = ddr_edac_base[slice_id][mc_id];
+	e_sts = &ddr_edac_status[slice_id][mc_id];
+
+	/* Read ECC STAT */
+	val = readl(base + ECC_STAT_OFF);
+	e_sts->ce_cnt = (val & ECC_STAT_CE_CNT_MASK) >> ECC_STAT_CE_CNT_SHIFT;
+	e_sts->ue_cnt = (val & ECC_STAT_UE_CNT_MASK) >> ECC_STAT_UE_CNT_SHIFT;
+	if (!e_sts->ce_cnt && !e_sts->ue_cnt) {
+		dev_err(&pdev->dev, "No DDR ECC CE/UE detected on Slice %d MC %d\n",
+				    slice_id, mc_id);
+		return NO_ERR;
+	}
+
+	if (e_sts->ce_cnt) {
+		err = CORR_ERR;
+		e_base = base + ECC_CE_INFO_OFF;
+		e_info = &e_sts->ce_info;
+		e_info->bit_pos = val & ECC_STAT_BIT_NUM_MASK;
+	} else {
+		err = UNCORR_ERR;
+		e_base = base + ECC_UE_INFO_OFF;
+		e_info = &e_sts->ue_info;
+	}
+
+	/* Read ADDR0 */
+	val = readl(e_base + ADDR0_OFF);
+	e_info->row = (val & ADDR0_ROW_MASK);
+
+	/* Read ADDR1 */
+	val = readl(e_base + ADDR1_OFF);
+	e_info->bank = (val & ADDR1_BANK_NUM_MASK) >> ADDR1_BANK_NUM_SHIFT;
+	e_info->bank_grp_num = (val & ADDR1_BANK_GRP_MASK) >>
+				ADDR1_BANK_GRP_SHIFT;
+	e_info->blk_num = (val & ADDR1_BLK_NUM_MASK);
+
+	/* Read SYN0 */
+	e_info->data_pattern = readl(e_base + SYN0_OFF);
+
+	return err;
+}
+
+static u8 get_slice_mc_id(int irq)
+{
+	int i, j = 0;
+
+	for (i = 0; i < num_slices; i++) {
+		for (j = 0; j < num_mcs_per_slice; j++) {
+			if (ddr_edac_irq[i][j] == irq)
+				return  (i << 4) | j;
+		}
+	}
+	return  (i << 4) | j;
+}
+
+static irqreturn_t ddr_edac_handle_irq(int irq, void *data)
+{
+	u8 id;
+	enum error_type err;
+	struct platform_device *pdev = (struct platform_device *)data;
+
+	id = get_slice_mc_id(irq);
+
+	err = ddr_edac_get_err_info(pdev, id >> 4, id & 0xF);
+	if (err < 0)
+		return IRQ_HANDLED;
+
+	ddr_edac_clear_err(pdev, id >> 4, id & 0xF);
+	xbay_ras_clear_interrupt(irq);
+	xbay_pcie_report_internal_error(err);
+
+	return IRQ_HANDLED;
+}
+
+#if defined(DEBUG_RAS_DDR) && defined(DEBUG_DDR_HW_INJ)
+static ssize_t tst_ddr_edac_poison_addr_show(struct device *dev,
+					 struct device_attribute *mattr,
+					 char *data)
+{
+	struct platform_device *pdev = to_pdev(dev);
+
+	dev_info(&pdev->dev, "%s %d\n", __func__, __LINE__);
+
+	return 0;
+}
+
+static ssize_t tst_ddr_edac_poison_addr_store(struct device *dev,
+					      struct device_attribute *mattr,
+					      const char *data, size_t count)
+{
+	struct platform_device *pdev = to_pdev(dev);
+	ulong poison_addr;
+
+	if (kstrtoul(data, 0, &poison_addr))
+		return -EINVAL;
+
+	dev_info(&pdev->dev, "Poisoning DDR Address %lu\n", poison_addr);
+
+	return count;
+}
+
+static ssize_t tst_ddr_edac_inj_error_store(struct device *dev,
+					    struct device_attribute *mattr,
+					    const char *data, size_t count)
+{
+	struct platform_device *pdev = to_pdev(dev);
+
+	if (strncmp(data, "CE", 2) == 0)
+		dev_info(&pdev->dev, "Injecting CE on DDR\n");
+	else
+		dev_info(&pdev->dev, "Injecting UE on DDR\n");
+
+	return count;
+}
+
+static DEVICE_ATTR_RW(tst_ddr_edac_poison_addr);
+static DEVICE_ATTR_WO(tst_ddr_edac_inj_error);
+#endif
+
+#if defined(DEBUG_RAS_DDR) && defined(DEBUG_DDR_SW_INJ)
+static ssize_t tst_ddr_edac_sw_inj_store(struct device *dev,
+					 struct device_attribute *mattr,
+					 const char *data, size_t count)
+{
+	struct platform_device *pdev = to_pdev(dev);
+	struct ddr_edac_status_t *e_sts = NULL;
+	struct ddr_edac_err_info_t *e_info = NULL;
+	int slice_id, mc_id;
+	bool ce = false;
+
+	if (strncmp(data, "CE_0_0", 6) == 0) {
+		ce = true; slice_id = 0; mc_id = 0;
+	} else if (strncmp(data, "UE_2_0", 6) == 0) {
+		ce = false; slice_id = 2; mc_id = 0;
+	} else if (strncmp(data, "CE_1_1", 6) == 0) {
+		ce = true; slice_id = 1; mc_id = 1;
+	} else if (strncmp(data, "UE_3_1", 6) == 0) {
+		ce = false; slice_id = 3; mc_id = 1;
+	} else {
+		dev_err(&pdev->dev, "Invalid options chosen\n");
+		dev_err(&pdev->dev,
+			"CE_0_0, UE_2_0, CE_1_1, UE_3_1 are available\n");
+		return -EINVAL;
+	}
+
+	dev_info(&pdev->dev, "Injecting SW Error on DDR Slice%d MC%d\n",
+		 slice_id, mc_id);
+	e_sts = &ddr_edac_status[slice_id][mc_id];
+	e_info = &e_sts->ce_info;
+
+	e_info->row = 0x04 + mc_id;
+	e_info->col = 0x05 + mc_id;
+	e_info->bank = 0x06 + mc_id;
+	e_info->bit_pos = 0x07 + mc_id;
+	e_info->data_pattern = 0xa5a5a5 + mc_id;
+	e_info->bank_grp_num = 0x08 + mc_id;
+	e_info->blk_num = 0x09 + mc_id;
+	if (ce)
+		e_sts->ce_cnt = 0x02 + mc_id;
+	else
+		e_sts->ue_cnt = 0x03 + mc_id;
+
+	return count;
+}
+static DEVICE_ATTR_WO(tst_ddr_edac_sw_inj);
+#endif
+
+#ifdef DEBUG_RAS_DDR
+static const struct attribute *ddr_edac_inject_attrs[] = {
+#ifdef DEBUG_DDR_HW_INJ
+	&dev_attr_tst_ddr_edac_poison_addr.attr,
+	&dev_attr_tst_ddr_edac_inj_error.attr,
+#endif
+#ifdef DEBUG_DDR_SW_INJ
+	&dev_attr_tst_ddr_edac_sw_inj.attr,
+#endif
+	NULL,
+};
+#endif
+
+#ifdef DEBUG_RAS_DDR
+static const struct attribute_group ddr_edac_attributes = {
+	.attrs = (struct attribute **)ddr_edac_inject_attrs,
+};
+#endif
+
+void xbay_ddr_edac_get_all_info(struct platform_device *pdev,
+				char *buf, int count)
+{
+	memcpy(buf, (char *)ddr_edac_status, count);
+}
+
+void xbay_ddr_edac_clear_all_info(struct platform_device *pdev, int count)
+{
+	memset((char *)ddr_edac_status, 0, count);
+}
+
+int xbay_ddr_edac_probe(struct platform_device *pdev, struct device_node *np)
+{
+	int i, j, err;
+	char slice_name[20];
+
+	err = of_property_read_u32(np, "num-slices", &num_slices);
+	if (err) {
+		dev_err(&pdev->dev, "missing num-slices property\n");
+		return err;
+	}
+
+	if (num_slices > THB_DDR_SLICE_NUM) {
+		dev_err(&pdev->dev, "Expected DDR Slices %d, but got %d\n",
+					THB_DDR_SLICE_NUM,
+					num_slices);
+		return -EINVAL;
+	}
+
+	err = of_property_read_u32(np, "num-mcs-per-slice",
+				   &num_mcs_per_slice);
+	if (err) {
+		dev_err(&pdev->dev, "missing num-mcs-per-slice property\n");
+		return err;
+	}
+
+	if (num_mcs_per_slice > THB_DDR_MCS_PER_SLICE) {
+		dev_err(&pdev->dev, "Expected MCs per Slice %d, but got %d\n",
+					THB_DDR_MCS_PER_SLICE,
+					num_mcs_per_slice);
+		return -EINVAL;
+	}
+
+	for (i = 0; i < num_slices; i++) {
+		for (j = 0; j < num_mcs_per_slice; j++) {
+			sprintf(slice_name, "slice%d-mc%d-edac", i, j);
+
+			/* Map DDR ECC Registers */
+			ddr_edac_base[i][j] =
+			    devm_platform_ioremap_resource_byname(pdev,
+								  slice_name);
+			if (IS_ERR(ddr_edac_base[i][j])) {
+				dev_err(&pdev->dev,
+					"Failed to Map DDR ECC slice%d mc%d\n",
+					i, j);
+				return PTR_ERR(ddr_edac_base[i][j]);
+			}
+
+			/* Get IRQ */
+			ddr_edac_irq[i][j] = of_irq_get_byname(np, slice_name);
+			if (ddr_edac_irq[i][j] < 0) {
+				dev_err(&pdev->dev,
+					"Failed to get IRQ slice%d mc%d\n",
+					i, j);
+				return ddr_edac_irq[i][j];
+			}
+
+			/* Request IRQ */
+			err = devm_request_threaded_irq(&pdev->dev,
+							ddr_edac_irq[i][j],
+							ddr_edac_handle_irq,
+							NULL,
+							IRQF_SHARED,
+							slice_name,
+							pdev);
+			if (err) {
+				dev_err(&pdev->dev,
+					"Failed to request IRQ %d\n",
+					ddr_edac_irq[i][j]);
+				return err;
+			}
+		}
+	}
+
+#ifdef DEBUG_RAS_DDR
+	err = sysfs_create_group(&pdev->dev.kobj, &ddr_edac_attributes);
+	if (err < 0) {
+		dev_err(&pdev->dev,
+			"Failed to create DDR EDAC sysfs entries\n");
+		return err;
+	}
+#endif
+
+	dev_info(&pdev->dev, "DDR EDAC module probed Successfully\n");
+
+	return 0;
+}
diff --git a/drivers/misc/xbay_ras/snps_pcie_rasdes.c b/drivers/misc/xbay_ras/snps_pcie_rasdes.c
new file mode 100644
index 000000000000..32e06018ecfe
--- /dev/null
+++ b/drivers/misc/xbay_ras/snps_pcie_rasdes.c
@@ -0,0 +1,460 @@
+// SPDX-License-Identifier: GPL-2.0 only
+/*
+ * Intel xBay RAS: PCIe RAS DES SW
+ *
+ * Copyright (C) 2020 Intel Corporation
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2, as published
+ * by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include "ras_core.h"
+
+#ifdef CONFIG_RAS_PCIE_RASDES
+#define THB_PCIE_EP_RASDES_CAP_OFF	0x1D0
+
+#define RASDES_EVENT_COUNTER_REG	(THB_PCIE_EP_RASDES_CAP_OFF + 0x4)
+#define RASDES_EVENT_DATA_REG		(THB_PCIE_EP_RASDES_CAP_OFF + 0x8)
+
+#define PCIE_RASDES_NUM_GROUPS		8
+#define PCIE_RASDES_NUM_ERR_GROUPS	4
+#define PCIE_RASDES_NUM_STAT_GROUPS	4
+
+#define PCIE_RASDES_MAX_GROUP_CNT	30
+#endif
+
+#define PCIE_PF0_CORR_ERR_MASK		0x114
+#define PCIE_PF0_UNCORR_ERR_MASK	0x108
+
+#define PCIE_PF0_CORR_INT_ERR		BIT(14)
+#define PCIE_PF0_UNCORR_INT_ERR		BIT(22)
+
+#define PCIE_AER_REPORT_ERROR		0x2F0
+
+#define PCIE_AER_REPORT_UNCORR		BIT(1)
+#define PCIE_AER_REPORT_ERR_GEN		BIT(0)
+
+static void __iomem *pcie_ep_apb_base;
+static void __iomem *pcie_ep_pf0_cfg_base;
+
+#ifdef CONFIG_RAS_PCIE_RASDES
+/* RAS DES counter group 0 */
+struct pcie_rasdes_grp0_t {
+	u8 ebuf_overflow;
+	u8 ebuf_underrun;
+	u8 decode_error;
+	u8 running_disparity_error;
+	u8 skp_os_parity_error;
+	u8 sync_header_error;
+	u8 rx_valid_deassertion;
+	u8 dummy;
+};
+
+/* RAS DES counter group 1 */
+struct pcie_rasdes_grp1_t {
+	u8 detect_ei_infer;
+	u8 receiver_error;
+	u8 rx_recovery_request;
+	u8 n_fts_timeout;
+	u8 framing_error;
+	u8 deskew_error;
+	u8 dummy1;
+	u8 dummy2;
+};
+
+/* RAS DES counter group 2 */
+struct pcie_rasdes_grp2_t {
+	u8 bad_tlp;
+	u8 lcrc_error;
+	u8 bad_dllp;
+	u8 replay_number_rollover;
+	u8 replay_timeout;
+	u8 rx_nak_dllp;
+	u8 tx_nak_dllp;
+	u8 retry_tlp;
+};
+
+/* RAS DES counter group 3 */
+struct pcie_rasdes_grp3_t {
+	u8 fc_timeout;
+	u8 poisoned_tlp;
+	u8 ecrc_error;
+	u8 unsupported_request;
+	u8 completer_abort;
+	u8 completion_timeout;
+	u8 dummy1;
+	u8 dummy2;
+};
+
+/* RAS DES counter group 4 */
+struct pcie_rasdes_grp4_t {
+	u8 ebuf_skp_add;
+	u8 ebuf_skp_del;
+	u8 dummy1;
+	u8 dummy2;
+};
+
+/* RAS DES counter group 5 */
+struct pcie_rasdes_grp5_t {
+	u32 l0_to_recovery_entry;
+	u32 l1_to_recovery_entry;
+	u32 tx_l0s_entry;
+	u32 rx_l0s_entry;
+	u32 aspm_l1_reject;
+	u32 l1_entry;
+	u32 l1_cpm;
+	u32 l11_entry;
+	u32 l12_entry;
+	u32 l1_short_duration;
+	u32 l12_abort;
+	u32 l2_entry;
+	u32 speed_change;
+	u32 link_width_change;
+};
+
+/* RAS DES counter group 6 */
+struct pcie_rasdes_grp6_t {
+	u32 tx_ack_dllp;
+	u32 tx_update_fc_dllp;
+	u32 rx_ack_dllp;
+	u32 rx_update_fc_dllp;
+	u32 rx_nullified_tlp;
+	u32 tx_nullified_tlp;
+	u32 rx_duplicate_tlp;
+};
+
+/* RAS DES counter group 7 */
+struct pcie_rasdes_grp7_t {
+	u32 tx_memory_write;
+	u32 tx_memory_read;
+	u32 tx_io_write;
+	u32 tx_io_read;
+	u32 tx_completion_without_data;
+	u32 tx_completion_with_data;
+	u32 tx_message_tlp;
+	u32 tx_atomic;
+	u32 tx_tlp_with_prefix;
+	u32 rx_memory_write;
+	u32 rx_memory_read;
+	u32 rx_config_write;
+	u32 rx_config_read;
+	u32 rx_tx_io_write;
+	u32 rx_io_read;
+	u32 rx_completion_without_data;
+	u32 rx_completion_with_data;
+	u32 rx_message_tlp;
+	u32 rx_atomic;
+	u32 rx_tlp_with_prefix;
+};
+
+/* RAS DES counter values as written to register */
+enum pcie_rasdes_cnt_t {
+	/* group 0 */
+	PCIE_RASDES_EBUF_OVERFLOW = 0x0000,
+	PCIE_RASDES_EBUF_UNDERRUN = 0x0001,
+	PCIE_RASDES_DECODE_ERROR = 0x0002,
+	PCIE_RASDES_RUNNING_DISPARITY_ERROR = 0x0003,
+	PCIE_RASDES_SKP_OS_PARITY_ERROR = 0x0004,
+	PCIE_RASDES_SYNC_HEADER_ERROR = 0x0005,
+	PCIE_RASDES_RX_VALID_DEASSERTION = 0x0006,
+
+	/* group 1 - events 0 to 4 are reserved */
+	PCIE_RASDES_DETECT_EI_INFER = 0x0105,
+	PCIE_RASDES_RECEIVER_ERROR = 0x0106,
+	PCIE_RASDES_RX_RECOVERY_REQUEST = 0x0107,
+	PCIE_RASDES_N_FTS_TIMEOUT = 0x0108,
+	PCIE_RASDES_FRAMING_ERROR = 0x0109,
+	PCIE_RASDES_DESKEW_ERROR = 0x010A,
+
+	/* group 2 */
+	PCIE_RASDES_BAD_TLP = 0x0200,
+	PCIE_RASDES_LCRC_ERROR = 0x0201,
+	PCIE_RASDES_BAD_DLLP = 0x0202,
+	PCIE_RASDES_REPLAY_NUMBER_ROLLOVER = 0x0203,
+	PCIE_RASDES_REPLAY_TIMEOUT = 0x0204,
+	PCIE_RASDES_RX_NAK_DLLP = 0x0205,
+	PCIE_RASDES_TX_NAK_DLLP = 0x0206,
+	PCIE_RASDES_RETRY_TLP = 0x0207,
+
+	/* group 3 */
+	PCIE_RASDES_FC_TIMEOUT = 0x0300,
+	PCIE_RASDES_POISONED_TLP = 0x0301,
+	PCIE_RASDES_ECRC_ERROR = 0x0302,
+	PCIE_RASDES_UNSUPPORTED_REQUEST = 0x0303,
+	PCIE_RASDES_COMPLETER_ABORT = 0x0304,
+	PCIE_RASDES_COMPLETION_TIMEOUT = 0x0305,
+
+	/* group 4 */
+	PCIE_RASDES_EBUF_SKP_ADD = 0x0400,
+	PCIE_RASDES_EBUF_SKP_DEL = 0x0401,
+
+	/* group 5 */
+	PCIE_RASDES_L0_TO_RECOVERY_ENTRY = 0x0500,
+	PCIE_RASDES_L1_TO_RECOVERY_ENTRY = 0x0501,
+	PCIE_RASDES_TX_L0S_ENTRY = 0x0502,
+	PCIE_RASDES_RX_L0S_ENTRY = 0x0503,
+	PCIE_RASDES_ASPM_L1_REJECT = 0x0504,
+	PCIE_RASDES_L1_ENTRY = 0x0505,
+	PCIE_RASDES_L1_CPM = 0x0506,
+	PCIE_RASDES_L11_ENTRY = 0x0507,
+	PCIE_RASDES_L12_ENTRY = 0x0508,
+	PCIE_RASDES_L1_SHORT_DURATION = 0x0509,
+	PCIE_RASDES_L12_ABORT = 0x050A,
+	PCIE_RASDES_L2_ENTRY = 0x050B,
+	PCIE_RASDES_SPEED_CHANGE = 0x050C,
+	PCIE_RASDES_LINK_WIDTH_CHANGE = 0x050D,
+
+	/* group 6 */
+	PCIE_RASDES_TX_ACK_DLLP = 0x0600,
+	PCIE_RASDES_TX_UPDATE_FC_DLLP = 0x0601,
+	PCIE_RASDES_RX_ACK_DLLP = 0x0602,
+	PCIE_RASDES_RX_UPDATE_FC_DLLP = 0x0603,
+	PCIE_RASDES_RX_NULLIFIED_TLP = 0x0604,
+	PCIE_RASDES_TX_NULLIFIED_TLP = 0x0605,
+	PCIE_RASDES_RX_DUPLICATE_TLP = 0x0606,
+
+	/* group 7 */
+	PCIE_RASDES_TX_MEMORY_WRITE = 0x0700,
+	PCIE_RASDES_TX_MEMORY_READ = 0x0701,
+	PCIE_RASDES_TX_IO_WRITE = 0x0704,
+	PCIE_RASDES_TX_IO_READ = 0x0705,
+	PCIE_RASDES_TX_COMPLETION_WITHOUT_DATA = 0x0706,
+	PCIE_RASDES_TX_COMPLETION_WITH_DATA = 0x0707,
+	PCIE_RASDES_TX_MESSAGE_TLP = 0x0708,
+	PCIE_RASDES_TX_ATOMIC = 0x0709,
+	PCIE_RASDES_TX_TLP_WITH_PREFIX = 0x070A,
+	PCIE_RASDES_RX_MEMORY_WRITE = 0x070B,
+	PCIE_RASDES_RX_MEMORY_READ = 0x070C,
+	PCIE_RASDES_RX_CONFIG_WRITE = 0x070D,
+	PCIE_RASDES_RX_CONFIG_READ = 0x070E,
+	PCIE_RASDES_RX_TX_IO_WRITE = 0x070F,
+	PCIE_RASDES_RX_IO_READ = 0x0710,
+	PCIE_RASDES_RX_COMPLETION_WITHOUT_DATA = 0x0711,
+	PCIE_RASDES_RX_COMPLETION_WITH_DATA = 0x0712,
+	PCIE_RASDES_RX_MESSAGE_TLP = 0x0713,
+	PCIE_RASDES_RX_ATOMIC = 0x0714,
+	PCIE_RASDES_RX_TLP_WITH_PREFIX = 0x0715,
+};
+
+struct pcie_rasdes_grp_desc_t {
+	const u32 entry_size;
+	u8 counter_offsets[PCIE_RASDES_MAX_GROUP_CNT];
+};
+
+static pcie_rasdes_grp_desc_t pcie_rasdes_grp_table[PCIE_RASDES_NUM_GROUPS] = {
+
+	{
+		.entry_size = sizeof(pcie_rasdes_grp0_t),
+		.counter_offsets = {0, 1, 2, 3, 4, 5, 6, 0xff}
+	},
+
+	{
+		.entry_size = sizeof(pcie_rasdes_grp1_t),
+		.counter_offsets = {5, 6, 7, 8, 9, 10, 0xff},
+	},
+
+	{
+		.entry_size = sizeof(pcie_rasdes_grp2_t),
+		.counter_offsets = {0, 1, 2, 3, 4, 5, 6, 7, 0xff},
+	},
+
+	{
+		.entry_size = sizeof(pcie_rasdes_grp3_t),
+		.counter_offsets = {0, 1, 2, 3, 4, 5, 0xff},
+	},
+
+	{
+		.entry_size = sizeof(pcie_rasdes_grp4_t),
+		.counter_offsets = {0, 1, 0xff},
+	},
+
+	{
+		.entry_size = sizeof(pcie_rasdes_grp5_t),
+		.counter_offsets = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,
+				    12, 13, 0xff},
+	},
+
+	{
+		.entry_size = sizeof(pcie_rasdes_grp6_t),
+		.counter_offsets = {0, 1, 2, 3, 4, 5, 6, 0xff},
+	},
+
+	{
+		.entry_size = sizeof(pcie_rasdes_grp7_t),
+		.counter_offsets = {0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,
+				    14, 15, 16, 17, 18, 19, 20, 21, 0xff},
+	},
+
+};
+
+static u32 pcie_rasdes_rd_counter(pcie_rasdes_cnt_t counter)
+{
+	u32 val;
+
+	val = readl(pcie_ep_apb_base + RASDES_EVENT_COUNTER_REG);
+	val |= (counter << 16);
+	writel(val, pcie_ep_apb_base + RASDES_EVENT_COUNTER_REG);
+
+	return readl(pcie_ep_apb_base + RASDES_EVENT_DATA_REG);
+}
+
+static void pcie_rasdes_enable(void)
+{
+	u32 val;
+
+	val = readl(pcie_ep_apb_base + RASDES_EVENT_COUNTER_REG);
+	val |= (0x7 << 2);
+	writel(val, pcie_ep_apb_base + RASDES_EVENT_COUNTER_REG);
+}
+
+static void pcie_rasdes_get_group(u32 group)
+{
+	int i;
+	u32 counter_val, counter_id;
+
+	if (group >= PCIE_RASDES_NUM_GROUPS)
+		return;
+
+	for (i = 0;
+	     pcie_rasdes_grp_table[group].counter_offsets[i] != 0xff; i++) {
+		counter_id = (group << 8) |
+				pcie_rasdes_grp_table[group].counter_offsets[i];
+		counter_val =
+			pcie_rasdes_rd_counter((pcie_rasdes_cnt_t)counter_id);
+	}
+}
+
+static void pcie_rasdes_get_stat_groups(void)
+{
+	int i;
+
+	for (i = PCIE_RASDES_NUM_ERR_GROUPS;
+		i < PCIE_RASDES_NUM_GROUPS; i++)
+		pcie_rasdes_get_group(i);
+}
+
+void xbay_pcie_rasdes_get_err_counters(void)
+{
+	int i;
+
+	for (i = 0; i < PCIE_RASDES_NUM_ERR_GROUPS; i++)
+		pcie_rasdes_get_group(i);
+}
+#endif
+
+#ifdef DEBUG_RAS_PCIE
+static ssize_t tst_pcie_ep_report_error_store(struct device *dev,
+					  struct device_attribute *mattr,
+					  const char *data, size_t count)
+{
+	struct platform_device *pdev = to_pdev(dev);
+
+	if (strncmp(data, "CE", 2) == 0) {
+		dev_info(&pdev->dev, "Reporting Internal CE to Host\n");
+		xbay_pcie_report_internal_error(0);
+	} else {
+		dev_info(&pdev->dev, "Reporting Internal UE to Host\n");
+		xbay_pcie_report_internal_error(1);
+	}
+
+	return count;
+}
+static DEVICE_ATTR_WO(tst_pcie_ep_report_error);
+
+static const struct attribute *pcie_rasdes_attrs[] = {
+	&dev_attr_tst_pcie_ep_report_error.attr,
+	NULL,
+};
+static const struct attribute_group pcie_rasdes_attributes = {
+	.attrs = (struct attribute **)pcie_rasdes_attrs,
+};
+#endif
+
+void xbay_pcie_report_internal_error(bool ce)
+{
+	if (!pcie_ep_apb_base)
+		return;
+
+	if (!ce)
+		writel(PCIE_AER_REPORT_ERR_GEN,
+		       pcie_ep_apb_base + PCIE_AER_REPORT_ERROR);
+	else
+		writel(PCIE_AER_REPORT_ERR_GEN | PCIE_AER_REPORT_UNCORR,
+		       pcie_ep_apb_base + PCIE_AER_REPORT_ERROR);
+}
+
+int xbay_pcie_rasdes_probe(struct platform_device *pdev,
+			   struct device_node *child)
+{
+	struct device_node *np;
+	struct platform_device *pcie_ep_pdev;
+	struct resource *res;
+	u32 val;
+
+	np = of_parse_phandle(child, "thb-pcie-ep", 0);
+	if (!np) {
+		dev_err(&pdev->dev, "Failed to find a THB PCIe EP node\n");
+		return -ENODEV;
+	}
+
+	pcie_ep_pdev = of_find_device_by_node(np);
+	if (!pcie_ep_pdev) {
+		dev_info(&pdev->dev, "PCIe RASDES module probe deferred\n");
+		of_node_put(np);
+		return -EPROBE_DEFER;
+	}
+
+	/* Map PCIe EP Registers */
+	res = platform_get_resource_byname(pcie_ep_pdev, IORESOURCE_MEM, "apb");
+	pcie_ep_apb_base = devm_ioremap(&pdev->dev, res->start,
+					(res->end - res->start + 1));
+	if (IS_ERR(pcie_ep_apb_base)) {
+		dev_err(&pdev->dev,
+			"Failed to I/O Map PCIe EP APB memory");
+		return PTR_ERR(pcie_ep_apb_base);
+	}
+
+	res = platform_get_resource_byname(pcie_ep_pdev, IORESOURCE_MEM, "dbi");
+	pcie_ep_pf0_cfg_base = devm_ioremap(&pdev->dev, res->start,
+					    (res->end - res->start + 1));
+	if (IS_ERR(pcie_ep_pf0_cfg_base)) {
+		dev_err(&pdev->dev,
+			"Failed to I/O Map PCIe EP DBI memory");
+		return PTR_ERR(pcie_ep_pf0_cfg_base);
+	}
+
+	/* Unmask PF0 AER Internal Errors */
+	val = readl(pcie_ep_pf0_cfg_base + PCIE_PF0_CORR_ERR_MASK);
+	val &= ~PCIE_PF0_CORR_INT_ERR;
+	writel(val, pcie_ep_pf0_cfg_base + PCIE_PF0_CORR_ERR_MASK);
+
+	val = readl(pcie_ep_pf0_cfg_base + PCIE_PF0_UNCORR_ERR_MASK);
+	val &= ~PCIE_PF0_UNCORR_INT_ERR;
+	writel(val, pcie_ep_pf0_cfg_base + PCIE_PF0_UNCORR_ERR_MASK);
+
+#ifdef CONFIG_RAS_PCIE_RASDES
+	pcie_rasdes_enable();
+#endif
+
+#ifdef DEBUG_RAS_PCIE
+	err = sysfs_create_group(&pdev->dev.kobj, &pcie_rasdes_attributes);
+	if (err < 0) {
+		dev_err(&pdev->dev,
+			"Failed to create PCIe RAS sysfs entries\n");
+		return err;
+	}
+#endif
+
+	dev_info(&pdev->dev, "PCIe RASDES module probed Successfully\n");
+
+	return 0;
+}
diff --git a/include/linux/xbay_ras.h b/include/linux/xbay_ras.h
new file mode 100644
index 000000000000..a84c90b9f704
--- /dev/null
+++ b/include/linux/xbay_ras.h
@@ -0,0 +1,106 @@
+/* SPDX-License-Identifier: GPL-2.0 only */
+/*
+ * Intel xBay RAS: User common Header file
+ *
+ * Copyright (C) 2020 Intel Corporation
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2, as published
+ * by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, see <http://www.gnu.org/licenses/>.
+ */
+
+#define THB_DDR_SLICE_NUM	4
+#define THB_DDR_MCS_PER_SLICE	4
+
+#define THB_CSRAM_BANK_NUM	8
+
+#define NUM_CACHES	2
+
+/* EDAC Info size */
+#define EDAC_STS_SZ		4
+#define DDR_EDAC_INFO_SZ	1024
+#define CSRAM_EDAC_INFO_SZ	128
+#define CPU_EDAC_INFO_SZ	48
+#define WDOG_INFO_SZ		4
+#define TOTAL_INFO_SZ		1208
+
+/* EDAC Info structure offsets for user space */
+#define EDAC_STS_OFF	0
+#define DDR_EDAC_OFF	4
+#define CSRAM_EDAC_OFF	1028
+#define CPU_EDAC_OFF	1156
+#define WDOG_OFF	1204
+
+#define RAS_EDAC_INTR_STAT_0_MASK	0xFFFFF
+#define RAS_EDAC_INTR_STAT_0_DDR_MASK	0xFFFF
+#define RAS_EDAC_INTR_STAT_0_CSRAM_MASK 0x90000
+
+/* Reserved for Watchdog */
+#define RAS_RESV_WDOG_INTR	(1 << 29)
+
+/* Only for Test purposes */
+#define RAS_TST_DDR_INTR	(1 << 0)
+#define RAS_TST_CSRAM_INTR	(1 << 16)
+#define RAS_TST_CPU_INTR	(1 << 28)
+
+struct ddr_edac_err_info_t {
+	uint32_t row;
+	uint32_t col;
+	uint32_t bank;
+	uint32_t bit_pos;
+	uint32_t data_pattern;
+	uint32_t bank_grp_num;
+	uint32_t blk_num;
+};
+
+struct ddr_edac_status_t {
+	uint32_t ce_cnt;
+	uint32_t ue_cnt;
+	struct ddr_edac_err_info_t ce_info;
+	struct ddr_edac_err_info_t ue_info;
+};
+
+struct csram_edac_status_t {
+	uint16_t sbit_cnt;
+	uint16_t dbit_cnt;
+	uint32_t err_status;
+	uint64_t err_acsramess;
+};
+
+struct cpu_edac_info_t {
+	uint32_t cpu;
+	uint32_t way;
+	uint32_t repeat_err;
+	uint32_t other_err;
+	uint32_t index;
+	uint32_t ram_id;
+};
+
+struct edac_info_t {
+	uint32_t edac_event;
+	struct ddr_edac_status_t
+		ddr_edac_status[THB_DDR_SLICE_NUM][THB_DDR_MCS_PER_SLICE];
+	struct csram_edac_status_t
+		csram_edac_status[THB_CSRAM_BANK_NUM];
+	struct cpu_edac_info_t
+		cpu_edac_info[NUM_CACHES];
+	uint32_t wdog_sts;
+} __attribute__ ((packed));
+
+enum xbay_ras_wdog_event {
+	XBAY_RAS_NS_WDOG_TH_TO = 1,
+	XBAY_RAS_NS_WDOG_TO,
+};
+
+#ifdef CONFIG_XBAY_RAS
+void xbay_ras_notify_wdog_event(enum xbay_ras_wdog_event evnt);
+#endif
+
-- 
2.27.0

