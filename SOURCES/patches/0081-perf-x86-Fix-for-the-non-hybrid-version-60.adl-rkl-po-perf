From a111c395fde6a921c8660bced232741fcd0a9728 Mon Sep 17 00:00:00 2001
From: Kan Liang <kan.liang@linux.intel.com>
Date: Tue, 30 Mar 2021 08:45:33 -0700
Subject: [PATCH 81/88] perf/x86: Fix for the non-hybrid version (601) of ADL

Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
---
 arch/x86/events/core.c       |  5 ++++-
 arch/x86/events/intel/core.c | 16 +++++++++++++++-
 arch/x86/events/perf_event.h |  9 ++++-----
 3 files changed, 23 insertions(+), 7 deletions(-)

diff --git a/arch/x86/events/core.c b/arch/x86/events/core.c
index dbae103b01c6..0147d74752db 100644
--- a/arch/x86/events/core.c
+++ b/arch/x86/events/core.c
@@ -2157,10 +2157,13 @@ static int __init init_hw_perf_events(void)
 		if (err)
 			goto out2;
 	} else {
-		u8 cpu_type = get_hybrid_cpu_type(smp_processor_id());
 		struct x86_hybrid_pmu *hybrid_pmu;
+		u8 cpu_type = 0;
 		int i;
 
+		if (x86_pmu.get_hybrid_cpu_type)
+			cpu_type = x86_pmu.get_hybrid_cpu_type();
+
 		for (i = 0; i < x86_pmu.num_hybrid_pmus; i++) {
 			hybrid_pmu = &x86_pmu.hybrid_pmu[i];
 
diff --git a/arch/x86/events/intel/core.c b/arch/x86/events/intel/core.c
index f39a58d0f0ab..5ca3234491a4 100644
--- a/arch/x86/events/intel/core.c
+++ b/arch/x86/events/intel/core.c
@@ -4234,6 +4234,16 @@ static int adl_hw_config(struct perf_event *event)
 	return -EOPNOTSUPP;
 }
 
+static u8 adl_get_hybrid_cpu_type(void)
+{
+	u8 cpu_type = get_hybrid_cpu_type(smp_processor_id());
+
+	if (cpu_type)
+		return cpu_type;
+
+	return INTEL_HYBRID_TYPE_CORE;
+}
+
 /*
  * Broadwell:
  *
@@ -4487,11 +4497,14 @@ static void init_hybrid_pmu(int cpu)
 {
 	unsigned int fixed_mask, unused_eax, unused_ebx, unused_edx;
 	struct cpu_hw_events *cpuc = &per_cpu(cpu_hw_events, cpu);
-	u8 cpu_type = get_hybrid_cpu_type(cpu);
 	struct x86_hybrid_pmu *pmu = NULL;
 	struct perf_cpu_context *cpuctx;
+	u8 cpu_type = 0;
 	int i;
 
+	if (x86_pmu.get_hybrid_cpu_type)
+		cpu_type = x86_pmu.get_hybrid_cpu_type();
+
 	for (i = 0; i < x86_pmu.num_hybrid_pmus; i++) {
 		if (x86_pmu.hybrid_pmu[i].cpu_type == cpu_type) {
 			pmu = &x86_pmu.hybrid_pmu[i];
@@ -6479,6 +6492,7 @@ __init int intel_pmu_init(void)
 		x86_pmu.get_event_constraints = mtl_h_get_event_constraints;
 		x86_pmu.hw_config = adl_hw_config;
 		x86_pmu.limit_period = spr_limit_period;
+		x86_pmu.get_hybrid_cpu_type = adl_get_hybrid_cpu_type;
 
 		/* PERF METRICS and PEBS via PT are not common features */
 		x86_pmu.intel_cap.perf_metrics = 0;
diff --git a/arch/x86/events/perf_event.h b/arch/x86/events/perf_event.h
index 083d9354b76b..83e85e759807 100644
--- a/arch/x86/events/perf_event.h
+++ b/arch/x86/events/perf_event.h
@@ -658,16 +658,14 @@ struct x86_hybrid_pmu {
 	struct extra_reg		*extra_regs;
 };
 
-static __always_inline bool is_hybrid(void)
-{
-	return unlikely(cpu_feature_enabled(X86_FEATURE_HYBRID_CPU));
-}
-
 static __always_inline struct x86_hybrid_pmu *hybrid_pmu(struct pmu *pmu)
 {
 	return container_of(pmu, struct x86_hybrid_pmu, pmu);
 }
 
+/* The number of hybrid PMUs implies a hybrid system */
+#define is_hybrid()			(!!x86_pmu.num_hybrid_pmus)
+
 #define hybrid(_pmu, _field)				\
 ({							\
 	typeof(x86_pmu._field) __F = x86_pmu._field;	\
@@ -887,6 +885,7 @@ struct x86_pmu {
 	 */
 	int 				num_hybrid_pmus;
 	struct x86_hybrid_pmu		*hybrid_pmu;
+	u8 (*get_hybrid_cpu_type)	(void);
 };
 
 struct x86_perf_task_context_opt {
-- 
2.27.0

