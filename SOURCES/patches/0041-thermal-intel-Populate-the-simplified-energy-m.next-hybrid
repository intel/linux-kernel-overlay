From 462689eef61bea978bd97affabb320f0078c85d6 Mon Sep 17 00:00:00 2001
From: Ricardo Neri <ricardo.neri-calderon@linux.intel.com>
Date: Sat, 28 Mar 2020 16:27:48 -0700
Subject: [PATCH 41/76] thermal: intel: Populate the simplified energy model

The Intel Hardware Feedback Interface delivers a per-CPU energy efficiency
rating. Deliver these ratings to the scheduler via the simplified energy
model.

The Intel Hardware Interface gives higher energy efficiency rating to more
efficient CPUs. However, the simple energy model and the scheduler make
task placement decisions based on CPUs with the lowest energy rating.
Hence, invert the energy ratings from HFI.

Also, if the energy ratings are too similar, the scheduler will not find
sufficient energy gains and placement decisions will be skewed towards
capacity. Hence, scale the energy ratings from HFI.

Signed-off-by: Ricardo Neri <ricardo.neri-calderon@linux.intel.com>
---
 drivers/thermal/intel/Kconfig     |   1 +
 drivers/thermal/intel/intel_hfi.c | 104 +++++++++++++++++++++++++++++-
 2 files changed, 103 insertions(+), 2 deletions(-)

diff --git a/drivers/thermal/intel/Kconfig b/drivers/thermal/intel/Kconfig
index ebfb7384ba29..a6f4279c4a18 100644
--- a/drivers/thermal/intel/Kconfig
+++ b/drivers/thermal/intel/Kconfig
@@ -95,6 +95,7 @@ config INTEL_HFI
 	bool "Intel Hardware Feedback Interface"
 	depends on CPU_SUP_INTEL
 	depends on SCHED_MC && X86_THERMAL_VECTOR
+	select ENERGY_MODEL
 	help
 	  Select this option to enable the Hardware Feedback Interface in
 	  Intel hybrid processors. If selected, hardware provides guidance to
diff --git a/drivers/thermal/intel/intel_hfi.c b/drivers/thermal/intel/intel_hfi.c
index 321b2be8e6aa..8d0c67428b0f 100644
--- a/drivers/thermal/intel/intel_hfi.c
+++ b/drivers/thermal/intel/intel_hfi.c
@@ -18,6 +18,7 @@
 
 #define pr_fmt(fmt)  "intel-hfi: " fmt
 
+#include <linux/cpu.h>
 #include <linux/cpuset.h>
 #include <linux/io.h>
 #include <linux/slab.h>
@@ -30,6 +31,9 @@
 /* Delay reading HFI updates a few milliseconds */
 #define HFI_UPDATE_DELAY (1000 / HZ)
 
+#define HFI_EFFICIENCY_SHIFT 10
+#define HFI_EFFICIENCY_SCALE (1L << HFI_EFFICIENCY_SHIFT)
+
 /**
  * struct hfi_cpu_data - Capabilities of a logical processor in the HFI table.
  *			 These capabilities are unitless.
@@ -134,6 +138,85 @@ unsigned long hfi_scale_cpu_capacity(int cpu)
 	return per_cpu(cpu_scale, cpu);
 }
 
+static void register_perf_domain_cpu(int cpu, unsigned long eff)
+{
+	struct em_perf_domain *em_pd = NULL;
+	unsigned long cpu_cap, sibling_cap;
+	int sibling, pd_sibling;
+
+	cpu_cap = arch_scale_cpu_capacity(cpu);
+
+	for_each_cpu(sibling, topology_cluster_cpumask(cpu)) {
+		sibling_cap = arch_scale_cpu_capacity(sibling);
+		/*
+		 * CPUs in the same domain must have the same capacity.
+		 * Siblings in a cluster may have different capacities
+		 * if they have not been initialized. In such case, the
+		 * last initialized CPU will register the perf domain.
+		 */
+		if (cpu_cap != sibling_cap)
+			return;
+
+		if (!em_pd) {
+			em_pd = em_cpu_get(sibling);
+			pd_sibling = sibling;
+		}
+	}
+
+	if (em_pd) {
+		em_dev_perf_domain_add_cpu(get_cpu_device(pd_sibling), cpu);
+		return;
+	}
+
+	em_dev_register_perf_domain_simple(get_cpu_device(cpu),
+					   topology_cluster_cpumask(cpu), eff);
+}
+
+/* must be called with hfi_lock */
+static void update_efficiency_cpu(unsigned long eff, int cpu)
+{
+	struct em_perf_domain *em_pd;
+
+	/* TODO: we should be able to iterate among one CPU per perf domain.
+	 * Iterating over each CPU results in updating the same perf domainn
+	 * with the same energy efficiency several times. This would require
+	 * the energy model to have a 'handling_cpu'. We cannot simoply skip
+	 * continuous CPUs as the cluster cpumask could have holes.
+	 *
+	 * Also, it assumes that cluster siblings of a cpu are a subset
+	 * of params->cpus. This must be true as thee latter are all the CPUs
+	 * in an HFI table, which are all the CPUs in a package.
+	 */
+
+	em_pd = em_cpu_get(cpu);
+	if (em_pd) {
+		em_dev_perf_domain_update_energy_rating(get_cpu_device(cpu), eff);
+		return;
+	}
+
+	register_perf_domain_cpu(cpu, eff);
+}
+
+static void scale_efficiency_cpu(u8 ee_cap, int cpu)
+{
+	unsigned long efficiency;
+
+	/*
+	 * The CPU with highest performance has not been found. This can
+	 * happen if a CPU comes online before the first HFI interrupt
+	 * happens.
+	 */
+	if (!class0_max_caps.ee_cap)
+		return;
+
+	efficiency = div64_u64(ee_cap << HFI_EFFICIENCY_SHIFT,
+			       class0_max_caps.ee_cap);
+
+	efficiency = 2048 - efficiency;
+
+	update_efficiency_cpu(efficiency, cpu);
+}
+
 static void get_one_hfi_cap(struct hfi_params *params, int cpu,
 			    struct hfi_cpu_data *hfi_caps)
 {
@@ -194,6 +277,7 @@ static void scale_capabilities(struct hfi_params *params)
 
 		get_one_hfi_cap(params, cpu, &caps);
 		scale_capacity_cpu(caps.perf_cap, cpu);
+		scale_efficiency_cpu(caps.ee_cap, cpu);
 	}
 }
 
@@ -227,11 +311,14 @@ static void rescale_all_capabilities(struct hfi_cpu_data *new_max_caps)
 
 		get_one_hfi_cap(params, cpu, &caps);
 		scale_capacity_cpu(caps.perf_cap, cpu);
+		scale_efficiency_cpu(caps.ee_cap, cpu);
 	}
 }
 
 static void init_asym_capacity(void)
 {
+	int cpu;
+
 	mutex_lock(&hfi_lock);
 	if (class0_max_caps.perf_cap == class0_min_caps.perf_cap)
 		goto out_unlock;
@@ -253,6 +340,17 @@ static void init_asym_capacity(void)
 	if (asym_capacity_initialized)
 		goto out_unlock;
 
+	/*
+	 * Make sure we only rebuild sched domains when all online CPUs have an
+	 * energy model.
+	 */
+	for_each_online_cpu(cpu) {
+		struct em_perf_domain *pd = em_cpu_get(cpu);
+
+		if (!pd)
+			goto out_unlock;
+	}
+
 	asym_capacity_initialized = true;
 	x86_topology_update = true;
 	mutex_unlock(&hfi_lock);
@@ -534,10 +632,12 @@ int enable_hfi(unsigned int cpu)
 
 		/* If we found the biggest CPU, rescale all capacities */
 		if (caps.perf_cap > class0_max_caps.perf_cap ||
-		    caps.ee_cap > class0_max_caps.ee_cap)
+		    caps.ee_cap > class0_max_caps.ee_cap) {
 			rescale_all_capabilities(&caps);
-		else
+		} else {
 			scale_capacity_cpu(caps.perf_cap, cpu);
+			scale_efficiency_cpu(caps.ee_cap, cpu);
+		}
 
 		schedule_work(&hfi_asym_capacity_work);
 		mutex_unlock(&hfi_lock);
-- 
2.27.0

