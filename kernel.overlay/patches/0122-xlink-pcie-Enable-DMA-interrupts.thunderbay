From 00aa6f8a991f54c0cc77ce56c1fd8c3508a65ec5 Mon Sep 17 00:00:00 2001
From: Srikanth Thokala <srikanth.thokala@intel.com>
Date: Thu, 4 Mar 2021 10:20:18 +0530
Subject: [PATCH 122/170] xlink-pcie: Enable DMA interrupts

Enable DMA interrupts

Signed-off-by: Srikanth Thokala <srikanth.thokala@intel.com>
---
 drivers/misc/xlink-pcie/local_host/dma.c | 129 ++++++++++++++++++++++-
 drivers/misc/xlink-pcie/local_host/epf.h |   4 +
 2 files changed, 131 insertions(+), 2 deletions(-)

diff --git a/drivers/misc/xlink-pcie/local_host/dma.c b/drivers/misc/xlink-pcie/local_host/dma.c
index e872f789a48e..267d33d9671d 100644
--- a/drivers/misc/xlink-pcie/local_host/dma.c
+++ b/drivers/misc/xlink-pcie/local_host/dma.c
@@ -151,6 +151,12 @@ enum xpcie_ep_engine_type {
 	READ_ENGINE
 };
 
+#if (IS_ENABLED(CONFIG_PCIE_TBH_EP))
+#define DMA_CHAN_NUM (8)
+#else
+#define DMA_CHAN_NUM (4)
+#endif
+
 static u32 dma_chan_offset[2][DMA_CHAN_NUM] = {
 #if (IS_ENABLED(CONFIG_PCIE_TBH_EP))
 	{ 0x200, 0x400, 0x600, 0x800, 0xA00, 0xC00, 0xE00, 0x1000 },
@@ -358,11 +364,18 @@ int intel_xpcie_ep_dma_write_ll(struct pci_epf *epf, int chan, int descs_num)
 	struct xpcie_dma_ll_desc_buf *desc_buf;
 	struct __iomem pcie_dma_reg * dma_reg =
 				(struct __iomem pcie_dma_reg *)(dma_base);
-	int i, rc;
+	int rc;
+#if (!IS_ENABLED(CONFIG_PCIE_TBH_EP))
+	int i;
+#endif
 
 	if (descs_num <= 0 || descs_num > XPCIE_NUM_TX_DESCS)
 		return -EINVAL;
 
+#if (IS_ENABLED(CONFIG_PCIE_TBH_EP))
+	chan = xpcie_epf->epf->func_no;
+#endif
+
 	if (chan < 0 || chan >= DMA_CHAN_NUM)
 		return -EINVAL;
 
@@ -373,6 +386,10 @@ int intel_xpcie_ep_dma_write_ll(struct pci_epf *epf, int chan, int descs_num)
 
 	intel_xpcie_ep_dma_setup_ll_descs(dma_chan, desc_buf, descs_num);
 
+#if (IS_ENABLED(CONFIG_PCIE_TBH_EP))
+	xpcie_epf->dma_wr_done = false;
+#endif
+
 	/* Start DMA transfer. */
 	rc = intel_xpcie_ep_dma_doorbell(xpcie_epf, chan,
 					 (void __iomem *)
@@ -380,6 +397,7 @@ int intel_xpcie_ep_dma_write_ll(struct pci_epf *epf, int chan, int descs_num)
 	if (rc)
 		return rc;
 
+#if (!IS_ENABLED(CONFIG_PCIE_TBH_EP))
 	/* Wait for DMA transfer to complete. */
 	for (i = 0; i < DMA_POLLING_TIMEOUT; i++) {
 		usleep_range(5, 10);
@@ -393,16 +411,23 @@ int intel_xpcie_ep_dma_write_ll(struct pci_epf *epf, int chan, int descs_num)
 		rc = -ETIME;
 		goto cleanup;
 	}
+#else
+	/* Wait for DMA transfer to complete. */
+	rc = wait_event_interruptible(xpcie_epf->dma_wr_wq,
+				      xpcie_epf->dma_wr_done);
+#endif
 
 	rc = intel_xpcie_ep_dma_err_status((void __iomem *)
 					   &dma_reg->dma_write_err_status,
 					   chan);
 
+#if (!IS_ENABLED(CONFIG_PCIE_TBH_EP))
 cleanup:
 	/* Clear the done/abort interrupt. */
 	iowrite32((DMA_DONE_INTERRUPT_CH_MASK(chan) |
 		   DMA_ABORT_INTERRUPT_CH_MASK(chan)),
 		  (void __iomem *)&dma_reg->dma_write_int_clear);
+#endif
 
 	if (rc) {
 		if (intel_xpcie_ep_dma_disable(dma_base, WRITE_ENGINE)) {
@@ -424,11 +449,18 @@ int intel_xpcie_ep_dma_read_ll(struct pci_epf *epf, int chan, int descs_num)
 	struct __iomem pcie_dma_reg * dma_reg =
 				(struct __iomem pcie_dma_reg *)(dma_base);
 	struct __iomem pcie_dma_chan * dma_chan;
-	int i, rc;
+	int rc;
+#if (!IS_ENABLED(CONFIG_PCIE_TBH_EP))
+	int i;
+#endif
 
 	if (descs_num <= 0 || descs_num > XPCIE_NUM_RX_DESCS)
 		return -EINVAL;
 
+#if (IS_ENABLED(CONFIG_PCIE_TBH_EP))
+	chan = xpcie_epf->epf->func_no;
+#endif
+
 	if (chan < 0 || chan >= DMA_CHAN_NUM)
 		return -EINVAL;
 
@@ -439,6 +471,10 @@ int intel_xpcie_ep_dma_read_ll(struct pci_epf *epf, int chan, int descs_num)
 
 	intel_xpcie_ep_dma_setup_ll_descs(dma_chan, desc_buf, descs_num);
 
+#if (IS_ENABLED(CONFIG_PCIE_TBH_EP))
+	xpcie_epf->dma_rd_done = false;
+#endif
+
 	/* Start DMA transfer. */
 	rc = intel_xpcie_ep_dma_doorbell(xpcie_epf, chan,
 					 (void __iomem *)
@@ -446,6 +482,7 @@ int intel_xpcie_ep_dma_read_ll(struct pci_epf *epf, int chan, int descs_num)
 	if (rc)
 		return rc;
 
+#if (!IS_ENABLED(CONFIG_PCIE_TBH_EP))
 	/* Wait for DMA transfer to complete. */
 	for (i = 0; i < DMA_POLLING_TIMEOUT; i++) {
 		usleep_range(5, 10);
@@ -459,6 +496,11 @@ int intel_xpcie_ep_dma_read_ll(struct pci_epf *epf, int chan, int descs_num)
 		rc = -ETIME;
 		goto cleanup;
 	}
+#else
+	/* Wait for DMA transfer to complete. */
+	rc = wait_event_interruptible(xpcie_epf->dma_rd_wq,
+				      xpcie_epf->dma_rd_done);
+#endif
 
 	rc = intel_xpcie_ep_dma_err_status((void __iomem *)
 					   &dma_reg->dma_read_err_status_low,
@@ -469,11 +511,14 @@ int intel_xpcie_ep_dma_read_ll(struct pci_epf *epf, int chan, int descs_num)
 						&dma_reg->dma_rd_err_sts_h,
 						chan);
 	}
+
+#if (!IS_ENABLED(CONFIG_PCIE_TBH_EP))
 cleanup:
 	/* Clear the done/abort interrupt. */
 	iowrite32((DMA_DONE_INTERRUPT_CH_MASK(chan) |
 		   DMA_ABORT_INTERRUPT_CH_MASK(chan)),
 		  (void __iomem *)&dma_reg->dma_read_int_clear);
+#endif
 
 	if (rc) {
 		if (intel_xpcie_ep_dma_disable(dma_base, READ_ENGINE)) {
@@ -565,6 +610,57 @@ int intel_xpcie_ep_dma_reset(struct pci_epf *epf)
 	return 0;
 }
 
+static irqreturn_t intel_xpcie_ep_dma_wr_interrupt(int irq, void *args)
+{
+	struct xpcie_epf *xpcie_epf = args;
+	void __iomem *dma_base = xpcie_epf->dma_base;
+	struct pcie_dma_reg *dma_reg = (struct pcie_dma_reg *)dma_base;
+	struct pcie_dma_chan *dma_chan;
+#if (IS_ENABLED(CONFIG_PCIE_TBH_EP))
+	int chan = xpcie_epf->epf->func_no;
+#endif
+	dma_chan = (struct pcie_dma_chan *)
+		(dma_base + dma_chan_offset[WRITE_ENGINE][chan]);
+
+	if (ioread32(&dma_reg->dma_write_int_status) &
+		(DMA_ABORT_INTERRUPT_CH_MASK(chan) |
+		 DMA_DONE_INTERRUPT_CH_MASK(chan))) {
+		iowrite32(DMA_DONE_INTERRUPT_CH_MASK(chan),
+			  &dma_reg->dma_write_int_clear);
+
+		xpcie_epf->dma_wr_done = true;
+		wake_up_interruptible(&xpcie_epf->dma_wr_wq);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t intel_xpcie_ep_dma_rd_interrupt(int irq, void *args)
+{
+	struct xpcie_epf *xpcie_epf = args;
+	void __iomem *dma_base = xpcie_epf->dma_base;
+	struct pcie_dma_reg *dma_reg = (struct pcie_dma_reg *)dma_base;
+	struct pcie_dma_chan *dma_chan;
+#if (IS_ENABLED(CONFIG_PCIE_TBH_EP))
+	int chan = xpcie_epf->epf->func_no;
+#endif
+
+	dma_chan = (struct pcie_dma_chan *)
+		(dma_base + dma_chan_offset[READ_ENGINE][chan]);
+
+	if (ioread32(&dma_reg->dma_read_int_status) &
+		(DMA_ABORT_INTERRUPT_CH_MASK(chan) |
+		 DMA_DONE_INTERRUPT_CH_MASK(chan))) {
+		iowrite32(DMA_DONE_INTERRUPT_CH_MASK(chan),
+			  &dma_reg->dma_read_int_clear);
+
+		xpcie_epf->dma_rd_done = true;
+		wake_up_interruptible(&xpcie_epf->dma_rd_wq);
+	}
+
+	return IRQ_HANDLED;
+}
+
 int intel_xpcie_ep_dma_uninit(struct pci_epf *epf)
 {
 	struct xpcie_epf *xpcie_epf = epf_get_drvdata(epf);
@@ -573,6 +669,13 @@ int intel_xpcie_ep_dma_uninit(struct pci_epf *epf)
 	    intel_xpcie_ep_dma_disable(xpcie_epf->dma_base, READ_ENGINE))
 		return -EBUSY;
 
+#if (IS_ENABLED(CONFIG_PCIE_TBH_EP))
+	if (xpcie_epf->irq_rdma)
+		free_irq(xpcie_epf->irq_rdma, xpcie_epf);
+	if (xpcie_epf->irq_wdma)
+		free_irq(xpcie_epf->irq_wdma, xpcie_epf);
+#endif
+
 	intel_xpcie_ep_dma_free_ll_descs_mem(xpcie_epf);
 
 	return 0;
@@ -589,5 +692,27 @@ int intel_xpcie_ep_dma_init(struct pci_epf *epf)
 	if (rc)
 		return rc;
 
+#if (IS_ENABLED(CONFIG_PCIE_TBH_EP))
+	init_waitqueue_head(&xpcie_epf->dma_rd_wq);
+	init_waitqueue_head(&xpcie_epf->dma_wr_wq);
+
+	rc = request_irq(xpcie_epf->irq_rdma, &intel_xpcie_ep_dma_rd_interrupt,
+			 0, "xpcie_epf_rd_dma", xpcie_epf);
+	if (rc) {
+		pr_err("intel_xpcie_ep_dma: Failed to request read intr\n");
+		intel_xpcie_ep_dma_free_ll_descs_mem(xpcie_epf);
+		return rc;
+	}
+
+	rc = request_irq(xpcie_epf->irq_wdma, &intel_xpcie_ep_dma_wr_interrupt,
+			 0, "xpcie_epf_wr_dma", xpcie_epf);
+	if (rc) {
+		pr_err("intel_xpcie_ep_dma: Failed to request write intr\n");
+		free_irq(xpcie_epf->irq_rdma, xpcie_epf);
+		intel_xpcie_ep_dma_free_ll_descs_mem(xpcie_epf);
+		return rc;
+	}
+#endif
+
 	return intel_xpcie_ep_dma_reset(epf);
 }
diff --git a/drivers/misc/xlink-pcie/local_host/epf.h b/drivers/misc/xlink-pcie/local_host/epf.h
index fb63e4f6f2ca..08107896351c 100644
--- a/drivers/misc/xlink-pcie/local_host/epf.h
+++ b/drivers/misc/xlink-pcie/local_host/epf.h
@@ -74,6 +74,10 @@ struct xpcie_epf {
 	int                             irq_doorbell;
 	int                             irq_rdma;
 	int                             irq_wdma;
+	wait_queue_head_t		dma_rd_wq;
+	bool				dma_rd_done;
+	wait_queue_head_t		dma_wr_wq;
+	bool				dma_wr_done;
 #else
 	int irq_dma;
 	int irq_err;
-- 
2.27.0

