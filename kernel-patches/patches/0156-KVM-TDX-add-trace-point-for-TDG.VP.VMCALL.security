From 3bec53279e53f94655b4ae357b346d6ef1c14f28 Mon Sep 17 00:00:00 2001
From: Isaku Yamahata <isaku.yamahata@intel.com>
Date: Sun, 27 Mar 2022 01:02:05 -0700
Subject: [PATCH 156/163] KVM: TDX: add trace point for TDG.VP.VMCALL

Signed-off-by: Isaku Yamahata <isaku.yamahata@intel.com>
---
 arch/x86/kvm/trace.h   | 107 +++++++++++++++++++++++++++++++++++++++++
 arch/x86/kvm/vmx/tdx.c |  53 +++++++++++++-------
 arch/x86/kvm/x86.c     |   2 +
 3 files changed, 145 insertions(+), 17 deletions(-)

diff --git a/arch/x86/kvm/trace.h b/arch/x86/kvm/trace.h
index 83843379813e..4e9c4904faaa 100644
--- a/arch/x86/kvm/trace.h
+++ b/arch/x86/kvm/trace.h
@@ -8,6 +8,8 @@
 #include <asm/clocksource.h>
 #include <asm/pvclock-abi.h>
 
+#include "vmx/tdx_arch.h"
+
 #undef TRACE_SYSTEM
 #define TRACE_SYSTEM kvm
 
@@ -146,7 +148,112 @@ TRACE_EVENT(kvm_xen_hypercall,
 		  __entry->a3, __entry->a4, __entry->a5)
 );
 
+#define TDG_VP_VMCALL_NAME(x) {x, #x}
+
+#define kvm_trace_symbol_tdvmcall				\
+	TDG_VP_VMCALL_NAME(EXIT_REASON_CPUID),			\
+	TDG_VP_VMCALL_NAME(EXIT_REASON_HLT),			\
+	TDG_VP_VMCALL_NAME(EXIT_REASON_IO_INSTRUCTION),		\
+	TDG_VP_VMCALL_NAME(EXIT_REASON_EPT_VIOLATION),		\
+	TDG_VP_VMCALL_NAME(EXIT_REASON_MSR_READ),		\
+	TDG_VP_VMCALL_NAME(EXIT_REASON_MSR_WRITE),		\
+	TDG_VP_VMCALL_NAME(TDG_VP_VMCALL_GET_TD_VM_CALL_INFO),	\
+	TDG_VP_VMCALL_NAME(TDG_VP_VMCALL_MAP_GPA),		\
+	TDG_VP_VMCALL_NAME(TDG_VP_VMCALL_GET_QUOTE),		\
+	TDG_VP_VMCALL_NAME(TDG_VP_VMCALL_REPORT_FATAL_ERROR),	\
+	TDG_VP_VMCALL_NAME(TDG_VP_VMCALL_SETUP_EVENT_NOTIFY_INTERRUPT)
+
+TRACE_EVENT(kvm_tdx_hypercall,
+	TP_PROTO(__u64 subfunction, __u64 reg_mask, __u64 r12, __u64 r13,
+		 __u64 r14, __u64 rbx, __u64 rdi, __u64 rsi, __u64 r8, __u64 r9,
+		 __u64 rdx),
+
+	TP_ARGS(subfunction, reg_mask, r12, r13, r14, rbx, rdi, rsi, r8, r9, rdx),
+
+	TP_STRUCT__entry(
+		__field(__u64,		subfunction)
+		__field(__u64,		reg_mask)
+		__field(__u64,		r12)
+		__field(__u64,		r13)
+		__field(__u64,		r14)
+		__field(__u64,		rbx)
+		__field(__u64,		rdi)
+		__field(__u64,		rsi)
+		__field(__u64,		r8)
+		__field(__u64,		r9)
+		__field(__u64,		rdx)
+	),
+
+	TP_fast_assign(
+		__entry->subfunction	= subfunction;
+		__entry->reg_mask	= reg_mask;
+		__entry->r12		= r12;
+		__entry->r13		= r13;
+		__entry->r14		= r14;
+		__entry->rbx		= rbx;
+		__entry->rdi		= rdi;
+		__entry->rsi		= rsi;
+		__entry->r8		= r8;
+		__entry->r9		= r9;
+		__entry->rdx		= rdx;
+	),
 
+	TP_printk("%s reg_mask 0x%llx r12 0x%llx r13 0x%llx r14 0x%llx "
+		  "rbx 0x%llx rdi 0x%llx rsi 0x%llx r8 0x%llx r9 0x%llx "
+		  "rdx 0x%llx",
+		  __print_symbolic(__entry->subfunction,
+				   kvm_trace_symbol_tdvmcall),
+		  __entry->reg_mask, __entry->r12, __entry->r13, __entry->r14,
+		  __entry->rbx, __entry->rdi, __entry->rsi, __entry->r8,
+		  __entry->r9, __entry->rdx)
+);
+
+TRACE_EVENT(kvm_tdx_hypercall_done,
+	TP_PROTO(int r, __u64 subfunction, __u64 status_code, __u64 r12, __u64 r13,
+		 __u64 r14, __u64 rbx, __u64 rdi, __u64 rsi, __u64 r8, __u64 r9,
+		__u64 rdx),
+	TP_ARGS(r, subfunction, status_code, r12, r13, r14, rbx, rdi, rsi, r8, r9, rdx),
+
+	TP_STRUCT__entry(
+		__field(int,		r)
+		__field(__u64,		subfunction)
+		__field(__u64,		status_code)
+		__field(__u64,		r12)
+		__field(__u64,		r13)
+		__field(__u64,		r14)
+		__field(__u64,		rbx)
+		__field(__u64,		rdi)
+		__field(__u64,		rsi)
+		__field(__u64,		r8)
+		__field(__u64,		r9)
+		__field(__u64,		rdx)
+	),
+
+	TP_fast_assign(
+		__entry->r		= r;
+		__entry->subfunction	= subfunction;
+		__entry->status_code	= status_code;
+		__entry->r12		= r12;
+		__entry->r13		= r13;
+		__entry->r14		= r14;
+		__entry->rbx		= rbx;
+		__entry->rdi		= rdi;
+		__entry->rsi		= rsi;
+		__entry->r8		= r8;
+		__entry->r9		= r9;
+		__entry->rdx		= rdx;
+	),
+
+	TP_printk("%s r 0x%x status_code 0x%llx r12 0x%llx r13 0x%llx r14 0x%llx "
+		  "rbx 0x%llx rdi 0x%llx rsi 0x%llx r8 0x%llx r9 0x%llx "
+		  "rdx 0x%llx",
+		  __print_symbolic(__entry->subfunction,
+				   kvm_trace_symbol_tdvmcall),
+		  __entry->r, __entry->status_code,
+		  __entry->r12, __entry->r13, __entry->r14, __entry->rbx,
+		  __entry->rdi, __entry->rsi, __entry->r8, __entry->r9,
+		  __entry->rdx)
+);
 
 /*
  * Tracepoint for PIO.
diff --git a/arch/x86/kvm/vmx/tdx.c b/arch/x86/kvm/vmx/tdx.c
index a18c73c6c6ba..ff48e5d52f32 100644
--- a/arch/x86/kvm/vmx/tdx.c
+++ b/arch/x86/kvm/vmx/tdx.c
@@ -1467,38 +1467,57 @@ static int tdx_get_td_vm_call_info(struct kvm_vcpu *vcpu)
 
 static int handle_tdvmcall(struct kvm_vcpu *vcpu)
 {
+	int r;
+
 	if (tdvmcall_exit_type(vcpu))
 		return tdx_emulate_vmcall(vcpu);
 
+	trace_kvm_tdx_hypercall(tdvmcall_leaf(vcpu), kvm_rcx_read(vcpu),
+				kvm_r12_read(vcpu), kvm_r13_read(vcpu), kvm_r14_read(vcpu),
+				kvm_rbx_read(vcpu), kvm_rdi_read(vcpu), kvm_rsi_read(vcpu),
+				kvm_r8_read(vcpu), kvm_r9_read(vcpu), kvm_rdx_read(vcpu));
+
 	switch (tdvmcall_leaf(vcpu)) {
 	case EXIT_REASON_CPUID:
-		return tdx_emulate_cpuid(vcpu);
+		r = tdx_emulate_cpuid(vcpu);
+		break;
 	case EXIT_REASON_HLT:
-		return tdx_emulate_hlt(vcpu);
+		r = tdx_emulate_hlt(vcpu);
+		break;
 	case EXIT_REASON_IO_INSTRUCTION:
-		return tdx_emulate_io(vcpu);
+		r = tdx_emulate_io(vcpu);
+		break;
 	case EXIT_REASON_EPT_VIOLATION:
-		return tdx_emulate_mmio(vcpu);
+		r = tdx_emulate_mmio(vcpu);
+		break;
 	case EXIT_REASON_MSR_READ:
-		return tdx_emulate_rdmsr(vcpu);
+		r = tdx_emulate_rdmsr(vcpu);
+		break;
 	case EXIT_REASON_MSR_WRITE:
-		return tdx_emulate_wrmsr(vcpu);
+		r = tdx_emulate_wrmsr(vcpu);
+		break;
 	case TDG_VP_VMCALL_GET_TD_VM_CALL_INFO:
-		return tdx_get_td_vm_call_info(vcpu);
+		r = tdx_get_td_vm_call_info(vcpu);
+		break;
 	default:
+		/*
+		 * Unknown VMCALL.  Toss the request to the user space VMM,
+		 * e.g. qemu, as it may know how to handle.
+		 *
+		 * Those VMCALLs require user space VMM:
+		 * TDG_VP_VMCALL_REPORT_FATAL_ERROR, TDG_VP_VMCALL_MAP_GPA,
+		 * TDG_VP_VMCALL_SETUP_EVENT_NOTIFY_INTERRUPT, and
+		 * TDG_VP_VMCALL_GET_QUOTE.
+		 */
+		r = tdx_vp_vmcall_to_user(vcpu);
 		break;
 	}
 
-	/*
-	 * Unknown VMCALL.  Toss the request to the user space VMM, e.g. qemu,
-	 * as it may know how to handle.
-	 *
-	 * Those VMCALLs require user space VMM:
-	 * TDG_VP_VMCALL_REPORT_FATAL_ERROR, TDG_VP_VMCALL_MAP_GPA,
-	 * TDG_VP_VMCALL_SETUP_EVENT_NOTIFY_INTERRUPT, and
-	 * TDG_VP_VMCALL_GET_QUOTE.
-	 */
-	return tdx_vp_vmcall_to_user(vcpu);
+	trace_kvm_tdx_hypercall_done(r, kvm_r11_read(vcpu), kvm_r10_read(vcpu),
+				     kvm_r12_read(vcpu), kvm_r13_read(vcpu), kvm_r14_read(vcpu),
+				     kvm_rbx_read(vcpu), kvm_rdi_read(vcpu), kvm_rsi_read(vcpu),
+				     kvm_r8_read(vcpu), kvm_r9_read(vcpu), kvm_rdx_read(vcpu));
+	return r;
 }
 
 void tdx_load_mmu_pgd(struct kvm_vcpu *vcpu, hpa_t root_hpa, int pgd_level)
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 161e5f41497f..92d07bc697b5 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -13962,6 +13962,8 @@ EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_vmgexit_enter);
 EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_vmgexit_exit);
 EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_vmgexit_msr_protocol_enter);
 EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_vmgexit_msr_protocol_exit);
+EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_tdx_hypercall);
+EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_tdx_hypercall_done);
 
 static int __init kvm_x86_init(void)
 {
-- 
2.25.1

