From 7e0183fca28ca13364555ea767a3875cd9ddd5e5 Mon Sep 17 00:00:00 2001
From: Ricardo Neri <ricardo.neri-calderon@linux.intel.com>
Date: Sat, 28 Mar 2020 15:42:50 -0700
Subject: [PATCH 23/72] x86/sched: Use HFI to define CPU capacity

The Intel Hardware Feedback Interface (HFI) table provides a performance
capability per logical processor. Use the performance capability of the
HFI table to set the per-CPU cpu_scale parameter. Update such capacities
whenever hardware signals (via a thermal interrupt) that the HFI table has
changed.

Since the HFI table defines different performance capabilities for each
logical processor, the flag SD_ASYM_CAPACITY must be set in the "MC"
scheduling domain. However, by the time we receive the first HFI update
the scheduling domains have been defined using identical capacities for
all CPUs. Thus, the mentioned flag was not set. Rebuild the scheduling
domains only at the first HFI update to reflect the fact that now
capacities are asymmetric. Subsequent capacity updates, if any, will
continue being asymmetric and the scheduling domains do not need to be
rebuilt.

Lastly, Intel has also published the specification of the Enhanced
Hardware Feedback Interface (EHFI). This interface introduces the concept
of classes of workloads. Classes of workloads have different performance
as CPUs are optimized to execute specific sets of instructions with higher
performance. Class 0 is a generic class and can be applied to the majority
of workloads. Also, Class 0 of the EHFI is simply the HFI.

Cc: Andi Kleen <ak@linux.intel.com>
Cc: Aubrey Li <aubrey.li@linux.intel.com>
Cc: Len Brown <len.brown@intel.com>
Cc: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
Cc: Tim Chen <tim.c.chen@linux.intel.com>
Cc: "Ravi V. Shankar" <ravi.v.shankar@intel.com>
Signed-off-by: Ricardo Neri <ricardo.neri-calderon@linux.intel.com>
---
Changes since v4:
  * Removed init_asymmetric_capacity() to set the SD_ASYM_CAPACITY flag.
    Instead, obtain the same result by rebuilding the scheduling domains
    only during the first HFI update. (Len)
  * Removed unnecessary pr_debug statements. (Srinivas)
  * Ignore HFI updates if performance capability is reported as zero for
    all CPUs. (Len)
  * Fix bug when setting the SD_ASYM_CAPACITY. It was previously being set
    on a single "SMT" domain, which broke find_energy_efficient_cpu().
  * Reworked update_capacity() to use EHFI class 0 when the EHFI is
    present.
  * Carve functionality to read the HFI performance data out of
    update_capacity() and put it in a separate function
    get_hfi_performance_cap().
  * Compare the HFI table timestamp against a single static global variable
    instead of per-CPU instances.

Changes since v3:
 * Removed custom capacity normalization code and instead use the existing
   topology_normalize_cpu_scale(). This requires the use of a raw_capacity
   array.
 * Removed unnecessary calls to rebuild_sched_domains(). (Srinivas)
 * Do not rebuild scheduling domains at every HFI update. Instead, enable
   asymmetric capacity at boot. (Srinivas)
 * Improved inline comments. (PeterZ)

Changes since v2:
 * Introduce this patch

Changes since v1:
 * N/A
---
 arch/x86/include/asm/hfi.h      |   1 +
 arch/x86/include/asm/topology.h |   6 ++
 arch/x86/platform/intel/hfi.c   | 112 +++++++++++++++++++++++++++++++-
 3 files changed, 116 insertions(+), 3 deletions(-)

diff --git a/arch/x86/include/asm/hfi.h b/arch/x86/include/asm/hfi.h
index fd7154255e1e..15ba88821830 100644
--- a/arch/x86/include/asm/hfi.h
+++ b/arch/x86/include/asm/hfi.h
@@ -28,6 +28,7 @@
 void hfi_setup_cpu(struct cpuinfo_x86 *c);
 void enable_hfi(void);
 void intel_hfi_check_event(__u64 pkg_therm_status_msr_val);
+unsigned long hfi_scale_cpu_capacity(int cpu);
 #else
 static inline void hfi_setup_cpu(struct cpuinfo_x86 *c) { }
 static inline void enable_hfi(void) { }
diff --git a/arch/x86/include/asm/topology.h b/arch/x86/include/asm/topology.h
index aa736b970119..fee816141d38 100644
--- a/arch/x86/include/asm/topology.h
+++ b/arch/x86/include/asm/topology.h
@@ -32,6 +32,8 @@
  */
 #include <linux/numa.h>
 
+#include <asm/hfi.h>
+
 #ifdef CONFIG_NUMA
 #include <linux/cpumask.h>
 
@@ -225,4 +227,8 @@ void init_freq_invariance_cppc(void);
 
 #define CPUTYPES_MAX_NR 2
 
+#ifdef CONFIG_INTEL_HFI
+#define arch_scale_cpu_capacity hfi_scale_cpu_capacity
+#endif
+
 #endif /* _ASM_X86_TOPOLOGY_H */
diff --git a/arch/x86/platform/intel/hfi.c b/arch/x86/platform/intel/hfi.c
index abdb54ecea66..4b2d16269026 100644
--- a/arch/x86/platform/intel/hfi.c
+++ b/arch/x86/platform/intel/hfi.c
@@ -18,8 +18,10 @@
 
 #define pr_fmt(fmt)  "intel-hfi: " fmt
 
-#include <linux/io.h>
+#include <linux/cpuset.h>
 #include <linux/gfp.h>
+#include <linux/io.h>
+#include <linux/slab.h>
 
 #include <asm/hfi.h>
 
@@ -70,7 +72,69 @@ struct hfi_params {
 /* CPU's indexes (i.e., rows) in the HFI table */
 static DEFINE_PER_CPU(s16, hfi_cpu_index) = -1;
 
+static bool asym_capacity_initialized;
 static struct hfi_params hfi_params;
+static u64 hfi_timestamp;
+static u32 *raw_data;
+
+unsigned long hfi_scale_cpu_capacity(int cpu)
+{
+	return per_cpu(cpu_scale, cpu);
+}
+
+static int get_hfi_performance_cap(void)
+{
+	u32 max_perf = 0;
+	int cpu;
+
+	/*
+	 * do_topology_normalize_cpu_scale() iterates on cpu_possible_mask.
+	 * However, capacity must be scaled scale capacity considering only
+	 * online CPUs. Thus, clear raw_data in case a high-capacity CPU
+	 * went offline since the last time capacities were updated.
+	 */
+	memset(raw_data, 0, num_possible_cpus() * sizeof(*raw_data));
+
+	/* First read the HFI table to get raw capacities. */
+	for_each_online_cpu(cpu) {
+		struct hfi_cpu_data *data;
+		s16 index;
+
+		index = per_cpu(hfi_cpu_index, cpu);
+
+		/* Find the performance data of @cpu */
+		data = hfi_params.data + index * hfi_params.cpu_stride;
+		raw_data[cpu] = data->perf_cap;
+
+		max_perf = max(max_perf, raw_data[cpu]);
+	}
+
+	/* If the HFI table has all zeros, ignore this update. */
+	if (!max_perf)
+		return -EINVAL;
+
+	return 0;
+}
+
+/*
+ * Call update_capacity() when there are changes in the HFI table.
+ */
+static void update_capacity(void)
+{
+	struct hfi_hdr *hdr = hfi_params.hdr;
+
+	if (!hdr->perf_updated)
+		return;
+
+	/* Read data from the HFI table. */
+	if (get_hfi_performance_cap())
+		return;
+
+	/* Now scale capacities to the range [1, SCHED_CAPACITY_SCALE] */
+	do_topology_normalize_cpu_scale(raw_data);
+
+	hdr->perf_updated = 0;
+}
 
 static void hfi_update_work_fn(struct work_struct *work)
 {
@@ -86,7 +150,38 @@ static void hfi_update_work_fn(struct work_struct *work)
 	if (!(msr_val & PACKAGE_THERM_STATUS_HFI_UPDATED))
 		return;
 
-	/* TODO: Update capacity here. */
+	/*
+	 * Sanity check that the timestamp moved forward before consuming
+	 * the table update.
+	 */
+	if (hfi_timestamp >= *hfi_params.ts_counter) {
+		pr_err_once("Updated HFI timestamp is in the past. FW bug?\n");
+		return;
+	}
+
+	hfi_timestamp = *hfi_params.ts_counter;
+
+	update_capacity();
+
+	/*
+	 * Using the HFI means that not all CPUs will have the same capacity.
+	 * Thus,  the "MC" scheduling domain should have the SD_ASYM_CPUCAPACITY
+	 * flag set. Given that by the time we have the first HFI update the
+	 * scheduling domains have been built. Flags of the scheduling domains
+	 * are evaluated when rebuilding them. However, it is not necessary to
+	 * rebuild them every time there is a change in CPU capacities, as they
+	 * will continue to be asymmetric. Thus, rebuild capacity domains only
+	 * in the first HFI update.
+	 *
+	 * We are sure that SD_ASYM_CPUCAPACITY will be set only in the "MC"
+	 * domain and not in the "SMT" domain since all SMT siblings have the
+	 * same capacity.
+	 */
+	if (!asym_capacity_initialized) {
+		x86_topology_update = true;
+		rebuild_sched_domains();
+		asym_capacity_initialized = true;
+	}
 
 	/*
 	 * Let hardware and other CPUs know that we are done reading the HFI
@@ -223,6 +318,12 @@ static void __init intel_hfi_init(void)
 		return;
 	}
 
+	raw_data = kcalloc(num_possible_cpus(), sizeof(*raw_data), GFP_KERNEL);
+	if (!raw_data) {
+		pr_err("No memory for raw data\n");
+		return;
+	}
+
 	/* The number of 4KB pages required by the table */
 	table_pages = ((reg & CPUID_HFI_TABLE_SIZE_MASK) >>
 		       CPUID_HFI_TABLE_SIZE_SHIFT) + 1;
@@ -235,7 +336,7 @@ static void __init intel_hfi_init(void)
 	table_base = alloc_pages_exact(table_pages, GFP_KERNEL | __GFP_ZERO);
 	if (!table_base) {
 		pr_err("Unable to allocate pages for table\n");
-		return;
+		goto free_raw_data;
 	}
 
 	table_base_pa = virt_to_phys(table_base);
@@ -245,5 +346,10 @@ static void __init intel_hfi_init(void)
 	wrmsrl(MSR_IA32_HW_FEEDBACK_PTR, msr_val);
 
 	init_hfi_params(table_base, capabilities);
+
+	return;
+
+free_raw_data:
+	kfree(raw_data);
 }
 device_initcall(intel_hfi_init);
-- 
2.27.0

