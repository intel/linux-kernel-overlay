From 60e26dc0ed62520af49c5539c920882cd9fae0d4 Mon Sep 17 00:00:00 2001
From: "Zawawi, Muhammad Zul Husni" <muhammad.zul.husni.zawawi@intel.com>
Date: Thu, 23 Jun 2022 09:41:19 +0800
Subject: [PATCH 2764/2779] drm/i915/gt: Add new GuC features

Adding extra GuC feature from DII_5668. This extra
feature to support latest SRIOV implementation.

Signed-off-by: Zawawi, Muhammad Zul Husni <muhammad.zul.husni.zawawi@intel.com>
---
 drivers/gpu/drm/i915/Makefile                 |   1 +
 drivers/gpu/drm/i915/gt/intel_gt.c            |  11 +-
 drivers/gpu/drm/i915/gt/intel_gt_regs.h       |   4 +-
 drivers/gpu/drm/i915/gt/intel_lrc.h           |   2 +
 .../gpu/drm/i915/gt/uc/abi/guc_actions_abi.h  |  35 +++++
 drivers/gpu/drm/i915/gt/uc/intel_guc.c        |  90 +++++++++++
 drivers/gpu/drm/i915/gt/uc/intel_guc.h        |  13 ++
 drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c     |  31 +++-
 drivers/gpu/drm/i915/gt/uc/intel_guc_fwif.h   |   6 +
 drivers/gpu/drm/i915/gt/uc/intel_guc_log.c    |  21 ++-
 drivers/gpu/drm/i915/gt/uc/intel_guc_log.h    |   2 +
 .../drm/i915/gt/uc/intel_guc_log_debugfs.c    |  57 ++++++-
 .../gpu/drm/i915/gt/uc/intel_guc_submission.c |  88 ++++++++++-
 drivers/gpu/drm/i915/gt/uc/intel_uc.c         |   7 +
 drivers/gpu/drm/i915/intel_pagefault.c        | 148 ++++++++++++++++++
 drivers/gpu/drm/i915/intel_pagefault.h        |  17 ++
 16 files changed, 504 insertions(+), 29 deletions(-)
 create mode 100644 drivers/gpu/drm/i915/intel_pagefault.c
 create mode 100644 drivers/gpu/drm/i915/intel_pagefault.h

diff --git a/drivers/gpu/drm/i915/Makefile b/drivers/gpu/drm/i915/Makefile
index f8cc1eb52626..42d668e628d7 100644
--- a/drivers/gpu/drm/i915/Makefile
+++ b/drivers/gpu/drm/i915/Makefile
@@ -184,6 +184,7 @@ i915-y += \
 	  i915_ttm_buddy_manager.o \
 	  i915_vma.o \
 	  i915_vma_resource.o \
+	  intel_pagefault.o \
 	  intel_wopcm.o
 
 # general-purpose microcontroller (GuC) support
diff --git a/drivers/gpu/drm/i915/gt/intel_gt.c b/drivers/gpu/drm/i915/gt/intel_gt.c
index d0b03a928b9a..ac868d669862 100644
--- a/drivers/gpu/drm/i915/gt/intel_gt.c
+++ b/drivers/gpu/drm/i915/gt/intel_gt.c
@@ -288,12 +288,12 @@ static void gen6_check_faults(struct intel_gt *gt)
 				"\tAddr: 0x%08lx\n"
 				"\tAddress space: %s\n"
 				"\tSource ID: %d\n"
-				"\tType: %d\n",
+				"\tLevel: %d\n",
 				fault & PAGE_MASK,
 				fault & RING_FAULT_GTTSEL_MASK ?
 				"GGTT" : "PPGTT",
 				RING_FAULT_SRCID(fault),
-				RING_FAULT_FAULT_TYPE(fault));
+				RING_FAULT_LEVEL(fault));
 		}
 	}
 }
@@ -330,12 +330,13 @@ static void gen8_check_faults(struct intel_gt *gt)
 			"\tAddress space: %s\n"
 			"\tEngine ID: %d\n"
 			"\tSource ID: %d\n"
-			"\tType: %d\n",
-			upper_32_bits(fault_addr), lower_32_bits(fault_addr),
+			"\tLevel: %d\n",
+			upper_32_bits(fault_addr),
+			lower_32_bits(fault_addr),
 			fault_data1 & FAULT_GTT_SEL ? "GGTT" : "PPGTT",
 			GEN8_RING_FAULT_ENGINE_ID(fault),
 			RING_FAULT_SRCID(fault),
-			RING_FAULT_FAULT_TYPE(fault));
+			RING_FAULT_LEVEL(fault));
 	}
 }
 
diff --git a/drivers/gpu/drm/i915/gt/intel_gt_regs.h b/drivers/gpu/drm/i915/gt/intel_gt_regs.h
index 2275ee47da95..7cdf388240ba 100644
--- a/drivers/gpu/drm/i915/gt/intel_gt_regs.h
+++ b/drivers/gpu/drm/i915/gt/intel_gt_regs.h
@@ -1032,10 +1032,12 @@
 #define   FAULT_GTT_SEL				(1 << 4)
 
 #define GEN12_RING_FAULT_REG			_MMIO(0xcec4)
+#define   GEN12_RING_FAULT_FAULT_TYPE(x)	(((x) >> 18) & 0x3)
+#define   GEN12_RING_FAULT_ACCESS_TYPE		(1 << 17)
 #define   GEN8_RING_FAULT_ENGINE_ID(x)		(((x) >> 12) & 0x7)
 #define   RING_FAULT_GTTSEL_MASK		(1 << 11)
 #define   RING_FAULT_SRCID(x)			(((x) >> 3) & 0xff)
-#define   RING_FAULT_FAULT_TYPE(x)		(((x) >> 1) & 0x3)
+#define   RING_FAULT_LEVEL(x)			(((x) >> 1) & 0x3)
 #define   RING_FAULT_VALID			(1 << 0)
 
 #define GEN12_GFX_TLB_INV_CR			_MMIO(0xced8)
diff --git a/drivers/gpu/drm/i915/gt/intel_lrc.h b/drivers/gpu/drm/i915/gt/intel_lrc.h
index a390f0813c8b..71c122ce1dd2 100644
--- a/drivers/gpu/drm/i915/gt/intel_lrc.h
+++ b/drivers/gpu/drm/i915/gt/intel_lrc.h
@@ -102,6 +102,8 @@ enum {
 #define GEN8_CTX_ID_WIDTH			21
 #define GEN11_SW_CTX_ID_SHIFT			37
 #define GEN11_SW_CTX_ID_WIDTH			11
+#define GEN11_SW_COUNTER_SHIFT			55
+#define GEN11_SW_COUNTER_WIDTH			6
 #define GEN11_ENGINE_CLASS_SHIFT		61
 #define GEN11_ENGINE_CLASS_WIDTH		3
 #define GEN11_ENGINE_INSTANCE_SHIFT		48
diff --git a/drivers/gpu/drm/i915/gt/uc/abi/guc_actions_abi.h b/drivers/gpu/drm/i915/gt/uc/abi/guc_actions_abi.h
index 29ef8afc8c2e..2442a3465007 100644
--- a/drivers/gpu/drm/i915/gt/uc/abi/guc_actions_abi.h
+++ b/drivers/gpu/drm/i915/gt/uc/abi/guc_actions_abi.h
@@ -137,6 +137,10 @@ enum intel_guc_action {
 	INTEL_GUC_ACTION_REGISTER_CONTEXT_MULTI_LRC = 0x4601,
 	INTEL_GUC_ACTION_CLIENT_SOFT_RESET = 0x5507,
 	INTEL_GUC_ACTION_SET_ENG_UTIL_BUFF = 0x550A,
+	INTEL_GUC_ACTION_NOTIFY_MEMORY_CAT_ERROR = 0x6000,
+	INTEL_GUC_ACTION_PAGE_FAULT_NOTIFICATION = 0x6001,
+	INTEL_GUC_ACTION_TLB_INVALIDATION = 0x7000,
+	INTEL_GUC_ACTION_TLB_INVALIDATION_DONE = 0x7001,
 	INTEL_GUC_ACTION_STATE_CAPTURE_NOTIFICATION = 0x8002,
 	INTEL_GUC_ACTION_NOTIFY_FLUSH_LOG_BUFFER_TO_FILE = 0x8003,
 	INTEL_GUC_ACTION_NOTIFY_CRASH_DUMP_POSTED = 0x8004,
@@ -180,4 +184,35 @@ enum intel_guc_state_capture_event_status {
 
 #define INTEL_GUC_STATE_CAPTURE_EVENT_STATUS_MASK      0x000000FF
 
+#define INTEL_GUC_TLB_INVAL_TYPE_SHIFT 0
+#define INTEL_GUC_TLB_INVAL_MODE_SHIFT 8
+/* Flush PPC or SMRO caches along with TLB invalidation request */
+#define INTEL_GUC_TLB_INVAL_FLUSH_CACHE (1 << 31)
+
+enum intel_guc_tlb_invalidation_type {
+	INTEL_GUC_TLB_INVAL_GUC = 0x3,
+};
+
+/*
+ * 0: Heavy mode of Invalidation:
+ * The pipeline of the engine(s) for which the invalidation is targeted to is
+ * blocked, and all the in-flight transactions are guaranteed to be Globally
+ * Observed before completing the TLB invalidation
+ * 1: Lite mode of Invalidation:
+ * TLBs of the targeted engine(s) are immediately invalidated.
+ * In-flight transactions are NOT guaranteed to be Globally Observed before
+ * completing TLB invalidation.
+ * Light Invalidation Mode is to be used only when
+ * it can be guaranteed (by SW) that the address translations remain invariant
+ * for the in-flight transactions across the TLB invalidation. In other words,
+ * this mode can be used when the TLB invalidation is intended to clear out the
+ * stale cached translations that are no longer in use. Light Invalidation Mode
+ * is much faster than the Heavy Invalidation Mode, as it does not wait for the
+ * in-flight transactions to be GOd.
+ */
+enum intel_guc_tlb_inval_mode {
+	INTEL_GUC_TLB_INVAL_MODE_HEAVY = 0x0,
+	INTEL_GUC_TLB_INVAL_MODE_LITE = 0x1,
+};
+
 #endif /* _ABI_GUC_ACTIONS_ABI_H */
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc.c b/drivers/gpu/drm/i915/gt/uc/intel_guc.c
index 27b09ba1d295..43f6e48869a5 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc.c
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc.c
@@ -842,6 +842,96 @@ int intel_guc_self_cfg64(struct intel_guc *guc, u16 key, u64 value)
 	return __guc_self_cfg(guc, key, 2, value);
 }
 
+static int guc_send_invalidate_tlb(struct intel_guc *guc, u32 *action, u32 size)
+{
+	struct intel_guc_tlb_wait _wq, *wq = &_wq;
+	DEFINE_WAIT_FUNC(wait, woken_wake_function);
+	int err = 0;
+	u32 seqno;
+
+	init_waitqueue_head(&_wq.wq);
+
+	if (xa_alloc_cyclic_irq(&guc->tlb_lookup, &seqno, wq,
+				xa_limit_32b, &guc->next_seqno,
+				GFP_ATOMIC | __GFP_NOWARN) < 0) {
+		/* Under severe memory pressure? Serialise TLB allocations */
+		xa_lock_irq(&guc->tlb_lookup);
+		wq = xa_load(&guc->tlb_lookup, guc->serial_slot);
+		wait_event_lock_irq(wq->wq,
+				    !READ_ONCE(wq->status),
+				    guc->tlb_lookup.xa_lock);
+		/*
+		 * Update wq->status under lock to ensure only one waiter can
+		 * issue the tlb invalidation command using the serial slot at a
+		 * time. The condition is set to false before releasing the lock
+		 * so that other caller continue to wait until woken up again.
+		 */
+		wq->status = 1;
+		xa_unlock_irq(&guc->tlb_lookup);
+
+		seqno = guc->serial_slot;
+	}
+
+	action[1] = seqno;
+
+	add_wait_queue(&wq->wq, &wait);
+
+	err = intel_guc_send_busy_loop(guc, action, size, G2H_LEN_DW_INVALIDATE_TLB, true);
+	if (err) {
+		/*
+		 * XXX: Failure of tlb invalidation is critical and would
+		 * warrant a gt reset.
+		 */
+		goto out;
+	}
+/*
+ * GuC has a timeout of 1ms for a tlb invalidation response from GAM. On a
+ * timeout GuC drops the request and has no mechanism to notify the host about
+ * the timeout. So keep a larger timeout that accounts for this individual
+ * timeout and max number of outstanding invalidation requests that can be
+ * queued in CT buffer.
+ */
+#define OUTSTANDING_GUC_TIMEOUT_PERIOD  (HZ)
+	if (!wait_woken(&wait, TASK_UNINTERRUPTIBLE,
+			OUTSTANDING_GUC_TIMEOUT_PERIOD)) {
+		/*
+		 * XXX: Failure of tlb invalidation is critical and would
+		 * warrant a gt reset.
+		 */
+		drm_err(&guc_to_gt(guc)->i915->drm,
+			 "tlb invalidation response timed out for seqno %u\n", seqno);
+		err = -ETIME;
+	}
+out:
+	remove_wait_queue(&wq->wq, &wait);
+	if (seqno != guc->serial_slot)
+		xa_erase_irq(&guc->tlb_lookup, seqno);
+
+	return err;
+}
+
+/*
+ * Guc TLB Invalidation: Invalidate the TLB's of GuC itself.
+ */
+int intel_guc_invalidate_tlb_guc(struct intel_guc *guc,
+				 enum intel_guc_tlb_inval_mode mode)
+{
+	u32 action[] = {
+		INTEL_GUC_ACTION_TLB_INVALIDATION,
+		0,
+		INTEL_GUC_TLB_INVAL_GUC << INTEL_GUC_TLB_INVAL_TYPE_SHIFT |
+			mode << INTEL_GUC_TLB_INVAL_MODE_SHIFT |
+			INTEL_GUC_TLB_INVAL_FLUSH_CACHE,
+	};
+
+	if (!INTEL_GUC_SUPPORTS_TLB_INVALIDATION(guc)) {
+		DRM_ERROR("Tlb invalidation: Operation not supported in this platform!\n");
+		return 0;
+	}
+
+	return guc_send_invalidate_tlb(guc, action, ARRAY_SIZE(action));
+}
+
 /**
  * intel_guc_load_status - dump information about GuC load status
  * @guc: the GuC
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc.h b/drivers/gpu/drm/i915/gt/uc/intel_guc.h
index 804133df1ac9..ed802ae24368 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc.h
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc.h
@@ -77,6 +77,10 @@ struct intel_guc {
 	atomic_t outstanding_submission_g2h;
 
 	/** @interrupts: pointers to GuC interrupt-managing functions. */
+	struct xarray tlb_lookup;
+	u32 serial_slot;
+	u32 next_seqno;
+
 	struct {
 		void (*reset)(struct intel_guc *guc);
 		void (*enable)(struct intel_guc *guc);
@@ -253,6 +257,11 @@ struct intel_guc {
 #endif
 };
 
+struct intel_guc_tlb_wait {
+	struct wait_queue_head wq;
+	u8 status;
+} __aligned(4);
+
 static inline struct intel_guc *log_to_guc(struct intel_guc_log *log)
 {
 	return container_of(log, struct intel_guc, log);
@@ -368,6 +377,9 @@ int intel_guc_allocate_and_map_vma(struct intel_guc *guc, u32 size,
 int intel_guc_self_cfg32(struct intel_guc *guc, u16 key, u32 value);
 int intel_guc_self_cfg64(struct intel_guc *guc, u16 key, u64 value);
 
+int intel_guc_invalidate_tlb_guc(struct intel_guc *guc,
+				 enum intel_guc_tlb_inval_mode mode);
+
 static inline bool intel_guc_is_supported(struct intel_guc *guc)
 {
 	return intel_uc_fw_is_supported(&guc->fw);
@@ -445,6 +457,7 @@ int intel_guc_engine_failure_process_msg(struct intel_guc *guc,
 					 const u32 *msg, u32 len);
 int intel_guc_error_capture_process_msg(struct intel_guc *guc,
 					const u32 *msg, u32 len);
+void intel_guc_tlb_invalidation_done(struct intel_guc *guc, u32 seqno);
 
 struct intel_engine_cs *
 intel_guc_lookup_engine(struct intel_guc *guc, u8 guc_class, u8 instance);
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c b/drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c
index 2b22065e87bf..3b7ef83751c2 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c
@@ -11,6 +11,7 @@
 
 #include "i915_drv.h"
 #include "intel_guc_ct.h"
+#include "intel_pagefault.h"
 #include "gt/intel_gt.h"
 
 static inline struct intel_guc *ct_to_guc(struct intel_guc_ct *ct)
@@ -1014,6 +1015,9 @@ static int ct_process_request(struct intel_guc_ct *ct, struct ct_incoming_msg *r
 	case INTEL_GUC_ACTION_CONTEXT_RESET_NOTIFICATION:
 		ret = intel_guc_context_reset_process_msg(guc, payload, len);
 		break;
+	case INTEL_GUC_ACTION_NOTIFY_MEMORY_CAT_ERROR:
+		ret = intel_pagefault_process_cat_error_msg(guc, payload, len);
+		break;
 	case INTEL_GUC_ACTION_STATE_CAPTURE_NOTIFICATION:
 		ret = intel_guc_error_capture_process_msg(guc, payload, len);
 		if (unlikely(ret))
@@ -1035,6 +1039,9 @@ static int ct_process_request(struct intel_guc_ct *ct, struct ct_incoming_msg *r
 		CT_ERROR(ct, "Received GuC exception notification!\n");
 		ret = 0;
 		break;
+	case INTEL_GUC_ACTION_PAGE_FAULT_NOTIFICATION:
+		ret = intel_pagefault_process_page_fault_msg(guc, payload, len);
+		break;
 	default:
 		ret = -EOPNOTSUPP;
 		break;
@@ -1050,7 +1057,7 @@ static int ct_process_request(struct intel_guc_ct *ct, struct ct_incoming_msg *r
 	return 0;
 }
 
-static bool ct_process_incoming_requests(struct intel_guc_ct *ct)
+static bool ct_process_incoming_requests(struct intel_guc_ct *ct, struct list_head *incoming)
 {
 	unsigned long flags;
 	struct ct_incoming_msg *request;
@@ -1058,11 +1065,11 @@ static bool ct_process_incoming_requests(struct intel_guc_ct *ct)
 	int err;
 
 	spin_lock_irqsave(&ct->requests.lock, flags);
-	request = list_first_entry_or_null(&ct->requests.incoming,
+	request = list_first_entry_or_null(incoming,
 					   struct ct_incoming_msg, link);
 	if (request)
 		list_del(&request->link);
-	done = !!list_empty(&ct->requests.incoming);
+	done = !!list_empty(incoming);
 	spin_unlock_irqrestore(&ct->requests.lock, flags);
 
 	if (!request)
@@ -1085,7 +1092,7 @@ static void ct_incoming_request_worker_func(struct work_struct *w)
 	bool done;
 
 	do {
-		done = ct_process_incoming_requests(ct);
+		done = ct_process_incoming_requests(ct, &ct->requests.incoming);
 	} while (!done);
 }
 
@@ -1105,14 +1112,30 @@ static int ct_handle_event(struct intel_guc_ct *ct, struct ct_incoming_msg *requ
 	switch (action) {
 	case INTEL_GUC_ACTION_SCHED_CONTEXT_MODE_DONE:
 	case INTEL_GUC_ACTION_DEREGISTER_CONTEXT_DONE:
+	case INTEL_GUC_ACTION_TLB_INVALIDATION_DONE:
 		g2h_release_space(ct, request->size);
 	}
+	/* Handle tlb invalidation response in interrupt context */
+	if (action == INTEL_GUC_ACTION_TLB_INVALIDATION_DONE) {
+		const u32 *payload;
+		u32 hxg_len, len;
+
+		hxg_len = request->size - GUC_CTB_MSG_MIN_LEN;
+		len = hxg_len - GUC_HXG_MSG_MIN_LEN;
+		if (unlikely(len < 1))
+			return -EPROTO;
+		payload = &hxg[GUC_HXG_MSG_MIN_LEN];
+		intel_guc_tlb_invalidation_done(ct_to_guc(ct),  payload[0]);
+		ct_free_msg(request);
+		return 0;
+	}
 
 	spin_lock_irqsave(&ct->requests.lock, flags);
 	list_add_tail(&request->link, &ct->requests.incoming);
 	spin_unlock_irqrestore(&ct->requests.lock, flags);
 
 	queue_work(system_unbound_wq, &ct->requests.worker);
+
 	return 0;
 }
 
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc_fwif.h b/drivers/gpu/drm/i915/gt/uc/intel_guc_fwif.h
index 323b055e5db9..153133b87925 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_fwif.h
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_fwif.h
@@ -22,6 +22,7 @@
 /* Payload length only i.e. don't include G2H header length */
 #define G2H_LEN_DW_SCHED_CONTEXT_MODE_SET	2
 #define G2H_LEN_DW_DEREGISTER_CONTEXT		1
+#define G2H_LEN_DW_INVALIDATE_TLB		1
 
 #define GUC_CONTEXT_DISABLE		0
 #define GUC_CONTEXT_ENABLE		1
@@ -476,4 +477,9 @@ enum intel_guc_recv_message {
 	INTEL_GUC_RECV_MSG_EXCEPTION = BIT(30),
 };
 
+#define INTEL_GUC_SUPPORTS_TLB_INVALIDATION(guc) \
+	((intel_guc_ct_enabled(&(guc)->ct)) && \
+	 (intel_guc_submission_is_used(guc)) && \
+	 (GRAPHICS_VER(guc_to_gt((guc))->i915) >= 12))
+
 #endif
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc_log.c b/drivers/gpu/drm/i915/gt/uc/intel_guc_log.c
index 55d3ef93e86f..67ceb020ce1e 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_log.c
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_log.c
@@ -141,7 +141,7 @@ u32 intel_guc_log_section_size_capture(struct intel_guc_log *log)
 	return log->sizes[GUC_LOG_SECTIONS_CAPTURE].bytes;
 }
 
-static u32 intel_guc_log_size(struct intel_guc_log *log)
+u32 intel_guc_log_size(struct intel_guc_log *log)
 {
 	/*
 	 *  GuC Log buffer Layout:
@@ -170,6 +170,12 @@ static u32 intel_guc_log_size(struct intel_guc_log *log)
 		intel_guc_log_section_size_capture(log);
 }
 
+#define GUC_LOG_RELAY_SUBBUF_COUNT 8
+u32 intel_guc_log_relay_subbuf_count(struct intel_guc_log *log)
+{
+	return GUC_LOG_RELAY_SUBBUF_COUNT;
+}
+
 /**
  * DOC: GuC firmware log
  *
@@ -459,13 +465,16 @@ static void _guc_log_copy_debuglogs_for_relay(struct intel_guc_log *log)
 
 		/* Just copy the newly written data */
 		if (read_offset > write_offset) {
-			i915_memcpy_from_wc(dst_data, src_data, write_offset);
+			if (!i915_memcpy_from_wc(dst_data, src_data, write_offset))
+				i915_unaligned_memcpy_from_wc(dst_data, src_data, write_offset);
 			bytes_to_copy = buffer_size - read_offset;
 		} else {
 			bytes_to_copy = write_offset - read_offset;
 		}
-		i915_memcpy_from_wc(dst_data + read_offset,
-				    src_data + read_offset, bytes_to_copy);
+		if (!i915_memcpy_from_wc(dst_data + read_offset,
+					 src_data + read_offset, bytes_to_copy))
+			i915_unaligned_memcpy_from_wc(dst_data + read_offset,
+						      src_data + read_offset, bytes_to_copy);
 
 		src_data += buffer_size;
 		dst_data += buffer_size;
@@ -540,9 +549,9 @@ static int guc_log_relay_create(struct intel_guc_log *log)
 	 * latency, for consuming the logs from relay. Also doesn't take
 	 * up too much memory.
 	 */
-	n_subbufs = 8;
+	n_subbufs = intel_guc_log_relay_subbuf_count(log);
 
-	guc_log_relay_chan = relay_open("guc_log",
+	guc_log_relay_chan = relay_open("guc_log_relay_chan",
 					dev_priv->drm.primary->debugfs_root,
 					subbuf_size, n_subbufs,
 					&relay_callbacks, dev_priv);
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc_log.h b/drivers/gpu/drm/i915/gt/uc/intel_guc_log.h
index 02127703be80..c981eb8f4990 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_log.h
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_log.h
@@ -81,6 +81,8 @@ unsigned int intel_guc_get_log_buffer_size(struct intel_guc_log *log,
 size_t intel_guc_get_log_buffer_offset(struct intel_guc_log *log, enum guc_log_buffer_type type);
 int intel_guc_log_create(struct intel_guc_log *log);
 void intel_guc_log_destroy(struct intel_guc_log *log);
+u32 intel_guc_log_size(struct intel_guc_log *log);
+u32 intel_guc_log_relay_subbuf_count(struct intel_guc_log *log);
 
 int intel_guc_log_set_level(struct intel_guc_log *log, u32 level);
 bool intel_guc_log_relay_created(const struct intel_guc_log *log);
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc_log_debugfs.c b/drivers/gpu/drm/i915/gt/uc/intel_guc_log_debugfs.c
index ddfbe334689f..4a6ad087678c 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_log_debugfs.c
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_log_debugfs.c
@@ -105,10 +105,49 @@ DEFINE_SIMPLE_ATTRIBUTE(guc_log_level_fops,
 			guc_log_level_get, guc_log_level_set,
 			"%lld\n");
 
-static int guc_log_relay_open(struct inode *inode, struct file *file)
+static int guc_log_relay_buf_size_get(void *data, u64 *val)
+{
+	struct intel_guc_log *log = data;
+
+	if (!log)
+		return -ENODEV;
+	if (!log->vma)
+		return -ENODEV;
+
+	*val = (u64) intel_guc_log_size(log);
+
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(guc_log_relay_buf_size_fops,
+			guc_log_relay_buf_size_get, NULL,
+			"%lld\n");
+
+static int guc_log_relay_subbuf_count_get(void *data, u64 *val)
+{
+	struct intel_guc_log *log = data;
+
+	if (!log)
+		return -ENODEV;
+	if (!log->vma)
+		return -ENODEV;
+
+	*val = intel_guc_log_relay_subbuf_count(log);
+
+	return 0;
+}
+
+DEFINE_SIMPLE_ATTRIBUTE(guc_log_relay_subbuf_count_fops,
+			guc_log_relay_subbuf_count_get, NULL,
+			"%lld\n");
+
+static int guc_log_relay_ctl_open(struct inode *inode, struct file *file)
 {
 	struct intel_guc_log *log = inode->i_private;
 
+	if (!log)
+		return -ENODEV;
+
 	if (!intel_guc_is_ready(log_to_guc(log)))
 		return -ENODEV;
 
@@ -118,7 +157,7 @@ static int guc_log_relay_open(struct inode *inode, struct file *file)
 }
 
 static ssize_t
-guc_log_relay_write(struct file *filp,
+guc_log_relay_ctl_write(struct file *filp,
 		    const char __user *ubuf,
 		    size_t cnt,
 		    loff_t *ppos)
@@ -143,7 +182,7 @@ guc_log_relay_write(struct file *filp,
 	return ret ?: cnt;
 }
 
-static int guc_log_relay_release(struct inode *inode, struct file *file)
+static int guc_log_relay_ctl_release(struct inode *inode, struct file *file)
 {
 	struct intel_guc_log *log = inode->i_private;
 
@@ -151,11 +190,11 @@ static int guc_log_relay_release(struct inode *inode, struct file *file)
 	return 0;
 }
 
-static const struct file_operations guc_log_relay_fops = {
+static const struct file_operations guc_log_relay_ctl_fops = {
 	.owner = THIS_MODULE,
-	.open = guc_log_relay_open,
-	.write = guc_log_relay_write,
-	.release = guc_log_relay_release,
+	.open = guc_log_relay_ctl_open,
+	.write = guc_log_relay_ctl_write,
+	.release = guc_log_relay_ctl_release,
 };
 
 void intel_guc_log_debugfs_register(struct intel_guc_log *log,
@@ -165,7 +204,9 @@ void intel_guc_log_debugfs_register(struct intel_guc_log *log,
 		{ "guc_log_dump", &guc_log_dump_fops, NULL },
 		{ "guc_load_err_log_dump", &guc_load_err_log_dump_fops, NULL },
 		{ "guc_log_level", &guc_log_level_fops, NULL },
-		{ "guc_log_relay", &guc_log_relay_fops, NULL },
+		{ "guc_log_relay_ctl", &guc_log_relay_ctl_fops, NULL },
+		{ "guc_log_relay_buf_size", &guc_log_relay_buf_size_fops, NULL },
+		{ "guc_log_relay_subbuf_count", &guc_log_relay_subbuf_count_fops, NULL },
 	};
 
 	if (!intel_guc_is_supported(log_to_guc(log)))
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc_submission.c b/drivers/gpu/drm/i915/gt/uc/intel_guc_submission.c
index 22ba66e48a9b..cd28fe2edeae 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_submission.c
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_submission.c
@@ -1709,11 +1709,20 @@ static void __guc_reset_context(struct intel_context *ce, intel_engine_mask_t st
 	intel_context_put(parent);
 }
 
+static void wake_up_tlb_invalidate(struct intel_guc_tlb_wait *wait)
+{
+	/* Barrier to ensure the store is observed by the woken thread */
+	smp_store_mb(wait->status, 0);
+	wake_up(&wait->wq);
+}
+
 void intel_guc_submission_reset(struct intel_guc *guc, intel_engine_mask_t stalled)
 {
+	struct intel_guc_tlb_wait *wait;
 	struct intel_context *ce;
 	unsigned long index;
 	unsigned long flags;
+	unsigned long i;
 
 	if (unlikely(!guc_submission_initialized(guc))) {
 		/* Reset called during driver load? GuC not yet initialised! */
@@ -1739,6 +1748,13 @@ void intel_guc_submission_reset(struct intel_guc *guc, intel_engine_mask_t stall
 
 	/* GuC is blown away, drop all references to contexts */
 	xa_destroy(&guc->context_lookup);
+
+	/*
+	 * The full GT reset will have cleared the TLB caches and flushed the
+	 * G2H message queue; we can release all the blocked waiters.
+	 */
+	xa_for_each(&guc->tlb_lookup, i, wait)
+		wake_up_tlb_invalidate(wait);
 }
 
 static void guc_cancel_context_requests(struct intel_context *ce)
@@ -1861,6 +1877,41 @@ void intel_guc_submission_reset_finish(struct intel_guc *guc)
 static void destroyed_worker_func(struct work_struct *w);
 static void reset_fail_worker_func(struct work_struct *w);
 
+static int init_tlb_lookup(struct intel_guc *guc)
+{
+	struct intel_guc_tlb_wait *wait;
+	int err;
+
+	xa_init_flags(&guc->tlb_lookup, XA_FLAGS_ALLOC);
+
+	wait = kzalloc(sizeof(*wait), GFP_KERNEL);
+	if (!wait)
+		return -ENOMEM;
+
+	init_waitqueue_head(&wait->wq);
+	err = xa_alloc_cyclic_irq(&guc->tlb_lookup, &guc->serial_slot, wait,
+				  xa_limit_32b, &guc->next_seqno, GFP_KERNEL);
+	if (err == -ENOMEM) {
+		kfree(wait);
+		return err;
+	}
+
+	return 0;
+}
+
+static void fini_tlb_lookup(struct intel_guc *guc)
+{
+	struct intel_guc_tlb_wait *wait;
+
+	wait = xa_load(&guc->tlb_lookup, guc->serial_slot);
+	if (wait) {
+		GEM_BUG_ON(wait->status);
+		kfree(wait);
+	}
+
+	xa_destroy(&guc->tlb_lookup);
+}
+
 /*
  * Set up the memory resources to be shared with the GuC (via the GGTT)
  * at firmware loading time.
@@ -1873,6 +1924,10 @@ int intel_guc_submission_init(struct intel_guc *guc)
 	if (guc->submission_initialized)
 		return 0;
 
+	ret = init_tlb_lookup(guc);
+	if (ret)
+		return ret;
+
 	if (GET_UC_VER(guc) < MAKE_UC_VER(70, 0, 0)) {
 		ret = guc_lrc_desc_pool_create_v69(guc);
 		if (ret)
@@ -1883,7 +1938,7 @@ int intel_guc_submission_init(struct intel_guc *guc)
 		bitmap_zalloc(NUMBER_MULTI_LRC_GUC_ID(guc), GFP_KERNEL);
 	if (!guc->submission_state.guc_ids_bitmap) {
 		ret = -ENOMEM;
-		goto destroy_pool;
+		goto err;
 	}
 
 	guc->timestamp.ping_delay = (POLL_TIME_CLKS / gt->clock_frequency + 1) * HZ;
@@ -1891,10 +1946,8 @@ int intel_guc_submission_init(struct intel_guc *guc)
 	guc->submission_initialized = true;
 
 	return 0;
-
-destroy_pool:
-	guc_lrc_desc_pool_destroy_v69(guc);
-
+err:
+	fini_tlb_lookup(guc);
 	return ret;
 }
 
@@ -1908,6 +1961,7 @@ void intel_guc_submission_fini(struct intel_guc *guc)
 	i915_sched_engine_put(guc->sched_engine);
 	bitmap_free(guc->submission_state.guc_ids_bitmap);
 	guc->submission_initialized = false;
+	fini_tlb_lookup(guc);
 }
 
 static inline void queue_request(struct i915_sched_engine *sched_engine,
@@ -4267,6 +4321,30 @@ g2h_context_lookup(struct intel_guc *guc, u32 ctx_id)
 	return ce;
 }
 
+static void wait_wake_outstanding_tlb_g2h(struct intel_guc *guc, u32 seqno)
+{
+	struct intel_guc_tlb_wait *wait;
+	unsigned long flags;
+
+	xa_lock_irqsave(&guc->tlb_lookup, flags);
+	wait = xa_load(&guc->tlb_lookup, seqno);
+
+	/* We received a response after the waiting task did exit with a timeout */
+	if (unlikely(!wait))
+		drm_dbg(&guc_to_gt(guc)->i915->drm,
+			"Stale tlb invalidation response with seqno %d\n", seqno);
+
+	if (wait)
+		wake_up_tlb_invalidate(wait);
+
+	xa_unlock_irqrestore(&guc->tlb_lookup, flags);
+}
+
+void intel_guc_tlb_invalidation_done(struct intel_guc *guc, u32 seqno)
+{
+	wait_wake_outstanding_tlb_g2h(guc, seqno);
+}
+
 int intel_guc_deregister_done_process_msg(struct intel_guc *guc,
 					  const u32 *msg,
 					  u32 len)
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_uc.c b/drivers/gpu/drm/i915/gt/uc/intel_uc.c
index dbd048b77e19..b59e7ad6ef2e 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_uc.c
+++ b/drivers/gpu/drm/i915/gt/uc/intel_uc.c
@@ -546,6 +546,13 @@ static int __uc_init_hw(struct intel_uc *uc)
 err_log_capture:
 	__uc_capture_load_err_log(uc);
 err_out:
+#if IS_ENABLED(CONFIG_DRM_I915_CAPTURE_ERROR) && IS_ENABLED(CONFIG_DRM_I915_DEBUG_GEM)
+	if (!i915_error_injected()) {
+		drm_info(&i915->drm, "Dumping on GuC load failure...\n");
+		intel_klog_error_capture(uc_to_gt(uc), (intel_engine_mask_t) ~0U);
+	}
+#endif
+
 	/* Return GT back to RPn */
 	intel_rps_lower_unslice(&uc_to_gt(uc)->rps);
 
diff --git a/drivers/gpu/drm/i915/intel_pagefault.c b/drivers/gpu/drm/i915/intel_pagefault.c
new file mode 100644
index 000000000000..5f6e7074e391
--- /dev/null
+++ b/drivers/gpu/drm/i915/intel_pagefault.c
@@ -0,0 +1,148 @@
+// SPDX-License-Identifier: MIT
+/*
+ * Copyright © 2020 Intel Corporation
+ */
+#include "gt/intel_gt.h"
+#include "gt/intel_gt_regs.h"
+#include "i915_drv.h"
+#include "intel_pagefault.h"
+
+struct page_fault_info {
+	u8 access_type;
+	u8 fault_type;
+	u8 engine_id;
+	u8 source_id;
+	u8 fault_lvl;
+	u64 address;
+};
+
+int intel_pagefault_process_cat_error_msg(struct intel_guc *guc,
+					  const u32 *payload, u32 len)
+{
+	struct intel_gt *gt = guc_to_gt(guc);
+	struct drm_i915_private *i915 = gt->i915;
+	u32 ctx_id;
+
+	if (len < 1)
+		return -EPROTO;
+
+	ctx_id = payload[0];
+
+	drm_err(&i915->drm, "GPU catastrophic memory error: GuC context 0x%x\n", ctx_id);
+
+	return 0;
+}
+
+static u64 __get_address(u32 fault_data0, u32 fault_data1)
+{
+	return ((u64)(fault_data1 & FAULT_VA_HIGH_BITS) << 44) |
+	       ((u64)fault_data0 << 12);
+}
+
+static u8 __get_engine_id(u32 fault_reg_data)
+{
+	return GEN8_RING_FAULT_ENGINE_ID(fault_reg_data);
+}
+
+static u8 __get_source_id(u32 fault_reg_data)
+{
+	return RING_FAULT_SRCID(fault_reg_data);
+}
+
+static u8 __get_access_type(u32 fault_reg_data)
+{
+	return !!(fault_reg_data & GEN12_RING_FAULT_ACCESS_TYPE);
+}
+
+static u8 __get_fault_lvl(u32 fault_reg_data)
+{
+	return RING_FAULT_LEVEL(fault_reg_data);
+}
+
+static u8 __get_fault_type(u32 fault_reg_data)
+{
+	return GEN12_RING_FAULT_FAULT_TYPE(fault_reg_data);
+}
+
+static void print_page_fault(struct drm_printer *p,
+			     struct page_fault_info *info)
+{
+	drm_printf(p, "Unexpected fault\n"
+		      "\tAddr: 0x%08x_%08x\n"
+		      "\tEngine ID: %d\n"
+		      "\tSource ID: %d\n"
+		      "\tType: %d\n"
+		      "\tFault Level: %d\n"
+		      "\tAccess type: %s\n",
+		      upper_32_bits(info->address),
+		      lower_32_bits(info->address),
+		      info->engine_id,
+		      info->source_id,
+		      info->fault_type,
+		      info->fault_lvl,
+		      info->access_type ?
+		      "Write" : "Read");
+}
+
+/*
+ * DOC: INTEL_GUC_ACTION_PAGE_FAULT_NOTIFICATION
+ *
+ *      +==========================================================+
+ *      | G2H REPORT PAGE FAULT MESSAGE PAYLOAD                    |
+ *      +==========================================================+
+ *      | 0 | 31:30 |Fault response:                               |
+ *      |   |       | 00 - fault successful resolved               |
+ *      |   |       | 01 - fault resolution is unsuccessful        |
+ *      |   |-------+----------------------------------------------|
+ *      |   | 29:20 |Reserved                                      |
+ *      |   |-------+----------------------------------------------|
+ *      |   | 19:18 |Fault type:                                   |
+ *      |   |       | 00 - page not present                        |
+ *      |   |       | 01 - write access violation                  |
+ *      |   |-------+----------------------------------------------|
+ *      |   |   17  |Access type of the memory request that fault  |
+ *      |   |       | 0 - faulted access is a read request         |
+ *      |   |       | 1 = faulted access is a write request        |
+ *      |   |-------+----------------------------------------------|
+ *      |   | 16:12 |Engine Id of the faulted memory cycle         |
+ *      |   |-------+----------------------------------------------|
+ *      |   |   11  |Reserved                                      |
+ *      |   |-------+----------------------------------------------|
+ *      |   |  10:3 |Source ID of the faulted memory cycle         |
+ *      |   |-------+----------------------------------------------|
+ *      |   |   2:1 |Fault level:                                  |
+ *      |   |       | 00 - PTE                                     |
+ *      |   |       | 01 - PDE                                     |
+ *      |   |       | 10 - PDP                                     |
+ *      |   |       | 11 - PML4                                    |
+ *      |   |-------+----------------------------------------------|
+ *      |   |     0 |Valid bit                                     |
+ *      +---+-------+----------------------------------------------+
+ *      | 1 |  31:0 |Fault cycle virtual address [43:12]           |
+ *      +---+-------+----------------------------------------------+
+ *      | 2 |  31:4 |Reserved                                      |
+ *      |   |-------+----------------------------------------------|
+ *      |   |   3:0 |Fault cycle virtual address [47:44]           |
+ *      +==========================================================+
+ */
+int intel_pagefault_process_page_fault_msg(struct intel_guc *guc,
+					   const u32 *payload, u32 len)
+{
+	struct drm_i915_private *i915 = guc_to_gt(guc)->i915;
+	struct page_fault_info info = {};
+	struct drm_printer p = drm_info_printer(i915->drm.dev);
+
+	if (len < 3)
+		return -EPROTO;
+
+	info.address = __get_address(payload[1], payload[2]);
+	info.engine_id = __get_engine_id(payload[0]);
+	info.source_id = __get_source_id(payload[0]);
+	info.access_type = __get_access_type(payload[0]);
+	info.fault_lvl = __get_fault_lvl(payload[0]);
+	info.fault_type = __get_fault_type(payload[0]);
+
+	print_page_fault(&p, &info);
+
+	return 0;
+}
diff --git a/drivers/gpu/drm/i915/intel_pagefault.h b/drivers/gpu/drm/i915/intel_pagefault.h
new file mode 100644
index 000000000000..623f25f09d39
--- /dev/null
+++ b/drivers/gpu/drm/i915/intel_pagefault.h
@@ -0,0 +1,17 @@
+/* SPDX-License-Identifier: MIT
+ *
+ * Copyright © 2020 Intel Corporation
+ */
+
+#ifndef _INTEL_PAGEFAULT_H
+#define _INTEL_PAGEFAULT_H
+
+#include <linux/types.h>
+
+struct intel_guc;
+
+int intel_pagefault_process_cat_error_msg(struct intel_guc *guc,
+					  const u32 *payload, u32 len);
+int intel_pagefault_process_page_fault_msg(struct intel_guc *guc,
+					   const u32 *payload, u32 len);
+#endif
-- 
2.25.1

