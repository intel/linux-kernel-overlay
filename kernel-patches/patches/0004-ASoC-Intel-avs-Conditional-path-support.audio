From c9a81424028cf6a0c990a34a5aa022d5e7c76787 Mon Sep 17 00:00:00 2001
From: Cezary Rojewski <cezary.rojewski@intel.com>
Date: Tue, 14 Sep 2021 16:06:02 +0200
Subject: [PATCH 4/6] ASoC: Intel: avs: Conditional-path support
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Compared to standard paths, conditional paths are not invoked by the
means of FE being opened by userspace and thus their variant selection
is not FE/BE audio format based. These are a side effect of standard path
creation if specific criteria are met.

Algorithm is implemented to walk on all existing runtime paths and match
them against conditions provided by topology. These conditions are based
on source and sink path formats, rather than formats provided from
userspace app or present on the codec. If match is found, new path is
created and tied to those which brought it into existence: source and
sink path. If any of its parents perishes, so does the conditional path.

Conditional paths are used to enable any complex, modern audio scenario
which involves usage of KPB, AEC and WoV modules and more.

Signed-off-by: Amadeusz Sławiński <amadeuszx.slawinski@linux.intel.com>
Signed-off-by: Cezary Rojewski <cezary.rojewski@intel.com>
---
 sound/soc/intel/avs/path.c | 275 +++++++++++++++++++++++++++++++++++++
 sound/soc/intel/avs/path.h |  13 ++
 2 files changed, 288 insertions(+)

diff --git a/sound/soc/intel/avs/path.c b/sound/soc/intel/avs/path.c
index 2782de202c68..75c4303788cb 100644
--- a/sound/soc/intel/avs/path.c
+++ b/sound/soc/intel/avs/path.c
@@ -114,6 +114,79 @@ avs_path_find_variant(struct avs_dev *adev,
 	return NULL;
 }
 
+static struct avs_tplg_path *
+avs_condpath_find_variant(struct avs_dev *adev,
+			  struct avs_tplg_path_template *template,
+			  struct avs_path *source, struct avs_path *sink)
+{
+	struct avs_tplg_path *variant;
+
+	list_for_each_entry(variant, &template->path_list, node) {
+		if (variant->source_path_id == source->template->id &&
+		    variant->sink_path_id == sink->template->id)
+			return variant;
+	}
+
+	return NULL;
+}
+
+static bool avs_tplg_path_template_id_equal(struct avs_tplg_path_template_id *id,
+					    struct avs_tplg_path_template_id *id2)
+{
+	return id->id == id2->id && !strcmp(id->tplg_name, id2->tplg_name);
+}
+
+static struct avs_path *
+avs_condpath_find_match(struct avs_dev *adev,
+			struct avs_tplg_path_template *template,
+			struct avs_path *path, int dir)
+{
+	struct avs_tplg_path_template_id *id, *id2;
+
+	if (dir) {
+		id = &template->source;
+		id2 = &template->sink;
+	} else {
+		id = &template->sink;
+		id2 = &template->source;
+	}
+
+	/* Check whether this path is either source or sink of condpath template. */
+	if (id->id != path->template->owner->id ||
+	    strcmp(id->tplg_name, path->template->owner->owner->name))
+		return NULL;
+
+	/* Unidirectional condpaths are allowed. */
+	if (avs_tplg_path_template_id_equal(id, id2))
+		return path;
+
+	/* Now find the counterpart. */
+	return avs_path_find_path(adev, id2->tplg_name, id2->id);
+}
+
+static struct avs_path *
+avs_condpath_find_conflict(struct avs_dev *adev, u32 cond_type,
+			   struct avs_path *path, int dir)
+{
+	struct avs_path *pos, *target;
+
+	if (cond_type != AVS_COND_TYPE_NONE) {
+		spin_lock(&adev->path_list_lock);
+		list_for_each_entry(pos, &adev->path_list, node) {
+			if (pos->template->owner->cond_type != cond_type)
+				continue;
+			target = dir ? pos->source : pos->sink;
+			if (path == target) {
+				spin_unlock(&adev->path_list_lock);
+				return pos;
+			}
+		}
+		spin_unlock(&adev->path_list_lock);
+	}
+
+	return NULL;
+}
+
 __maybe_unused
 static bool avs_dma_type_is_host(u32 dma_type)
 {
@@ -786,6 +859,10 @@ static int avs_path_init(struct avs_dev *adev, struct avs_path *path,
 	path->dma_id = dma_id;
 	INIT_LIST_HEAD(&path->ppl_list);
 	INIT_LIST_HEAD(&path->node);
+	INIT_LIST_HEAD(&path->source_list);
+	INIT_LIST_HEAD(&path->sink_list);
+	INIT_LIST_HEAD(&path->source_node);
+	INIT_LIST_HEAD(&path->sink_node);
 
 	/* create all the pipelines */
 	list_for_each_entry(tppl, &template->ppl_list, node) {
@@ -869,12 +946,177 @@ static struct avs_path *avs_path_create_unlocked(struct avs_dev *adev, u32 dma_i
 	return ERR_PTR(ret);
 }
 
+static void avs_condpath_free(struct avs_dev *adev, struct avs_path *path)
+{
+	int ret;
+
+	list_del(&path->source_node);
+	list_del(&path->sink_node);
+
+	ret = avs_path_reset(path);
+	if (ret < 0)
+		dev_err(adev->dev, "reset condpath failed: %d\n", ret);
+
+	ret = avs_path_unbind(path);
+	if (ret < 0)
+		dev_err(adev->dev, "unbind condpath failed: %d\n", ret);
+
+	avs_path_free_unlocked(path);
+}
+
+static struct avs_path *avs_condpath_create(struct avs_dev *adev, u32 dma_id,
+					    struct avs_tplg_path *template,
+					    struct avs_path *source,
+					    struct avs_path *sink)
+{
+	struct avs_path *path;
+	int ret;
+
+	path = avs_path_create_unlocked(adev, dma_id, template);
+	if (IS_ERR(path))
+		return path;
+
+	ret = avs_path_bind(path);
+	if (ret)
+		goto err;
+
+	ret = avs_path_reset(path);
+	if (ret)
+		goto err;
+
+	path->source = source;
+	path->sink = sink;
+	list_add_tail(&path->source_node, &source->source_list);
+	list_add_tail(&path->sink_node, &sink->sink_list);
+
+	return path;
+err:
+	avs_path_free_unlocked(path);
+	return ERR_PTR(ret);
+}
+
+static int avs_condpath_walk(struct avs_dev *adev, struct avs_path *path, int dir)
+{
+	struct avs_tplg_path_template *template;
+	struct avs_soc_component *acomp;
+	struct avs_tplg_path *variant;
+	struct avs_path **other, *conflict;
+	struct avs_path *source, *sink;
+	struct avs_path *cpath;
+	unsigned long type, types = 0;
+	int max, i;
+
+	if (dir) {
+		source = path;
+		other = &sink;
+	} else {
+		sink = path;
+		other = &source;
+	}
+
+	/* First create all non-conflicting condpaths. */
+	list_for_each_entry(acomp, &adev->comp_list, node) {
+		for (i = 0; i < acomp->tplg->num_condpath_tmpls; i++) {
+			template = &acomp->tplg->condpath_tmpls[i];
+
+			/* Do not create unidirectional condpaths twice */
+			if (avs_tplg_path_template_id_equal(&template->source,
+							    &template->sink) && dir)
+				continue;
+
+			if (template->cond_type != AVS_COND_TYPE_NONE) {
+				/* Save conflicting types to check later on. */
+				types |= BIT(template->cond_type);
+				continue;
+			}
+
+			*other = avs_condpath_find_match(adev, template, path, dir);
+			if (!*other)
+				continue;
+			variant = avs_condpath_find_variant(adev, template, source, sink);
+			if (!variant)
+				continue;
+
+			cpath = avs_condpath_create(adev, 0, variant, source, sink);
+			if (IS_ERR(cpath))
+				return PTR_ERR(cpath);
+		}
+	}
+	/* Now deal with exclusive condpaths. */
+	for_each_set_bit(type, &types, 32) {
+		variant = NULL;
+		*other = NULL;
+
+		conflict = avs_condpath_find_conflict(adev, type, path, dir);
+		if (conflict) {
+			/* Does existing conflict allow for override? */
+			if (!conflict->template->owner->overridable)
+				continue;
+			max = conflict->template->owner->priority;
+		} else {
+			max = -1;
+		}
+
+		/* Find best match - with highest priority. */
+		list_for_each_entry(acomp, &adev->comp_list, node) {
+			for (i = 0; i < acomp->tplg->num_condpath_tmpls; i++) {
+				template = &acomp->tplg->condpath_tmpls[i];
+
+				/* Do not create unidirectional condpaths twice */
+				if (avs_tplg_path_template_id_equal(&template->source,
+								    &template->sink) && dir)
+					continue;
+
+				if (template->cond_type != type || template->priority <= max)
+					continue;
+
+				*other = avs_condpath_find_match(adev, template, path, dir);
+				if (!*other)
+					continue;
+				variant = avs_condpath_find_variant(adev, template, source,
+								    sink);
+				if (variant)
+					max = template->priority;
+			}
+		}
+
+		if (variant) {
+			cpath = avs_condpath_create(adev, 0, variant, source, sink);
+			if (IS_ERR(cpath))
+				return PTR_ERR(cpath);
+		}
+	}
+
+	return 0;
+}
+
+/* caller responsible for holding adev->path_mutex */
+static int avs_condpath_walk_all(struct avs_dev *adev, struct avs_path *path)
+{
+	int ret;
+
+	ret = avs_condpath_walk(adev, path, 1);
+	if (ret)
+		return ret;
+
+	return avs_condpath_walk(adev, path, 0);
+}
+
 void avs_path_free(struct avs_path *path)
 {
+	struct avs_path *cpath, *csave;
 	struct avs_dev *adev = path->owner;
 
 	mutex_lock(&adev->path_mutex);
+
+	/* Free all condpaths this path spawned. */
+	list_for_each_entry_safe(cpath, csave, &path->source_list, source_node)
+		avs_condpath_free(path->owner, cpath);
+	list_for_each_entry_safe(cpath, csave, &path->sink_list, sink_node)
+		avs_condpath_free(path->owner, cpath);
+
 	avs_path_free_unlocked(path);
+
 	mutex_unlock(&adev->path_mutex);
 }
 
@@ -885,6 +1127,7 @@ struct avs_path *avs_path_create(struct avs_dev *adev, u32 dma_id,
 {
 	struct avs_tplg_path *variant;
 	struct avs_path *path;
+	int ret;
 
 	variant = avs_path_find_variant(adev, template, fe_params, be_params);
 	if (!variant) {
@@ -898,7 +1141,16 @@ struct avs_path *avs_path_create(struct avs_dev *adev, u32 dma_id,
 	mutex_lock(&adev->comp_list_mutex);
 
 	path = avs_path_create_unlocked(adev, dma_id, variant);
+	if (IS_ERR(path))
+		goto exit;
+
+	ret = avs_condpath_walk_all(adev, path);
+	if (ret) {
+		avs_path_free_unlocked(path);
+		path = ERR_PTR(ret);
+	}
 
+exit:
 	mutex_unlock(&adev->comp_list_mutex);
 	mutex_unlock(&adev->path_mutex);
 
@@ -1024,12 +1276,19 @@ int avs_path_reset(struct avs_path *path)
 int avs_path_pause(struct avs_path *path)
 {
 	struct avs_path_pipeline *ppl;
+	struct avs_path *cpath;
 	struct avs_dev *adev = path->owner;
 	int ret;
 
 	if (path->state == AVS_PPL_STATE_PAUSED)
 		return 0;
 
+	/* if either source or sink stops, so do attached conditional paths */
+	list_for_each_entry(cpath, &path->source_list, source_node)
+		avs_path_pause(cpath);
+	list_for_each_entry(cpath, &path->sink_list, sink_node)
+		avs_path_pause(cpath);
+
 	list_for_each_entry_reverse(ppl, &path->ppl_list, node) {
 		ret = avs_ipc_set_pipeline_state(adev, ppl->instance_id,
 						 AVS_PPL_STATE_PAUSED);
@@ -1047,6 +1306,7 @@ int avs_path_pause(struct avs_path *path)
 int avs_path_run(struct avs_path *path, int trigger)
 {
 	struct avs_path_pipeline *ppl;
+	struct avs_path *cpath;
 	struct avs_dev *adev = path->owner;
 	int ret;
 
@@ -1067,5 +1327,20 @@ int avs_path_run(struct avs_path *path, int trigger)
 	}
 
 	path->state = AVS_PPL_STATE_RUNNING;
+
+	/* granular pipeline triggering not intended for conditional paths */
+	if (trigger == AVS_TPLG_TRIGGER_AUTO) {
+		/* run conditional paths only if source and sink are both running */
+		list_for_each_entry(cpath, &path->source_list, source_node)
+			if (cpath->source->state == AVS_PPL_STATE_RUNNING &&
+			    cpath->sink->state == AVS_PPL_STATE_RUNNING)
+				avs_path_run(cpath, trigger);
+
+		list_for_each_entry(cpath, &path->sink_list, sink_node)
+			if (cpath->source->state == AVS_PPL_STATE_RUNNING &&
+			    cpath->sink->state == AVS_PPL_STATE_RUNNING)
+				avs_path_run(cpath, trigger);
+	}
+
 	return 0;
 }
diff --git a/sound/soc/intel/avs/path.h b/sound/soc/intel/avs/path.h
index 657f7b093e80..a5076c99a070 100644
--- a/sound/soc/intel/avs/path.h
+++ b/sound/soc/intel/avs/path.h
@@ -13,11 +13,24 @@
 #include "avs.h"
 #include "topology.h"
 
+#define AVS_COND_TYPE_NONE	0
+#define AVS_COND_TYPE_AECREF	1
+
 struct avs_path {
 	u32 dma_id;
 	struct list_head ppl_list;
 	u32 state;
 
+	/* condpath navigation for standard paths */
+	struct list_head source_list;
+	struct list_head sink_list;
+
+	/* conditional path fields */
+	struct avs_path *source;
+	struct avs_path *sink;
+	struct list_head source_node;
+	struct list_head sink_node;
+
 	struct avs_tplg_path *template;
 	struct avs_dev *owner;
 	/* device path management */
-- 
2.34.1

